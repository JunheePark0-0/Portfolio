{"cells":[{"cell_type":"code","execution_count":37,"metadata":{"id":"isT265wQhJU0","executionInfo":{"status":"ok","timestamp":1755340444837,"user_tz":-540,"elapsed":67,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from pathlib import Path\n","\n","import datetime\n","from datetime import timedelta\n","# !pip install holidays\n","import holidays\n","\n","os.chdir(\"/content/drive/MyDrive/3. Grad School/LG Aimers\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANnKbGzih5yO"},"outputs":[],"source":["# 데이터 불러오기\n","data = pd.read_csv(\"DATA/train/train.csv\")"]},{"cell_type":"markdown","metadata":{"id":"W3rcw_Bbh-nB"},"source":["#### 파생변수 생성"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"N6NiJd97h_-N","executionInfo":{"status":"ok","timestamp":1755340447708,"user_tz":-540,"elapsed":6,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["# 월(month) -> 계절 매핑 딕셔너리\n","month_to_season = {\n","    1: \"Winter\", 2: \"Winter\", 12: \"Winter\",\n","    3: \"Spring\", 4: \"Spring\", 5: \"Spring\",\n","    6: \"Summer\", 7: \"Summer\", 8: \"Summer\",\n","    9: \"Autumn\", 10: \"Autumn\", 11: \"Autumn\"}"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"WusevNkYqMwZ","executionInfo":{"status":"ok","timestamp":1755340448527,"user_tz":-540,"elapsed":4,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["# 월별 가중치 매핑\n","# monthly_weights = {\n","#     1: 1.5, 2: 1.5, 3: 0.5,\n","#     4: 0.8, 5: 0.8, 6: 0.8,\n","#     7: 1.2, 8: 1.2, 9: 0.8,\n","#     10: 0.8, 11: 0.8, 12: 1.2}\n","\n","monthly_weights = {\n","    1: 2.2, 2: 1.8, 3: 0.3,\n","    4: 1.01, 5: 0.7, 6: 0.8,\n","    7: 0.5, 8: 0.5, 9: 0.8,\n","    10: 1.55, 11: 1.03, 12: 1.4}"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"39ITfoSm14y4","executionInfo":{"status":"ok","timestamp":1755340449144,"user_tz":-540,"elapsed":3,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["# 요일별 가중치 매핑\n","# weekly_weights = {\n","#     \"Monday\": 0.8, \"Tuesday\": 0.8, \"Wednesday\": 0.8,\n","#     \"Thursday\": 0.8, \"Friday\": 1.2, \"Saturday\": 1.7,\n","#     \"Sunday\": 1.5}\n","\n","weekly_weights = {\n","    \"Monday\": 0.78, \"Tuesday\": 0.85, \"Wednesday\": 0.81,\n","    \"Thursday\": 9.9, \"Friday\": 1.2, \"Saturday\": 1.53,\n","    \"Sunday\": 1.3}"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"n5Bo-6_MYg5Q","executionInfo":{"status":"ok","timestamp":1755340450621,"user_tz":-540,"elapsed":226,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["class Make_Variables():\n","        def __init__(self, data = None, date = None, predict = 7, month_to_season = None, monthly_weights = None, weekly_weights = None):\n","            self.data = data\n","            self.date = date\n","            self.predict = predict\n","            self.month_to_season = month_to_season\n","            self.monthly_weights = monthly_weights\n","            self.weekly_weights = weekly_weights\n","\n","        def update_kor_holidays(self):\n","            \"\"\"국경일 추가\"\"\"\n","            kor_holidays = holidays.KR(years = [2023, 2024, 2025])\n","            kor_holidays.update({\n","                # datetime.date(2023,2,14) : \"Valentine's Day\",\n","                # datetime.date(2023,3,14) : \"White Day\",\n","                # datetime.date(2023,11,11) : \"Pepero Day\",\n","                # datetime.date(2024,2,14) : \"Valentine's Day\",\n","                # datetime.date(2024,3,14) : \"White Day\",\n","                # datetime.date(2024,11,11) : \"Pepero Day\",\n","                # datetime.date(2025,2,14) : \"Valentine's Day\",\n","                # datetime.date(2025,3,14) : \"White Day\",\n","                # datetime.date(2025,11,11) : \"Pepero Day\",\n","\n","                datetime.date(2024,10,1) : \"Temporary Holiday\", # 국군의 날 임시공휴일\n","                datetime.date(2025,1,27) : \"Temporary Holiday\", # 설날 임시공휴일\n","                datetime.date(2025,3,3) : \"Temporary Holiday\", # 삼일절 대체공휴일\n","                datetime.date(2025, 5, 29) : \"Election Period\",\n","                datetime.date(2025, 5, 30) : \"Election Period\",\n","                datetime.date(2025, 6, 3) : \"Presidential Election Day\"})\n","            return kor_holidays\n","\n","        def check_holidays(self, date, kor_holidays) -> int:\n","            \"\"\"날짜 받아서 공휴일/주말 여부 출력\"\"\"\n","            # date = pd.Timestamp(date)\n","            if isinstance(date, pd.Series):\n","                check_holiday = date.dt.date.isin(kor_holidays)\n","                check_weekend = date.dt.weekday >= 5\n","            else:\n","                check_holiday = date.date() in kor_holidays\n","                check_weekend = date.weekday() >= 5\n","            is_holiday = (check_holiday | check_weekend)\n","            return is_holiday\n","\n","        def get_sandwich_score(self, data, is_holiday_col) -> pd.DataFrame:\n","            \"\"\"데이터프레임 기준으로 샌드위치 점수 계산\"\"\"\n","            data = data.reset_index(drop = True)\n","            data['is_sandwich'] = 0\n","            is_holiday = data[is_holiday_col].astype(int)\n","            for idx in range(len(data)):\n","                if idx == 0 or idx == len(data) - 1: # 첫날, 마지막 날\n","                    continue\n","\n","                # 앞/뒤 하루씩 봤을 때 모두 휴일 -> 5점\n","                if (is_holiday.iloc[idx - 1] == 1) and (is_holiday.iloc[idx + 1] == 1): # 하루 전이랑 다음 날이 공휴일이면\n","                    data.iloc[idx, data.columns.get_loc('is_sandwich')] = 5\n","\n","                # 앞/뒤 이틀씩 봤을 때 휴일 3일 -> 3점, 2일 -> 2점\n","                elif idx > 1 and idx < len(is_holiday) - 2: # 셋째날, 마지막에서 세 번째 날\n","                    start_idx = idx - 2\n","                    end_idx = idx + 2\n","                    nearby_holidays = (is_holiday.iloc[start_idx : end_idx + 1].sum() - is_holiday.iloc[idx])\n","                    if nearby_holidays == 3:\n","                        data.iloc[idx, data.columns.get_loc('is_sandwich')] = 3\n","                    elif nearby_holidays == 2:\n","                        data.iloc[idx, data.columns.get_loc('is_sandwich')] = 2\n","                    else:\n","                        data.iloc[idx, data.columns.get_loc('is_sandwich')] = 0\n","            return data\n","\n","        def get_sandwich_score_for_dates(self, date, kor_holidays) -> int:\n","            \"\"\"특정 날짜를 받아와서 앞뒤 날짜를 구하고, 샌드위치 점수 계산\"\"\"\n","            # 하루씩\n","            prev_date, next_date = date - timedelta(days = 1), date + timedelta(days = 1)\n","            prev_hol, next_hol = self.check_holidays(prev_date, kor_holidays), self.check_holidays(next_date, kor_holidays) # T/F Bool\n","            if prev_hol and next_hol: # 바로 다음 날들이 휴일이라면\n","                return 3\n","            days_offsets = [-2, -1, 1, 2] # 앞뒤로 이틀 살펴보기\n","            nearby_holidays = sum(self.check_holidays(date + timedelta(days = d), kor_holidays) for d in days_offsets)\n","            if nearby_holidays == 3: # 앞뒤 4일 중에 3일이 휴일이면\n","                return 2\n","            elif nearby_holidays == 2: # 앞뒤 4일 중에 2일이 휴일이면\n","                return 1\n","            else:\n","                return 0\n","\n","        def get_month_weights(self, data = None, monthly_weights = monthly_weights):\n","            \"\"\"월별 가중치 부여\"\"\"\n","            # 데이터프레임 들어오면\n","            if data is not None:\n","                data['month_weight'] = data['month'].map(monthly_weights)\n","                return data\n","\n","        def get_week_weights(self, data = None, weekly_weights = weekly_weights):\n","            \"\"\"요일별 가중치 부여\"\"\"\n","            # 데이터프레임 들어오면\n","            if data is not None:\n","                data['week_weight'] = data['weekday'].map(weekly_weights)\n","                return data\n","\n","        def get_prev_days(self, data, test_df = None, date = None, menu = None, howmany = 7):\n","            \"\"\"\n","            일요일 날짜 받아와서 직전 주차의 일-토 매출수량 평균 계산\n","            주의 - test data에서 생성할 때는 참고할 데이터와 붙여넣을 데이터가 다름\n","            data : 참고할 데이터\n","            test_df : 참고할 데이터\n","            \"\"\"\n","            if test_df is None:\n","                # 혹시 모르니까 검증\n","                if date.weekday() == 6:\n","                    # 이전 날짜들\n","                    prev_start = date - timedelta(days = howmany)\n","                    prev_end = date - timedelta(days = 1)\n","                    prev_data = data[(data['영업일자'] >= prev_start) & (data['영업일자'] <= prev_end) & (data['영업장명_메뉴명'] == menu)]\n","                    prev_avg = prev_data['매출수량'].mean()\n","                    prev_sd = prev_data['매출수량'].std()\n","                    # 첫 주 0으로 처리\n","                    if pd.isna(prev_avg):\n","                        prev_avg = 0\n","                    if pd.isna(prev_sd):\n","                        prev_sd = 0\n","                    week_end = date + timedelta(days = 6)\n","                    curr_mask = (data['영업일자'] >= date) & (data['영업일자'] <= week_end) & (data['영업장명_메뉴명'] == menu)\n","                    colname_mean = f\"prev_avg_{howmany}\"\n","                    colname_sd = f\"prev_sd_{howmany}\"\n","                    data.loc[curr_mask, colname_mean] = prev_avg\n","                    data.loc[curr_mask, colname_sd] = prev_sd\n","                    return data\n","                else:\n","                    return np.nan\n","\n","            # test data라면\n","            else:\n","                # 혹시 모르니까 검증\n","                if date.weekday() == 6:\n","                    # 이전 날짜들\n","                    prev_start = date - timedelta(days = howmany)\n","                    prev_end = date - timedelta(days = 1)\n","                    prev_data = test_df[(test_df['영업일자'] >= prev_start) & (test_df['영업일자'] <= prev_end) & (test_df['영업장명_메뉴명'] == menu)]\n","                    prev_avg = prev_data['매출수량'].mean()\n","                    prev_sd = prev_data['매출수량'].std()\n","                    # 첫 주 0으로 처리\n","                    if pd.isna(prev_avg):\n","                        prev_avg = 0\n","                    if pd.isna(prev_sd):\n","                        prev_sd = 0\n","                    week_end = date + timedelta(days = 6)\n","                    curr_mask = (data['영업일자'] >= date) & (data['영업일자'] <= week_end) & (data['영업장명_메뉴명'] == menu)\n","                    colname_mean = f\"prev_avg_{howmany}\"\n","                    colname_sd = f\"prev_sd_{howmany}\"\n","                    data.loc[curr_mask, colname_mean] = prev_avg\n","                    data.loc[curr_mask, colname_sd] = prev_sd\n","                    return data\n","                else:\n","                    return np.nan\n","\n","        #########################################################################\n","        def add_ohe_cols(self, data):\n","            season_order = [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"]\n","            month_order = list(range(1,13))\n","            weekday_order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n","\n","            data[\"season\"] = pd.Categorical(data[\"season\"], categories=season_order)\n","            data[\"month\"]   = pd.Categorical(data[\"month\"].astype(int), categories = month_order)\n","            data[\"weekday\"] = pd.Categorical(data[\"weekday\"], categories = weekday_order)\n","\n","            season_ohe = pd.get_dummies(data[\"season\"], prefix=\"season\", dtype=\"int8\")\n","            m_ohe  = pd.get_dummies(data[\"month\"],   prefix=\"m\",  dtype=\"int8\")\n","            wd_ohe = pd.get_dummies(data[\"weekday\"], prefix=\"wd\", dtype=\"int8\")\n","\n","            return pd.concat([data, season_ohe, m_ohe, wd_ohe], axis=1)\n","        #########################################################################\n","\n","        # train, test 공통\n","        def make_fund_variables(self, data, month_to_season = month_to_season):\n","            # 영업일자 -> datetime\n","            data['영업일자'] = pd.to_datetime(data['영업일자'])\n","\n","            # 연, 월, 일, 요일 분리\n","            data['year'] = data['영업일자'].dt.year\n","            data['month'] = data['영업일자'].dt.month\n","            data['day'] = data['영업일자'].dt.day\n","            data['weekday'] = data['영업일자'].dt.day_name()\n","            data['weekday_enc'] = data['영업일자'].dt.weekday\n","\n","            # 계절 변수 생성\n","            data['season'] = data['month'].map(month_to_season)\n","\n","            # 연도 차이 변수 생성\n","            data['year_enc'] = data['year'] - 2023\n","\n","            # 월, 일, 요일 사이클릭 변환\n","            data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n","            data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n","\n","            data['day_sin'] = np.sin(2 * np.pi * data['day'] / 31)\n","            data['day_cos'] = np.cos(2 * np.pi * data['day'] / 31)\n","\n","            data['weekday_sin'] = np.sin(2 * np.pi * data['weekday_enc'] / 7)\n","            data['weekday_cos'] = np.cos(2 * np.pi * data['weekday_enc'] / 7)\n","\n","            # 공휴일 확인\n","            kor_holidays = self.update_kor_holidays()\n","            check_holiday = data['영업일자'].dt.date.isin(kor_holidays)\n","            check_weekend = data['weekday'].isin(['Saturday', 'Sunday'])\n","            data['is_holiday'] = (check_holiday | check_weekend).astype(int) # 공휴일 + 주말\n","            data['holiday_name'] = data['영업일자'].dt.date.map(kor_holidays)\n","\n","            # one-hot\n","            data = self.add_ohe_cols(data)\n","\n","            return data\n","\n","        # train의 입력 데이터\n","        def make_variables_train(self, data):\n","            data = self.make_fund_variables(data)\n","            kor_holidays = self.update_kor_holidays()\n","\n","            ### 샌드위치 데이\n","            data = self.get_sandwich_score(data, 'is_holiday')\n","\n","            # 샌드위치 - 첫날\n","            first = data['영업일자'].min()\n","            data.loc[data['영업일자'] == first, 'is_sandwich'] = self.get_sandwich_score_for_dates(first, kor_holidays)\n","            second = data['영업일자'].min() + timedelta(days = 1)\n","            data.loc[data['영업일자'] == second, 'is_sandwich'] = self.get_sandwich_score_for_dates(second, kor_holidays)\n","\n","            # 샌드위치 - 마지막 날\n","            last = data['영업일자'].max()\n","            data.loc[data['영업일자'] == last, 'is_sandwich'] = self.get_sandwich_score_for_dates(last, kor_holidays)\n","            before = data['영업일자'].max() - timedelta(days = 1)\n","            data.loc[data['영업일자'] == before, 'is_sandwich'] = self.get_sandwich_score_for_dates(before, kor_holidays)\n","\n","            # 샌드위치 포함한 공휴일\n","            data['is_holiday_sandwich'] = data['is_holiday'].astype(int) | (data['is_sandwich'] > 0).astype(int)\n","\n","            ### 월별 가중치\n","            data = self.get_month_weights(data, monthly_weights)\n","\n","            ### 요일별 가중치\n","            data = self.get_week_weights(data, weekly_weights)\n","\n","            ### 직전 주차 평균\n","            sundays = data[data['weekday'] == \"Sunday\"][[\"영업일자\", \"영업장명_메뉴명\"]].copy()\n","            for _, row in sundays.iterrows():\n","                date = row['영업일자']\n","                menu = row['영업장명_메뉴명']\n","                data = self.get_prev_days(data = data, date = date, menu = menu, howmany = 7)\n","                data = self.get_prev_days(data = data, date = date, menu = menu, howmany = 14)\n","                data = self.get_prev_days(data = data, date = date, menu = menu, howmany = 21)\n","\n","            ### 영업장명, 메뉴명 분리\n","            if '영업장명_메뉴명' in data.columns:\n","                data[['영업장명', '메뉴명']] = data['영업장명_메뉴명'].str.split('_', expand = True)\n","\n","            ### 음수 처리\n","            negative = data[data['매출수량'] < 0]\n","\n","            for idx, row in negative.iterrows():\n","                num = row['매출수량']\n","                if num < -10:\n","                    date = row['영업일자']\n","                    menu = row['영업장명_메뉴명']\n","                    prev_date = pd.to_datetime(date) - pd.Timedelta(days = 1)\n","                    prev_row = data[(data['영업일자'] == prev_date) & (data['영업장명_메뉴명'] == menu)]\n","\n","                    if prev_row.iloc[0][\"매출수량\"] >= abs(num):\n","                        data.loc[prev_row.index[0], '매출수량'] += num\n","\n","            # 남은 건 전부 0으로\n","            data.loc[data['매출수량'] < 0, '매출수량'] = 0\n","\n","            return data\n","\n","        # 예측하고자 하는 날들\n","        def make_variables_test(self, date, test_df, predict):\n","            \"\"\"\n","            date : 최종 날짜 (입력 7일 중 가장 마지막) - TimeStamp\n","            test_df : 예측할 때 참고해올 데이터 -> 이거로 직전 주차 평균 생성\n","            \"\"\"\n","            date = pd.to_datetime(date)\n","            future_dates = [date + timedelta(days = i + 1) for i in range(predict)]\n","            future_df = pd.DataFrame({'영업일자' : future_dates})\n","\n","            menus_df = (test_df[['영업장명_메뉴명']].drop_duplicates().reset_index(drop = True))\n","            future_df = future_df.merge(menus_df, how='cross')\n","\n","            kor_holidays = self.update_kor_holidays()\n","\n","            # 기본적인 변수들\n","            future_df = self.make_fund_variables(future_df)\n","\n","            future_df['영업일자'] = pd.to_datetime(future_df['영업일자']).dt.normalize()\n","\n","            # 샌드위치\n","            future_df['is_sandwich'] = future_df['영업일자'].apply(lambda d: self.get_sandwich_score_for_dates(d, kor_holidays))\n","\n","             # 샌드위치 포함한 공휴일\n","            future_df['is_holiday_sandwich'] = future_df['is_holiday'].astype(int) | (future_df['is_sandwich'] > 0).astype(int)\n","\n","            # 월별 가중치\n","            future_df = self.get_month_weights(future_df, monthly_weights)\n","\n","            # 요일별 가중치\n","            future_df = self.get_week_weights(future_df, weekly_weights)\n","\n","            # 직전 주차 평균 -> 이거는 test 까지 받아오고 생각해야 함..\n","            sundays =  future_df.loc[future_df['weekday'] == \"Sunday\", ['영업일자', '영업장명_메뉴명']].copy()\n","            for _, row in sundays.iterrows():\n","                date = row['영업일자']\n","                menu = row['영업장명_메뉴명']\n","                future_df = self.get_prev_days(data = future_df, test_df = test_df, date = date, menu = menu, howmany = 7)\n","                future_df = self.get_prev_days(data = future_df, test_df = test_df, date = date, menu = menu, howmany = 14)\n","                future_df = self.get_prev_days(data = future_df, test_df = test_df, date = date, menu = menu, howmany = 21)\n","\n","            return future_df"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"eSOBveVOoNIS"},"outputs":[],"source":["# 그냥 전부 만들면 돼\n","mv = Make_Variables()\n","data = mv.make_variables_train(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1755069295751,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"igarBBY4-iYw","outputId":"4380c8c7-0885-4b3f-b140-6d1ad483647b"},"outputs":[{"name":"stdout","output_type":"stream","text":["기존 공휴일 :  33389\n","샌드위치 :  579\n","샌드위치 포함 공휴일 :  33968\n"]}],"source":["print(\"기존 공휴일 : \", data['is_holiday'].sum().item())\n","print(\"샌드위치 : \", data['is_sandwich'].sum().item())\n","print(\"샌드위치 포함 공휴일 : \", data['is_holiday_sandwich'].sum().item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPZoqlrc-rxW"},"outputs":[],"source":["import pickle\n","data.to_pickle(\"/content/drive/MyDrive/3. Grad School/LG Aimers/DATA/train_data_new.pickle\")"]},{"cell_type":"markdown","metadata":{"id":"_xQZUH_KcAni"},"source":["#### 저장된 데이터 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llh2iAftY62P"},"outputs":[],"source":["# 데이터 불러오기\n","data = pd.read_pickle(\"/content/drive/MyDrive/3. Grad School/LG Aimers/DATA/train_data_new.pickle\")"]},{"cell_type":"code","source":["def add_ohe_cols(data):\n","    season_order = [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"]\n","    month_order = list(range(1,13))\n","    weekday_order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n","\n","    data[\"season\"] = pd.Categorical(data[\"season\"], categories=season_order)\n","    data[\"month\"]   = pd.Categorical(data[\"month\"].astype(int), categories = month_order)\n","    data[\"weekday\"] = pd.Categorical(data[\"weekday\"], categories = weekday_order)\n","\n","    season_ohe = pd.get_dummies(data[\"season\"], prefix=\"season\", dtype=\"int8\")\n","    m_ohe  = pd.get_dummies(data[\"month\"],   prefix=\"m\",  dtype=\"int8\")\n","    wd_ohe = pd.get_dummies(data[\"weekday\"], prefix=\"wd\", dtype=\"int8\")\n","\n","    return pd.concat([data, season_ohe, m_ohe, wd_ohe], axis=1)"],"metadata":{"id":"KYPW3fkHn1Zh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_ohe = add_ohe_cols(data)\n","data_ohe.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqFngLeYoRof","executionInfo":{"status":"ok","timestamp":1755327428875,"user_tz":-540,"elapsed":116,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"e6b47a3f-dc57-4c3d-c473-245b1eff8810"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['영업일자', '영업장명_메뉴명', '매출수량', 'year', 'month', 'day', 'weekday',\n","       'weekday_enc', 'season', 'year_enc', 'month_sin', 'month_cos',\n","       'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos', 'is_holiday',\n","       'holiday_name', 'is_sandwich', 'is_holiday_sandwich', 'month_weight',\n","       'week_weight', 'prev_avg_7', 'prev_sd_7', 'prev_avg_14', 'prev_sd_14',\n","       'prev_avg_21', 'prev_sd_21', '영업장명', '메뉴명', 'season_Spring',\n","       'season_Summer', 'season_Autumn', 'season_Winter', 'm_1', 'm_2', 'm_3',\n","       'm_4', 'm_5', 'm_6', 'm_7', 'm_8', 'm_9', 'm_10', 'm_11', 'm_12',\n","       'wd_Monday', 'wd_Tuesday', 'wd_Wednesday', 'wd_Thursday', 'wd_Friday',\n","       'wd_Saturday', 'wd_Sunday'],\n","      dtype='object')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import pickle\n","data_ohe.to_pickle(\"/content/drive/MyDrive/3. Grad School/LG Aimers/DATA/train_data_ohe.pickle\")"],"metadata":{"id":"oTYDWhAmsdOl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":42,"metadata":{"id":"xQk40UmYKn7K","executionInfo":{"status":"ok","timestamp":1755340456997,"user_tz":-540,"elapsed":12,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["cols =  [\"year_enc\", \"month_sin\", \"month_cos\", \"day_sin\", \"day_cos\", \"weekday_sin\", \"weekday_cos\", \"is_holiday\", \"is_sandwich\", \"is_holiday_sandwich\",\n","         \"prev_avg_7\", \"prev_avg_14\", \"prev_avg_21\", \"prev_sd_7\", \"prev_sd_14\", \"prev_sd_21\"]\n","\n","###############\n","season_cols = [f\"season_{s}\" for s in [\"Spring\",\"Summer\",\"Autumn\",\"Winter\"]]\n","m_cols  = [f\"m_{i}\" for i in range(1, 13)]\n","wd_cols = [f\"wd_{d}\" for d in [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]]\n","ohe_cols = season_cols + m_cols + wd_cols\n","\n","cols = cols + ohe_cols\n","###############\n","\n","# lstm에서는 minmaxscaling 해주는 게 안전\n","num_cols = [\"prev_avg_7\", \"prev_avg_14\", \"prev_avg_21\", \"prev_sd_7\", \"prev_sd_14\", \"prev_sd_21\"]"]},{"cell_type":"code","source":["data = data_ohe"],"metadata":{"id":"dvGUzOEisoYz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u9ImcgXgKdEC"},"source":["#### 매출 여부 (분류)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":9363,"status":"ok","timestamp":1755327937998,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"YwyEf8ZCKgIE","outputId":"c80ea530-80b5-40c6-fd30-4df28c3e28bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting category_encoders\n","  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n","Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n","Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: category_encoders\n","Successfully installed category_encoders-2.8.1\n"]}],"source":["from xgboost import XGBClassifier\n","from sklearn.model_selection import TimeSeriesSplit\n","! pip install category_encoders\n","from category_encoders import TargetEncoder\n","from sklearn.metrics import f1_score\n","from typing import Dict, List, Optional, Any\n","from collections import defaultdict\n","import pickle\n","import joblib"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"cBEA6_DYKRXo","executionInfo":{"status":"ok","timestamp":1755340462549,"user_tz":-540,"elapsed":78,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["class ClassificationModel():\n","    def __init__(self, data = None, cols = None, enc_cols = None, model_path = None):\n","        self.data = data\n","        self.cols = cols\n","        self.enc_cols = enc_cols or []\n","\n","    def fit_model_cv(self, data : pd.DataFrame, cols : List[str], enc_cols : List[str] = None) -> pd.DataFrame:\n","        \"\"\"\n","        data - 전체 dataset\n","        cols - 전체 변수들\n","        enc_cols - 인코딩 진행할 변수들 (범주형)\n","        \"\"\"\n","        oof_parts = []\n","        enc_cols = enc_cols or []\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values('영업일자')\n","\n","            # 나중에 oof 저장할 때 사용할 것들\n","            org_idx = group_df.index\n","            oof_proba = np.full(len(group_df), np.nan)\n","\n","            # x, y 분리\n","            x = group_df[cols]\n","            y = group_df[\"매출_여부\"]\n","\n","            # time series split\n","            tscv = TimeSeriesSplit(n_splits = 2)\n","\n","            # 각 split 별로\n","            for fold, (train_idx, val_idx) in enumerate(tscv.split(x)):\n","\n","                x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n","                x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n","\n","                # 수량 전부 0이거나 0 아닌 날 없으면 학습 불가\n","                if y_train.nunique() < 2:\n","                    print(f\"{menu} 학습 불가\")\n","                    continue\n","\n","                if enc_cols:\n","\n","                    # 범주형 변수 인코딩\n","                    target_encoder = TargetEncoder()\n","                    target_encoder.fit(x_train[enc_cols], y_train)\n","\n","                    x_train = pd.concat([\n","                        target_encoder.transform(x_train[enc_cols]),\n","                        x_train[[c for c in cols if c not in enc_cols]]\n","                    ], axis = 1)\n","\n","                    x_val = pd.concat([\n","                        target_encoder.transform(x_val[enc_cols]),\n","                        x_val[[c for c in cols if c not in enc_cols]]\n","                    ], axis = 1)\n","\n","                # 모델 설정 - 불균형 대비\n","                pos = y_train.sum()\n","                neg = len(y_train) - pos\n","                spw = (neg / max(1, pos)) if pos > 0 else 1.0\n","\n","                xgb_model = XGBClassifier(random_state = 1471, scale_pos_weight = spw, max_delta_step = 1, eval_metric = 'aucpr')\n","\n","                # 모델 학습\n","                xgb_model.fit(x_train, y_train)\n","                oof_proba[val_idx] = xgb_model.predict_proba(x_val)[:, 1]\n","\n","            part = pd.DataFrame({\n","                \"index\": org_idx.values,\n","                \"영업장명_메뉴명\": menu,\n","                \"y_true\": group_df[\"매출_여부\"].values,\n","                \"y_proba\": oof_proba\n","            }).set_index(\"index\")\n","\n","            oof_parts.append(part)\n","\n","        oof_df = pd.concat(oof_parts).sort_index()\n","        return oof_df\n","\n","\n","    def tuning_cv(self, data, cols, enc_cols, param_grid):\n","        \"\"\"\n","        메뉴별로 하이퍼파라미터 튜닝 진행 (성능 보고.. 추가 진행? )\n","        \"\"\"\n","        best_params_by_menu = {}\n","\n","        return None\n","\n","\n","    def tune_threshold(self, oof_df : pd.DataFrame, metric = 'f1') -> Dict[str, float]:\n","        \"\"\"\n","        메뉴별로 OOF 데이터프레임을 받아와서\n","        threshold를 최적화\n","        metric으로는 f1 사용\n","        \"\"\"\n","        best_thresholds = {}\n","        all_thresholds = []\n","\n","        for menu, group_df in oof_df.groupby(\"영업장명_메뉴명\"):\n","            # CV 못한 메뉴들 따로\n","            mask = group_df[\"y_proba\"].notna()\n","            if mask.sum() == 0:\n","                best_thresholds[menu] = None\n","                continue\n","\n","            y_true = group_df.loc[mask, \"y_true\"].values\n","            y_proba = group_df.loc[mask, \"y_proba\"].values\n","\n","            # 초기값 진행\n","            best_score, best_thr = -1, 0.5\n","            for thr in np.linspace(0.05, 0.95, 51):\n","                y_pred = (y_proba >= thr).astype(int)\n","                score = f1_score(y_true, y_pred, zero_division = 0)\n","                if score > best_score:\n","                    best_score = score\n","                    best_thr = thr\n","\n","            best_thresholds[menu] = best_thr\n","            all_thresholds.append(best_thr)\n","\n","        global_threshold = np.median(all_thresholds)\n","\n","        for menu, threshold in best_thresholds.items():\n","            if threshold is None:\n","                best_thresholds[menu] = global_threshold\n","\n","        return best_thresholds\n","\n","\n","    def get_final_model(self, data, cols, thresholds, enc_cols = None, hyperparameters_dict = None) -> Dict[str, Dict[str, Any]]:\n","        \"\"\"\n","        메뉴별로 튜닝된 하이퍼파라미터, threshold를 반영하여\n","        최종 모델 적합\n","        \"\"\"\n","        models = {}\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values('영업일자')\n","\n","            # 범주형 변수 처리 - 전체 데이터로\n","            if enc_cols:\n","                target_encoder_full = TargetEncoder()\n","                group_df[enc_cols] = target_encoder_full.fit_transform(group_df[enc_cols], group_df['매출_여부'])\n","\n","            # x, y 분리\n","            x_full = group_df[cols]\n","            y_full = group_df[\"매출_여부\"]\n","\n","            # 하이퍼파라미터\n","            hyperparameters = hyperparameters_dict.get(menu, {}) if hyperparameters_dict else {}\n","\n","            # 모델 설정 - 불균형 대비\n","            pos = int(y_full.sum())\n","            neg = len(y_full) - pos\n","            spw = (neg / max(1, pos)) if pos > 0 else 1.0\n","\n","            xgb_model_full = XGBClassifier(random_state = 1471, scale_pos_weight=spw, max_delta_step = 1, eval_metric = 'aucpr', **hyperparameters)\n","\n","            # 모델 학습\n","            xgb_model_full.fit(x_full, y_full)\n","\n","            models[menu] = {\n","                \"model\" : xgb_model_full,\n","                # \"encoder\" : target_encoder_full,\n","                \"threshold\" : thresholds.get(menu, 0.5)}\n","\n","        return models\n","\n","    def fit_whole_model(self, data, cols, enc_cols = None) -> Dict[str, Dict[str, Any]]:\n","        oof_df = self.fit_model_cv(data, cols, enc_cols)\n","        print(\"CV 완료!\")\n","        thresholds = self.tune_threshold(oof_df)\n","        print(\"threshold 탐색 완료!\")\n","        models = self.get_final_model(data, cols, thresholds, enc_cols)\n","        return models\n","\n","    def save_cls_model(self, models, model_path):\n","        joblib.dump(models, model_path)\n","        print(\"모델 저장 완료!\")\n","\n","    def load_saved_model(self, model_path):\n","        models = joblib.load(model_path)\n","        return models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwQhR-vQO84K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755330030375,"user_tz":-540,"elapsed":72187,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"28e296d0-d6e4-475d-9a6f-a5afc44c6126"},"outputs":[{"output_type":"stream","name":"stdout","text":["담하_(단체) 생목살 김치전골 2.0 학습 불가\n","담하_갱시기 학습 불가\n","담하_꼬막 비빔밥 학습 불가\n","담하_더덕 한우 지짐 학습 불가\n","담하_명인안동소주 학습 불가\n","담하_문막 복분자 칵테일 학습 불가\n","라그로타_AUS (200g) 학습 불가\n","라그로타_그릴드 비프 샐러드 학습 불가\n","라그로타_까르보나라 학습 불가\n","라그로타_모둠 해산물 플래터 학습 불가\n","라그로타_버섯 크림 리조또 학습 불가\n","라그로타_시저 샐러드  학습 불가\n","라그로타_알리오 에 올리오  학습 불가\n","라그로타_양갈비 (4ps) 학습 불가\n","라그로타_한우 (200g) 학습 불가\n","라그로타_해산물 토마토 스튜 파스타 학습 불가\n","미라시아_(오븐) 하와이안 쉬림프 피자 학습 불가\n","미라시아_잭 애플 토닉 학습 불가\n","미라시아_콥 샐러드 학습 불가\n","연회장_공깃밥 학습 불가\n","연회장_마라샹궈 학습 불가\n","연회장_삼겹살추가 (200g) 학습 불가\n","연회장_왕갈비치킨 학습 불가\n","카페테리아_진사골 설렁탕 학습 불가\n","CV 완료!\n","threshold 탐색 완료!\n","모델 저장 완료!\n"]}],"source":["classification = ClassificationModel()\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 8/cls_models.pkl'\n","\n","data_zero = data.copy()\n","data_zero['매출_여부'] = data_zero['매출수량'].apply(lambda x:1 if x > 0 else 0)\n","\n","models = classification.fit_whole_model(data = data_zero, cols = cols, enc_cols = None)\n","classification.save_cls_model(models, model_path)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"qpJeynRUZsjN","executionInfo":{"status":"ok","timestamp":1755340470130,"user_tz":-540,"elapsed":3150,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["# 다시 불러오기\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 8/cls_models.pkl'\n","classification = ClassificationModel()\n","models_class = classification.load_saved_model(model_path)"]},{"cell_type":"markdown","metadata":{"id":"i2wKL_C6P2Bp"},"source":["#### 매출 예측 (회귀)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7PqUIigSomp"},"outputs":[],"source":["from xgboost import XGBRegressor\n","# ! pip install category_encoders\n","from category_encoders import TargetEncoder\n","from sklearn.model_selection import TimeSeriesSplit\n","from collections import defaultdict\n","from itertools import product\n","import pickle\n","import joblib"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"CY881cMBP4Ka","executionInfo":{"status":"ok","timestamp":1755340476361,"user_tz":-540,"elapsed":6,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["class RegressionModel():\n","    def __init__(self, data = None, cols = None, enc_cols = None, model_path = None):\n","        self.data = data\n","        self.cols = cols\n","        self.enc_cols = enc_cols or []\n","\n","    def smape_score(self, y_true, y_pred, eps = 1e-8):\n","        y_true = np.asarray(y_true, dtype=float)\n","        y_pred = np.asarray(y_pred, dtype=float)\n","        denom = np.abs(y_true) + np.abs(y_pred)\n","        denom = np.where(denom < eps, eps, denom)\n","        return 200.0 * np.mean(np.abs(y_true - y_pred) / denom)\n","\n","    def tuning_cv(self, data : pd.DataFrame, cols : List[str], enc_cols : List[str] = None, param_grid = None) -> Dict[str, Dict]:\n","        \"\"\"\n","        메뉴별로 하이퍼파라미터 튜닝 진행\n","        \"\"\"\n","        best_params_by_menu = {}\n","\n","        if param_grid is None:\n","            param_grid = {\n","                \"min_child_weight\" : [1, 5],\n","                \"max_depth\" : [5, 6, 7],\n","                \"subsample\" : [0.7, 0.9],\n","                \"n_estimators\" : [100, 150],\n","                \"learning_rate\" : [0.03, 0.05]}\n","\n","        keys = list(param_grid.keys())\n","        combos = list(product(*[param_grid[k] for k in keys]))\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values(\"영업일자\")\n","\n","            x = group_df[cols]\n","            y = group_df[\"매출수량\"]\n","\n","            # time series split\n","            tscv = TimeSeriesSplit(n_splits = 3)\n","\n","            # 초기값\n","            best_smape = np.inf\n","            best_params = None\n","\n","            for values in combos:\n","                params = dict(zip(keys, values))\n","\n","                base_params = {\"random_state\" : 1478}\n","                base_params.update(params)\n","\n","                fold_smapes : List[float] = []\n","\n","                for fold, (train_idx, val_idx) in enumerate(tscv.split(x)):\n","\n","                    x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n","                    x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n","\n","                    # 데이터 수 적으면 학습 불가\n","                    if len(x_train) < 20:\n","                        print(f\"{menu} 튜닝 불가)\")\n","                        continue\n","\n","                    # 범주형 변수 인코딩\n","                    if enc_cols:\n","                        target_encoder = TargetEncoder()\n","                        target_encoder.fit(x_train[enc_cols], y_train)\n","\n","                        x_train = pd.concat([\n","                            target_encoder.transform(x_train[enc_cols]),\n","                            x_train[[c for c in cols if c not in enc_cols]]\n","                        ], axis = 1)\n","\n","                        x_val = pd.concat([\n","                            target_encoder.transform(x_val[enc_cols]),\n","                            x_val[[c for c in cols if c not in enc_cols]]\n","                        ], axis = 1)\n","\n","                    # 모델 설정\n","                    xgb_model = XGBRegressor(**base_params)\n","\n","                    # 모델 학습\n","                    xgb_model.fit(x_train, y_train)\n","\n","                    pred = xgb_model.predict(x_val)\n","                    smape = self.smape_score(y_val, pred)\n","                    fold_smapes.append(smape)\n","\n","                mean_smape = float(np.mean(fold_smapes))\n","\n","                if mean_smape < best_smape:\n","                    best_smape = mean_smape\n","                    best_params = base_params\n","\n","            if best_params is not None:\n","                best_params_by_menu[menu] = best_params\n","\n","        return best_params_by_menu\n","\n","\n","    def get_final_model(self, data, cols, enc_cols, hyperparameters_dict : dict[str, dict[str, Any]] = None)  -> Dict[str, Dict[str, Any]]:\n","        \"\"\"\n","        data, validation_reg - train, validation dataset\n","        cols - 전체 변수들\n","        enc_cols - 인코딩 진행할 변수들 (범주형)\n","        \"\"\"\n","        models = {}\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values(\"영업일자\")\n","\n","            # 데이터 수 적으면 학습 불가\n","            if len(group_df) < 10:\n","                print(f\"{menu} 학습 불가\")\n","                continue\n","\n","            # 범주형 변수 처리\n","            if enc_cols:\n","                target_encoder_full = TargetEncoder()\n","                group_df[enc_cols] = target_encoder_full.fit_transform(group_df[enc_cols], group_df['매출수량'])\n","\n","            # x, y 분리\n","            x_full = group_df[cols]\n","            y_full = group_df[\"매출수량\"]\n","\n","            # 하이퍼파라미터 불러오기\n","            params = hyperparameters_dict.get(menu, {}) if hyperparameters_dict else {}\n","\n","            base_params = {\"random_state\" : 1478}\n","            base_params.update(params)\n","\n","            # 모델 설정\n","            xgb_model_full = XGBRegressor(**base_params)\n","\n","            # 모델 학습\n","            xgb_model_full.fit(x_full, y_full)\n","\n","            models[menu] = {\n","                \"model\" : xgb_model_full,\n","                \"hyperparameters\" : base_params,\n","                # \"encoder\" : target_encoder_full\n","            }\n","\n","        return models\n","\n","    def fit_whole_model(self, data, cols, enc_cols = None) -> Dict[str, Dict[str, Any]]:\n","        best_params_by_menu = self.tuning_cv(data, cols, enc_cols)\n","        print(\"튜닝 완료!\")\n","        models = self.get_final_model(data, cols, enc_cols, best_params_by_menu)\n","        return models\n","\n","    def save_reg_model(self, models, model_path):\n","        joblib.dump(models, model_path)\n","        print(\"모델 저장 완료!\")\n","\n","    def load_saved_model(self, model_path):\n","        models = joblib.load(model_path)\n","        return models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3323471,"status":"ok","timestamp":1755333442911,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"2oFlYQvtTIwS","outputId":"4ed35471-47c8-4f58-aa76-c411e45b1e97"},"outputs":[{"output_type":"stream","name":"stdout","text":["튜닝 완료!\n","모델 저장 완료!\n"]}],"source":["regression = RegressionModel()\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 8/reg_models.pkl'\n","\n","data_notzero = data[data['매출수량'] > 0]\n","\n","models = regression.fit_whole_model(data = data_notzero, cols = cols, enc_cols = None)\n","regression.save_reg_model(models, model_path)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"Ev79J1ENbN19","executionInfo":{"status":"ok","timestamp":1755340484489,"user_tz":-540,"elapsed":4417,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["# 다시 불러오기\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 8/reg_models.pkl'\n","regression = RegressionModel()\n","models_reg = regression.load_saved_model(model_path)"]},{"cell_type":"markdown","metadata":{"id":"0d2L76egP4Yi"},"source":["#### 매출 예측 (시계열)"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"iBR9gHpRP50T","executionInfo":{"status":"ok","timestamp":1755340501079,"user_tz":-540,"elapsed":8015,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import TimeSeriesSplit\n","import random\n","import glob\n","import joblib\n","\n","import torch\n","import torch.nn as nn\n","from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if device.type == \"cuda\": torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"ZXjwjBNVTvWB","executionInfo":{"status":"ok","timestamp":1755340501165,"user_tz":-540,"elapsed":84,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["### Random Seed & Parameters\n","def set_seed(seed = 1471):\n","    random.seed(seed) # 일반 seed\n","    np.random.seed(seed) # numpy 난수 고정\n","    torch.manual_seed(seed) # CPU 난수 고정\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_seed(1478)"]},{"cell_type":"markdown","source":["##### Loss Functions"],"metadata":{"id":"Qbp0yN6WBSq5"}},{"cell_type":"code","execution_count":49,"metadata":{"id":"GznnD4qlTz0r","executionInfo":{"status":"ok","timestamp":1755340501194,"user_tz":-540,"elapsed":5,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["# weight 직접 입력해서 반영 가능\n","class WeightedSMAPELoss(nn.Module):\n","    def __init__(self, eps=1e-8):\n","        super().__init__()\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true, w=None):\n","        num = (y_pred - y_true).abs()\n","        den = (y_pred.abs() + y_true.abs()).clamp(min=self.eps)\n","        smape = 2.0 * num / (den)\n","\n","        mask = (y_true != 0).float()\n","        if w is None:\n","            w = torch.ones_like(y_true)\n","        else:\n","            if w.dim() == 1:\n","                w = w.view(-1, 1)\n","            w = w.expand_as(y_true)\n","\n","        w_mask = w * mask\n","        denom = w_mask.sum().clamp(min=self.eps)\n","        loss = (smape * w_mask).sum() / denom\n","        return loss\n","\n","# weighted huberLoss\n","class WeightedHuberLoss(nn.Module):\n","    def __init__(self, delta = 1.0, zeros : bool = False, eps = 1e-8):\n","        \"\"\"\n","        delta -L2 -> L1로 전환되는 임계값\n","        zeros - y_true = 0인 샘플 제외할지 여부\n","        eps - 분모가 0이 되는 것을 방지하기 위한 작은 값\n","        \"\"\"\n","        super().__init__()\n","        self.delta = float(delta)\n","        self.zeros = bool(zeros)\n","        self.eps = float(eps)\n","\n","    def forward(self, y_pred, y_true, w = None):\n","        \"\"\"\n","        w -  (N, ) 형태로 된 가중치\n","        \"\"\"\n","        error = y_pred - y_true\n","        abs_error = error.abs()\n","        huber = torch.where(\n","            abs_error <= self.delta,\n","            0.5 * error**2,\n","            self.delta * (abs_error - 0.5 * self.delta),\n","        )\n","\n","        if self.zeros:\n","            mask = (y_true != 0).float()\n","        else:\n","            mask = torch.ones_like(y_true)\n","\n","        if w is None:\n","            w_full = torch.ones_like(y_true)\n","        else:\n","            if w.dim() == 1:\n","                w = w.view(-1, 1) # (N, 1)로 확장\n","            w_full = w.expand_as(y_true).float()\n","\n","        w_mask = w_full * mask\n","        denom = w_mask.sum().clamp(min=self.eps)\n","        return (huber * w_mask).sum() / denom\n","\n","# SMAPE + Huber Loss\n","class CombinationLoss(nn.Module):\n","    def __init__(self, losses, weights):\n","        \"\"\"\n","        losses - 결합할 손실 리스트\n","        weights - 각 손실의 가중치 리스트\n","        \"\"\"\n","        super().__init__()\n","        if not losses or len(losses) != len(weights):\n","            raise ValueError(\"loss 배열과 weight 배열의 길이가 다릅니다.\")\n","        self.losses = nn.ModuleList(losses)\n","\n","        weight_tensor = torch.tensor(weights, dtype=torch.float32)\n","        self.weights = weight_tensor / weight_tensor.sum()\n","\n","    def forward(self, y_pred, y_true, w = None):\n","        \"\"\"\n","        w - 공통 가중치\n","        \"\"\"\n","        total_loss = 0.0\n","        device_weights = self.weights.to(y_pred.device)\n","        for i, lf in enumerate(self.losses):\n","            loss = lf(y_pred, y_true, w)\n","            total_loss += device_weights[i] * loss\n","        return total_loss"]},{"cell_type":"code","source":["def build_menu_weights(\n","    df: pd.DataFrame,\n","    menu_key: str = \"영업장명_메뉴명\",\n","    target_col: str = \"매출수량\",\n","    dispersion: str = \"p95-p5\",   # \"range\" | \"iqr\" | \"std\" | \"p95-p5\"\n","    alpha: float = 1.0,            # 민감도 (↑ 크면 가중치 차이 커짐)\n","    clip: tuple = (0.25, 4.0),     # 과도한 비율 방지\n","    eps: float = 1e-6\n",") -> dict:\n","    \"\"\"\n","    메뉴별 난이도(분산/범위) 기반 가중치 (간극 ↑ -> 가중치 ↑)\n","    반환: {menu_key -> weight}\n","    \"\"\"\n","    disp_vals = {}\n","    for k, g in df.groupby(menu_key):\n","        y = g[target_col].to_numpy()\n","        if len(y) == 0:\n","            disp = 0.0\n","        else:\n","            if dispersion == \"range\":\n","                disp = float(np.max(y) - np.min(y))\n","            elif dispersion == \"iqr\":\n","                q75, q25 = np.percentile(y, [75, 25])\n","                disp = float(q75 - q25)\n","            elif dispersion == \"std\":\n","                disp = float(np.std(y))\n","            else:  # \"p95-p5\"\n","                q95, q5 = np.percentile(y, [95, 5])\n","                disp = float(q95 - q5)\n","        disp_vals[k] = disp\n","\n","    # 분포 → 가중치 (단조증가), 평균 1로 정규화\n","    disp_series = pd.Series(disp_vals)\n","    # 0도 있을 수 있으니 +eps, 로그스케일 쓰고 싶으면 바꿔도 됨\n","    raw_w = (disp_series + eps) ** alpha\n","    w = raw_w / raw_w.mean()\n","\n","    # 과도한 값 클램프 (옵션)\n","    w = w.clip(lower=clip[0], upper=clip[1])\n","    return w.to_dict()\n","\n","def build_store_weights(\n","    df: pd.DataFrame,\n","    store_col: str = \"영업장명\",\n","    menu_col: str = \"메뉴명\",      # 없으면 아래에서 자동 fallback\n","    combined_key: str = \"영업장명_메뉴명\",\n","    beta: float = 1.0,             # 메뉴 가짓수 민감도\n","    clip: tuple = (0.5, 3.0)\n",") -> dict:\n","    \"\"\"\n","    음식점별 메뉴 가짓수 기반 가중치 (가짓수 ↑ -> 가중치 ↑)\n","    반환: {store -> weight}\n","    \"\"\"\n","    if (store_col in df.columns) and (menu_col in df.columns):\n","        n_menu = df.groupby(store_col)[menu_col].nunique()\n","    else:\n","        # fallback: combined_key에서 store를 추출 (최초 '_' 기준 split)\n","        def get_store(x: str) -> str:\n","            # 필요하면 사용자 규칙에 맞게 수정\n","            return str(x).split(\"_\", 1)[0]\n","        tmp = df[[combined_key]].copy()\n","        tmp[store_col] = tmp[combined_key].astype(str).map(get_store)\n","        # store별 unique combined_key 개수 = 메뉴 가짓수로 근사\n","        n_menu = tmp.groupby(store_col)[combined_key].nunique()\n","\n","    raw_w = (n_menu.astype(float) + 1e-6) ** beta\n","    w = raw_w / raw_w.mean()\n","    w = w.clip(lower=clip[0], upper=clip[1])\n","    return w.to_dict()"],"metadata":{"id":"V4LzzOZ4RAaS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### LSTMModel"],"metadata":{"id":"e3d0i4MHBU4x"}},{"cell_type":"code","execution_count":50,"metadata":{"id":"F1brZnPwP96i","executionInfo":{"status":"ok","timestamp":1755340501196,"user_tz":-540,"elapsed":4,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["class MultiOutputLSTM(nn.Module):\n","        def __init__(self, input_dim = 1, hidden_dim = 256, num_layers = 4, output_dim = 7, dropout = 0.4):\n","            \"\"\" 7개 값 예측 (PREDICT 만큼의 날짜의 값을 예측하고자 함)\"\"\"\n","            super(MultiOutputLSTM, self).__init__()\n","            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first = True, dropout = dropout)\n","            self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        def forward(self, x):\n","            out, _ = self.lstm(x)\n","            return self.fc(out[:, -1, :]) # 마지막 시점 출력만 선택해서 fc에 넣음 -> (batch * output_dim)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"G6J9ebzOPnOM","executionInfo":{"status":"ok","timestamp":1755340501312,"user_tz":-540,"elapsed":116,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["class LSTMModel():\n","    def __init__(self, data = None, cols = None, enc_cols = None, num_cols = None, scaler = None,\n","                 lookback = 28, predict = 7, hidden_dim = 256, num_layers = 4, device = \"cuda\", epochs = 200, batch_size = 16, dropout = 0.4,\n","                 delta = 0.1, val_ratio = 0.2, horizon_weight_mode = \"linear\",\n","                 lr = 0.04, losses = None, loss_weights = [0.5, 0.5], menu_weights = None):\n","        self.data = data\n","        self.cols = cols\n","        self.enc_cols = enc_cols\n","        self.scaler = scaler\n","\n","        self.lookback = lookback\n","        self.predict = predict\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.device = torch.device(device)\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.dropout = dropout\n","\n","        self.delta = delta\n","        self.val_ratio = val_ratio\n","        self.horizon_weight_mode = horizon_weight_mode\n","        self.lr = float(lr)\n","        self.losses = losses\n","        self.loss_weights = loss_weights\n","        self.menu_weights = menu_weights\n","\n","    # enc_cols는 LabelEncoding\n","    def label_encoding_lstm(self, data, enc_cols = None):\n","        encoders = {}\n","        if enc_cols:\n","            for col in enc_cols:\n","                if data[col].dtype == 'object' or data[col].dtype.name == 'bool' or data[col].dtype.name == 'category':\n","                    le = LabelEncoder()\n","                    data[col] = le.fit_transform(data[col])\n","                    encoders[col] = le\n","            return data, encoders\n","\n","    def minmax_scaling_features(self, data, num_cols):\n","        scaler = MinMaxScaler()\n","        data[num_cols] = scaler.fit_transform(data[num_cols])\n","        return data, scaler\n","\n","    # 매출수량은 MinMaxScaling\n","    def minmax_scaling_target(self, data):\n","        scaler = MinMaxScaler()\n","        data['매출수량'] = scaler.fit_transform(data[['매출수량']])\n","        return data, scaler\n","\n","    def build_horizon_weights(self, predict = 7):\n","        \"\"\"\n","        수평선(예측일) 가중치 벡터 생성.\n","        - 'linear': 1..predict 선형 가중 후 정규화\n","        - 'uniform': 동일 가중\n","        \"\"\"\n","        if self.horizon_weight_mode == \"uniform\":\n","            w = torch.ones(predict)\n","        else:\n","            # 기본: 뒤쪽일수록 더 큰 가중\n","            w = torch.arange(1, predict + 1).float()\n","        w = w / w.sum()\n","        return w\n","\n","    def compute_smape(self, y_pred, y_true, eps=1e-8):\n","        \"\"\"정규화 스케일에서의 SMAPE( y_true==0 은 마스킹 )\"\"\"\n","        num = (y_pred - y_true).abs()\n","        den = (y_pred.abs() + y_true.abs()).clamp(min=eps)\n","        smape = 2.0 * num / den\n","        mask = (y_true != 0).float()\n","        denom = mask.sum().clamp(min=eps)\n","        return (smape * mask).sum().item() / denom.item()\n","\n","    def _tss_last_split_indices(self, n_samples: int, n_splits: int = 3):\n","        \"\"\"\n","        마지막 TimeSeriesSplit fold의 (train_idx, val_idx)만 반환.\n","        누수 방지를 위해 gap = lookback + predict - 1 권장.\n","        \"\"\"\n","        idx = np.arange(n_samples)\n","        tscv = TimeSeriesSplit(n_splits=n_splits, gap=self.lookback + self.predict - 1)\n","        tr_idx, va_idx = None, None\n","        for tr, va in tscv.split(idx):\n","            tr_idx, va_idx = tr, va\n","        return tr_idx, va_idx\n","\n","    def _make_windows(self, x: np.ndarray, y: np.ndarray):\n","        \"\"\"\n","        구간 내부에서만 윈도우 생성 (누수 없음)\n","        x: (T, F), y: (T,)\n","        return: x:(N, lookback, F), y:(N, predict) or (None, None)\n","        \"\"\"\n","        T = len(x)\n","        xs, ys = [], []\n","        for i in range(T - self.lookback - self.predict + 1):\n","            xs.append(x[i:i+self.lookback])\n","            ys.append(y[i+self.lookback:i+self.lookback+self.predict])\n","        if not xs:\n","            return None, None\n","        return np.stack(xs).astype(np.float32), np.stack(ys).astype(np.float32)\n","\n","#############################################################################\n","    def train_lstm(self, train_df, cols, enc_cols, num_cols,\n","                   device, epochs, batch_size, lr, dropout,\n","                   losses, loss_weights,\n","                   n_splits : int = 3, print_every = 50):\n","        \"\"\"\n","        영업장, 메뉴별로 LSTM 모델 훈련, 각각을 trained_models에 저장\n","        Loss - CombinationLoss([WeightedSMAPELoss(), WeightedHuberLoss()], [0.5, 0.5]\n","        \"\"\"\n","        trained_models = {}\n","        horizon_w = self.build_horizon_weights(self.predict).to(device)\n","\n","        # Loss 구성\n","        comb_loss = CombinationLoss(losses = losses, weights = loss_weights).to(device)\n","\n","        # store_menu : 영업장명_메뉴명 / group : 나머지 데이터\n","        for store_menu, group in tqdm(train_df.groupby([\"영업장명_메뉴명\"]), desc = \"Training LSTM\"):\n","\n","            # 날짜 순으로 정렬해서 데이터가 너무 적으면 -> 학습 생략\n","            store_train = group.sort_values(\"영업일자\").copy()\n","            if len(store_train) < self.lookback + self.predict:\n","                continue\n","\n","            # ===== TimeSeriesSplit: 마지막 폴드를 검증으로 사용 =====\n","            tr_idx, va_idx = self._tss_last_split_indices(len(store_train), n_splits=n_splits)\n","            df_tr = store_train.iloc[tr_idx].copy()\n","            df_va = store_train.iloc[va_idx].copy()\n","\n","            # ===== 인코더/스케일러는 train(df_tr)에만 fit, df_tr/df_va에 transform (누수 방지) =====\n","            encoders = {}\n","            if enc_cols:\n","                for c in enc_cols:\n","                    le = LabelEncoder()\n","                    df_tr[c] = le.fit_transform(df_tr[c].astype(str))\n","                    # val에서 미지 카테고리 안전 처리\n","                    cls2idx = {cls: i for i, cls in enumerate(le.classes_)}\n","                    df_va[c] = df_va[c].astype(str).map(lambda v: cls2idx.get(v, -1))\n","                    encoders[c] = le\n","\n","            features_scaler = None\n","            if num_cols:\n","                features_scaler = MinMaxScaler()\n","                df_tr[num_cols] = features_scaler.fit_transform(df_tr[num_cols])\n","                df_va[num_cols] = features_scaler.transform(df_va[num_cols])\n","\n","            target_scaler = MinMaxScaler()\n","            df_tr[['매출수량']] = target_scaler.fit_transform(df_tr[['매출수량']])\n","            df_va[['매출수량']] = target_scaler.transform(df_va[['매출수량']])\n","\n","            # ===== 원시 배열 =====\n","            X_tr = df_tr[cols].to_numpy(dtype=np.float32)\n","            y_tr = df_tr['매출수량'].to_numpy(dtype=np.float32)\n","            X_va = df_va[cols].to_numpy(dtype=np.float32)\n","            y_va = df_va['매출수량'].to_numpy(dtype=np.float32)\n","\n","            # ===== 세그먼트 내부에서만 윈도우 생성 (경계 누수 없음) =====\n","            x_tr_np, y_tr_np = self._make_windows(X_tr, y_tr)\n","            x_va_np, y_va_np = self._make_windows(X_va, y_va)\n","            if x_tr_np is None or x_va_np is None:\n","                continue\n","\n","            # 텐서 이동\n","            x_train = torch.tensor(x_tr_np).to(device)         # (N_tr, lookback, F)\n","            y_train = torch.tensor(y_tr_np).to(device)         # (N_tr, predict)\n","            x_val   = torch.tensor(x_va_np).to(device)\n","            y_val   = torch.tensor(y_va_np).to(device)\n","\n","            # 모델 초기화 (영업장_메뉴별로 다른 모델)\n","            model = MultiOutputLSTM(input_dim = len(cols),\n","                                    hidden_dim = self.hidden_dim,\n","                                    num_layers = self.num_layers,\n","                                    output_dim = self.predict,\n","                                    dropout = dropout).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n","            best_val = float(\"inf\")\n","            best_sd = None\n","            best_epoch = -1\n","\n","            # 학습 모드로 설정\n","            model.train()\n","\n","            # epochs 만큼 훈련\n","            for epoch in range(1, epochs + 1):\n","                model.train(True)\n","                perm = torch.randperm(len(x_train), device = device)\n","                epoch_train_loss = 0.0\n","                total_train_count = 0\n","\n","                # idx : 랜덤하게 섞인 index들\n","                for i in range(0, len(x_train), batch_size):\n","                    batch_idx = perm[i : i+batch_size] # 배치 개수만큼 끊어서\n","                    x_batch, y_batch = x_train[batch_idx], y_train[batch_idx] # 배치 데이터 할당\n","\n","                    weight_mat = horizon_w.unsqueeze(0).repeat(y_batch.size(0), 1)\n","\n","                    output = model(x_batch) # 모델 태워서\n","                    loss = comb_loss(output, y_batch, w = weight_mat) # 평가하고\n","\n","                    optimizer.zero_grad() # 역전파를 위한 초기화\n","                    loss.backward() # 역전파\n","                    optimizer.step() # 최적화\n","\n","                    epoch_train_loss += loss.item() * y_batch.size(0)\n","                    total_train_count += y_batch.size(0)\n","\n","                epoch_train_loss /= max(1, total_train_count)\n","\n","                ### Validation\n","                with torch.no_grad():\n","                    model.eval()\n","                    pred_val = model(x_val)\n","                    weight_val = horizon_w.unsqueeze(0).repeat(y_val.size(0), 1)\n","                    val_loss = comb_loss(pred_val, y_val, w = weight_val).item()\n","                    val_smape = self.compute_smape(pred_val, y_val)\n","\n","                    if epoch % 50 == 0:\n","                        print(f\"\\n[{store_menu}] Epoch {epoch} ==============================\\n \"\n","                            f\"Train Loss {epoch_train_loss:.5f} | Val Loss {val_loss:.5f} | SMAPE {val_smape:.5f}\")\n","\n","                    if val_loss < best_val - 1e-6:\n","                        best_val = val_loss\n","                        best_sd = {k : v.detach().cpu().clone() for k, v in model.state_dict().items()}\n","                        best_epoch = epoch\n","\n","                model.train(True)\n","\n","\n","            if best_sd is not None:\n","                model.load_state_dict(best_sd)\n","\n","            # 모델 저장\n","            trained_models[store_menu] = {\n","                'model': model.state_dict(),\n","                # 'encoders' : encoders,\n","                'features_scaler' : features_scaler,\n","                'target_scaler': target_scaler,\n","                'meta' : {\n","                    'input_dim': len(cols),\n","                    'hidden_dim': self.hidden_dim,\n","                    'num_layers': self.num_layers,\n","                    'output_dim': self.predict,\n","                    'dropout' : self.dropout\n","                }\n","                }\n","\n","        return trained_models\n","\n","    def save_lstm_model_gpu(self, models, model_path):\n","        joblib.dump(models, model_path)\n","        print(\"GPU 버전 모델 저장 완료!\")\n","\n","    def save_lstm_model_cpu(self, models, model_path):\n","        cpu_models = {}\n","        for k, bundle in models.items():\n","            cpu_models[k] = {\n","            'model': {kk: vv.cpu() for kk, vv in bundle['model'].items()},  # 모델만 CPU로\n","            # 'encoders': bundle['encoders'],\n","            'features_scaler': bundle['features_scaler'],\n","            'target_scaler': bundle['target_scaler'],\n","            'meta' : bundle['meta']\n","        }\n","        joblib.dump(cpu_models, model_path)\n","        print(\"CPU 버전 모델 저장 완료!\")\n","\n","    def load_saved_model(self, model_path):\n","        models = joblib.load(model_path)\n","        return models"]},{"cell_type":"markdown","source":["##### Train"],"metadata":{"id":"uup-wSWOBYEA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20ZWwzy0UpQP","collapsed":true,"outputId":"0f68097f-5c08-4bd6-978e-73a6efc4005d","executionInfo":{"status":"ok","timestamp":1755282891215,"user_tz":-540,"elapsed":4017062,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   0%|          | 0/193 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 50 ==============================\n"," Train Loss 0.20157 | Val Loss 0.36097 | SMAPE 0.70360\n","\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 100 ==============================\n"," Train Loss 0.15947 | Val Loss 0.36834 | SMAPE 0.72988\n","\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 150 ==============================\n"," Train Loss 0.10027 | Val Loss 0.34908 | SMAPE 0.67813\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   1%|          | 1/193 [00:21<1:09:18, 21.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 200 ==============================\n"," Train Loss 0.07661 | Val Loss 0.35232 | SMAPE 0.69164\n","\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 50 ==============================\n"," Train Loss 0.16365 | Val Loss 0.29542 | SMAPE 0.57905\n","\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 100 ==============================\n"," Train Loss 0.10423 | Val Loss 0.29348 | SMAPE 0.57285\n","\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 150 ==============================\n"," Train Loss 0.07261 | Val Loss 0.30733 | SMAPE 0.59615\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   1%|          | 2/193 [00:48<1:18:35, 24.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 200 ==============================\n"," Train Loss 0.06287 | Val Loss 0.29537 | SMAPE 0.57962\n","\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 50 ==============================\n"," Train Loss 0.14862 | Val Loss 0.30516 | SMAPE 0.57383\n","\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 100 ==============================\n"," Train Loss 0.10365 | Val Loss 0.31524 | SMAPE 0.59194\n","\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 150 ==============================\n"," Train Loss 0.08006 | Val Loss 0.29226 | SMAPE 0.55236\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   2%|▏         | 3/193 [01:09<1:12:41, 22.95s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 200 ==============================\n"," Train Loss 0.05946 | Val Loss 0.29383 | SMAPE 0.55119\n","\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 50 ==============================\n"," Train Loss 0.15050 | Val Loss 0.32319 | SMAPE 0.61328\n","\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 100 ==============================\n"," Train Loss 0.09723 | Val Loss 0.31943 | SMAPE 0.60555\n","\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 150 ==============================\n"," Train Loss 0.07978 | Val Loss 0.30646 | SMAPE 0.57643\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   2%|▏         | 4/193 [01:30<1:09:47, 22.16s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 200 ==============================\n"," Train Loss 0.06420 | Val Loss 0.31154 | SMAPE 0.58664\n","\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 50 ==============================\n"," Train Loss 0.10000 | Val Loss 0.22002 | SMAPE 0.39269\n","\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 100 ==============================\n"," Train Loss 0.04859 | Val Loss 0.20014 | SMAPE 0.36372\n","\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 150 ==============================\n"," Train Loss 0.03503 | Val Loss 0.18769 | SMAPE 0.34339\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   3%|▎         | 5/193 [01:51<1:08:09, 21.76s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 200 ==============================\n"," Train Loss 0.03043 | Val Loss 0.19556 | SMAPE 0.36173\n","\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 50 ==============================\n"," Train Loss 0.13203 | Val Loss 0.36068 | SMAPE 0.70536\n","\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 100 ==============================\n"," Train Loss 0.08090 | Val Loss 0.36146 | SMAPE 0.71847\n","\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 150 ==============================\n"," Train Loss 0.07175 | Val Loss 0.35919 | SMAPE 0.71109\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   3%|▎         | 6/193 [02:15<1:09:51, 22.41s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 200 ==============================\n"," Train Loss 0.05535 | Val Loss 0.34463 | SMAPE 0.67958\n","\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 50 ==============================\n"," Train Loss 0.22965 | Val Loss 0.40237 | SMAPE 0.79405\n","\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 100 ==============================\n"," Train Loss 0.17731 | Val Loss 0.39618 | SMAPE 0.78081\n","\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 150 ==============================\n"," Train Loss 0.12939 | Val Loss 0.42152 | SMAPE 0.83241\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   4%|▎         | 7/193 [02:35<1:07:42, 21.84s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 200 ==============================\n"," Train Loss 0.11285 | Val Loss 0.42110 | SMAPE 0.82652\n","\n","[('느티나무 셀프BBQ_신라면',)] Epoch 50 ==============================\n"," Train Loss 0.20912 | Val Loss 0.38025 | SMAPE 0.75384\n","\n","[('느티나무 셀프BBQ_신라면',)] Epoch 100 ==============================\n"," Train Loss 0.15961 | Val Loss 0.39005 | SMAPE 0.76147\n","\n","[('느티나무 셀프BBQ_신라면',)] Epoch 150 ==============================\n"," Train Loss 0.11540 | Val Loss 0.37841 | SMAPE 0.75693\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   4%|▍         | 8/193 [02:56<1:06:19, 21.51s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_신라면',)] Epoch 200 ==============================\n"," Train Loss 0.08036 | Val Loss 0.38235 | SMAPE 0.75392\n","\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 50 ==============================\n"," Train Loss 0.19421 | Val Loss 0.37683 | SMAPE 0.69791\n","\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 100 ==============================\n"," Train Loss 0.12293 | Val Loss 0.39545 | SMAPE 0.73430\n","\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 150 ==============================\n"," Train Loss 0.07795 | Val Loss 0.39069 | SMAPE 0.73024\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   5%|▍         | 9/193 [03:16<1:04:54, 21.16s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 200 ==============================\n"," Train Loss 0.06386 | Val Loss 0.38945 | SMAPE 0.72368\n","\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 50 ==============================\n"," Train Loss 0.08789 | Val Loss 0.25120 | SMAPE 0.46781\n","\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 100 ==============================\n"," Train Loss 0.06029 | Val Loss 0.32718 | SMAPE 0.61805\n","\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 150 ==============================\n"," Train Loss 0.05032 | Val Loss 0.35606 | SMAPE 0.66326\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   5%|▌         | 10/193 [03:37<1:04:08, 21.03s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 200 ==============================\n"," Train Loss 0.03962 | Val Loss 0.38519 | SMAPE 0.72948\n","\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 50 ==============================\n"," Train Loss 0.17326 | Val Loss 0.35064 | SMAPE 0.70711\n","\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 100 ==============================\n"," Train Loss 0.11748 | Val Loss 0.35892 | SMAPE 0.71214\n","\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 150 ==============================\n"," Train Loss 0.09926 | Val Loss 0.36784 | SMAPE 0.72625\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   6%|▌         | 11/193 [03:58<1:03:56, 21.08s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 200 ==============================\n"," Train Loss 0.08486 | Val Loss 0.38402 | SMAPE 0.75618\n","\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 50 ==============================\n"," Train Loss 0.09606 | Val Loss 0.19160 | SMAPE 0.35253\n","\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 100 ==============================\n"," Train Loss 0.06985 | Val Loss 0.21731 | SMAPE 0.42002\n","\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 150 ==============================\n"," Train Loss 0.05036 | Val Loss 0.20873 | SMAPE 0.41174\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   6%|▌         | 12/193 [04:19<1:03:12, 20.95s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 200 ==============================\n"," Train Loss 0.04346 | Val Loss 0.19453 | SMAPE 0.37549\n","\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 50 ==============================\n"," Train Loss 0.14154 | Val Loss 0.20673 | SMAPE 0.39450\n","\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 100 ==============================\n"," Train Loss 0.10209 | Val Loss 0.26656 | SMAPE 0.49969\n","\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 150 ==============================\n"," Train Loss 0.05523 | Val Loss 0.25177 | SMAPE 0.47783\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   7%|▋         | 13/193 [04:40<1:02:52, 20.96s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 200 ==============================\n"," Train Loss 0.04207 | Val Loss 0.25615 | SMAPE 0.49253\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 50 ==============================\n"," Train Loss 0.20618 | Val Loss 0.23866 | SMAPE 0.47452\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 100 ==============================\n"," Train Loss 0.15635 | Val Loss 0.22852 | SMAPE 0.44334\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 150 ==============================\n"," Train Loss 0.11140 | Val Loss 0.24351 | SMAPE 0.48646\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   7%|▋         | 14/193 [05:00<1:02:07, 20.82s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 200 ==============================\n"," Train Loss 0.07522 | Val Loss 0.23142 | SMAPE 0.46008\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 50 ==============================\n"," Train Loss 0.18567 | Val Loss 0.27844 | SMAPE 0.54178\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 100 ==============================\n"," Train Loss 0.13039 | Val Loss 0.28849 | SMAPE 0.56802\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 150 ==============================\n"," Train Loss 0.11074 | Val Loss 0.29274 | SMAPE 0.58204\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   8%|▊         | 15/193 [05:21<1:01:25, 20.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 200 ==============================\n"," Train Loss 0.10059 | Val Loss 0.29603 | SMAPE 0.58448\n","\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 50 ==============================\n"," Train Loss 0.18202 | Val Loss 0.34741 | SMAPE 0.67189\n","\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 100 ==============================\n"," Train Loss 0.13279 | Val Loss 0.36522 | SMAPE 0.71937\n","\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 150 ==============================\n"," Train Loss 0.09225 | Val Loss 0.34997 | SMAPE 0.68242\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   8%|▊         | 16/193 [05:44<1:03:11, 21.42s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 200 ==============================\n"," Train Loss 0.07129 | Val Loss 0.36614 | SMAPE 0.71498\n","\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 50 ==============================\n"," Train Loss 0.27084 | Val Loss 0.36066 | SMAPE 0.71691\n","\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 100 ==============================\n"," Train Loss 0.23288 | Val Loss 0.37077 | SMAPE 0.73244\n","\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 150 ==============================\n"," Train Loss 0.17109 | Val Loss 0.37137 | SMAPE 0.74297\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   9%|▉         | 17/193 [06:05<1:02:40, 21.37s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 200 ==============================\n"," Train Loss 0.12203 | Val Loss 0.36995 | SMAPE 0.74344\n","\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 50 ==============================\n"," Train Loss 0.10462 | Val Loss 0.23342 | SMAPE 0.44560\n","\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 100 ==============================\n"," Train Loss 0.07932 | Val Loss 0.21420 | SMAPE 0.41275\n","\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 150 ==============================\n"," Train Loss 0.05372 | Val Loss 0.21124 | SMAPE 0.41246\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   9%|▉         | 18/193 [06:26<1:01:30, 21.09s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 200 ==============================\n"," Train Loss 0.03508 | Val Loss 0.20028 | SMAPE 0.38827\n","\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 50 ==============================\n"," Train Loss 0.13145 | Val Loss 0.23902 | SMAPE 0.45278\n","\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 100 ==============================\n"," Train Loss 0.08705 | Val Loss 0.23271 | SMAPE 0.44992\n","\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 150 ==============================\n"," Train Loss 0.06505 | Val Loss 0.22699 | SMAPE 0.44183\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  10%|▉         | 19/193 [06:47<1:01:15, 21.12s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 200 ==============================\n"," Train Loss 0.04568 | Val Loss 0.23582 | SMAPE 0.45956\n","\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 50 ==============================\n"," Train Loss 0.21951 | Val Loss 0.39156 | SMAPE 0.78546\n","\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 100 ==============================\n"," Train Loss 0.17142 | Val Loss 0.35390 | SMAPE 0.70338\n","\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 150 ==============================\n"," Train Loss 0.12706 | Val Loss 0.34843 | SMAPE 0.68642\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  10%|█         | 20/193 [07:06<59:37, 20.68s/it]  "]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 200 ==============================\n"," Train Loss 0.08444 | Val Loss 0.34395 | SMAPE 0.67920\n","\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 50 ==============================\n"," Train Loss 0.21227 | Val Loss 0.39239 | SMAPE 0.77513\n","\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 100 ==============================\n"," Train Loss 0.15460 | Val Loss 0.44299 | SMAPE 0.85462\n","\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 150 ==============================\n"," Train Loss 0.12115 | Val Loss 0.43047 | SMAPE 0.83276\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  11%|█         | 21/193 [07:28<59:50, 20.87s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 200 ==============================\n"," Train Loss 0.10842 | Val Loss 0.44223 | SMAPE 0.85840\n","\n","[('느티나무 셀프BBQ_햇반',)] Epoch 50 ==============================\n"," Train Loss 0.20259 | Val Loss 0.27476 | SMAPE 0.53288\n","\n","[('느티나무 셀프BBQ_햇반',)] Epoch 100 ==============================\n"," Train Loss 0.13562 | Val Loss 0.26589 | SMAPE 0.51208\n","\n","[('느티나무 셀프BBQ_햇반',)] Epoch 150 ==============================\n"," Train Loss 0.09101 | Val Loss 0.27837 | SMAPE 0.54349\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  11%|█▏        | 22/193 [07:48<59:00, 20.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_햇반',)] Epoch 200 ==============================\n"," Train Loss 0.05892 | Val Loss 0.25449 | SMAPE 0.49159\n","\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 50 ==============================\n"," Train Loss 0.11942 | Val Loss 0.19854 | SMAPE 0.37553\n","\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 100 ==============================\n"," Train Loss 0.07584 | Val Loss 0.19574 | SMAPE 0.36304\n","\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 150 ==============================\n"," Train Loss 0.04351 | Val Loss 0.22206 | SMAPE 0.41126\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  12%|█▏        | 23/193 [08:09<59:05, 20.85s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 200 ==============================\n"," Train Loss 0.02996 | Val Loss 0.21345 | SMAPE 0.39924\n","\n","[('담하_(단체) 공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.20524 | Val Loss 0.27472 | SMAPE 0.55510\n","\n","[('담하_(단체) 공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.14542 | Val Loss 0.27859 | SMAPE 0.55237\n","\n","[('담하_(단체) 공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.11513 | Val Loss 0.30373 | SMAPE 0.60202\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  12%|█▏        | 24/193 [08:30<58:32, 20.79s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.10757 | Val Loss 0.28348 | SMAPE 0.57579\n","\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 50 ==============================\n"," Train Loss 0.07885 | Val Loss 0.42984 | SMAPE 0.83429\n","\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 100 ==============================\n"," Train Loss 0.05511 | Val Loss 0.34789 | SMAPE 0.62632\n","\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 150 ==============================\n"," Train Loss 0.04847 | Val Loss 0.33147 | SMAPE 0.61162\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  13%|█▎        | 25/193 [08:50<57:46, 20.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 200 ==============================\n"," Train Loss 0.05230 | Val Loss 0.35049 | SMAPE 0.64757\n","\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 50 ==============================\n"," Train Loss 0.14427 | Val Loss 0.41131 | SMAPE 0.79751\n","\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 100 ==============================\n"," Train Loss 0.10680 | Val Loss 0.38758 | SMAPE 0.77021\n","\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 150 ==============================\n"," Train Loss 0.08714 | Val Loss 0.55112 | SMAPE 1.06578\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  13%|█▎        | 26/193 [09:11<57:39, 20.72s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 200 ==============================\n"," Train Loss 0.07425 | Val Loss 0.54764 | SMAPE 1.07910\n","\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 50 ==============================\n"," Train Loss 0.22797 | Val Loss 0.33183 | SMAPE 0.63143\n","\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 100 ==============================\n"," Train Loss 0.16309 | Val Loss 0.33633 | SMAPE 0.63304\n","\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 150 ==============================\n"," Train Loss 0.13835 | Val Loss 0.38542 | SMAPE 0.74352\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  14%|█▍        | 27/193 [09:32<57:04, 20.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 200 ==============================\n"," Train Loss 0.11447 | Val Loss 0.36560 | SMAPE 0.71772\n","\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 50 ==============================\n"," Train Loss 0.18483 | Val Loss 0.28872 | SMAPE 0.54660\n","\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 100 ==============================\n"," Train Loss 0.10964 | Val Loss 0.31629 | SMAPE 0.60542\n","\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 150 ==============================\n"," Train Loss 0.07592 | Val Loss 0.34062 | SMAPE 0.65219\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  15%|█▍        | 28/193 [09:53<57:12, 20.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 200 ==============================\n"," Train Loss 0.05876 | Val Loss 0.35140 | SMAPE 0.67093\n","\n","[('담하_(정식) 된장찌개',)] Epoch 50 ==============================\n"," Train Loss 0.20077 | Val Loss 0.37246 | SMAPE 0.74618\n","\n","[('담하_(정식) 된장찌개',)] Epoch 100 ==============================\n"," Train Loss 0.16339 | Val Loss 0.41155 | SMAPE 0.80002\n","\n","[('담하_(정식) 된장찌개',)] Epoch 150 ==============================\n"," Train Loss 0.13329 | Val Loss 0.44580 | SMAPE 0.86325\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  15%|█▌        | 29/193 [10:13<56:43, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(정식) 된장찌개',)] Epoch 200 ==============================\n"," Train Loss 0.09037 | Val Loss 0.49481 | SMAPE 0.99291\n","\n","[('담하_(정식) 물냉면 ',)] Epoch 50 ==============================\n"," Train Loss 0.19259 | Val Loss 0.36865 | SMAPE 0.71661\n","\n","[('담하_(정식) 물냉면 ',)] Epoch 100 ==============================\n"," Train Loss 0.13270 | Val Loss 0.60018 | SMAPE 1.17985\n","\n","[('담하_(정식) 물냉면 ',)] Epoch 150 ==============================\n"," Train Loss 0.08565 | Val Loss 0.47622 | SMAPE 0.91160\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  16%|█▌        | 30/193 [10:33<55:47, 20.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(정식) 물냉면 ',)] Epoch 200 ==============================\n"," Train Loss 0.06124 | Val Loss 0.57776 | SMAPE 1.14447\n","\n","[('담하_(정식) 비빔냉면',)] Epoch 50 ==============================\n"," Train Loss 0.21870 | Val Loss 0.38496 | SMAPE 0.74892\n","\n","[('담하_(정식) 비빔냉면',)] Epoch 100 ==============================\n"," Train Loss 0.15231 | Val Loss 0.36428 | SMAPE 0.70206\n","\n","[('담하_(정식) 비빔냉면',)] Epoch 150 ==============================\n"," Train Loss 0.12041 | Val Loss 0.35744 | SMAPE 0.69307\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  16%|█▌        | 31/193 [10:53<55:02, 20.39s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(정식) 비빔냉면',)] Epoch 200 ==============================\n"," Train Loss 0.07412 | Val Loss 0.41510 | SMAPE 0.81388\n","\n","[('담하_(후식) 된장찌개',)] Epoch 50 ==============================\n"," Train Loss 0.17545 | Val Loss 0.33567 | SMAPE 0.64503\n","\n","[('담하_(후식) 된장찌개',)] Epoch 100 ==============================\n"," Train Loss 0.12169 | Val Loss 0.35073 | SMAPE 0.67077\n","\n","[('담하_(후식) 된장찌개',)] Epoch 150 ==============================\n"," Train Loss 0.08494 | Val Loss 0.34358 | SMAPE 0.66503\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  17%|█▋        | 32/193 [11:14<54:55, 20.47s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(후식) 된장찌개',)] Epoch 200 ==============================\n"," Train Loss 0.06312 | Val Loss 0.34743 | SMAPE 0.66794\n","\n","[('담하_(후식) 물냉면',)] Epoch 50 ==============================\n"," Train Loss 0.19581 | Val Loss 0.49563 | SMAPE 0.92969\n","\n","[('담하_(후식) 물냉면',)] Epoch 100 ==============================\n"," Train Loss 0.13099 | Val Loss 0.52787 | SMAPE 0.99277\n","\n","[('담하_(후식) 물냉면',)] Epoch 150 ==============================\n"," Train Loss 0.10014 | Val Loss 0.56701 | SMAPE 1.07866\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  17%|█▋        | 33/193 [11:35<55:09, 20.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(후식) 물냉면',)] Epoch 200 ==============================\n"," Train Loss 0.06305 | Val Loss 0.57796 | SMAPE 1.10975\n","\n","[('담하_(후식) 비빔냉면',)] Epoch 50 ==============================\n"," Train Loss 0.17631 | Val Loss 0.54628 | SMAPE 1.05267\n","\n","[('담하_(후식) 비빔냉면',)] Epoch 100 ==============================\n"," Train Loss 0.12395 | Val Loss 0.80728 | SMAPE 1.53193\n","\n","[('담하_(후식) 비빔냉면',)] Epoch 150 ==============================\n"," Train Loss 0.07605 | Val Loss 0.75042 | SMAPE 1.46605\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  18%|█▊        | 34/193 [11:56<54:32, 20.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(후식) 비빔냉면',)] Epoch 200 ==============================\n"," Train Loss 0.04698 | Val Loss 0.74463 | SMAPE 1.43785\n","\n","[('담하_갑오징어 비빔밥',)] Epoch 50 ==============================\n"," Train Loss 0.19241 | Val Loss 0.53340 | SMAPE 1.06471\n","\n","[('담하_갑오징어 비빔밥',)] Epoch 100 ==============================\n"," Train Loss 0.16850 | Val Loss 0.52164 | SMAPE 1.03493\n","\n","[('담하_갑오징어 비빔밥',)] Epoch 150 ==============================\n"," Train Loss 0.13651 | Val Loss 0.51463 | SMAPE 1.00504\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  18%|█▊        | 35/193 [12:17<54:37, 20.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_갑오징어 비빔밥',)] Epoch 200 ==============================\n"," Train Loss 0.10518 | Val Loss 0.53039 | SMAPE 1.04273\n","\n","[('담하_갱시기',)] Epoch 50 ==============================\n"," Train Loss 0.12034 | Val Loss 0.53198 | SMAPE 0.99440\n","\n","[('담하_갱시기',)] Epoch 100 ==============================\n"," Train Loss 0.09991 | Val Loss 0.54550 | SMAPE 1.01804\n","\n","[('담하_갱시기',)] Epoch 150 ==============================\n"," Train Loss 0.07566 | Val Loss 0.57739 | SMAPE 1.08266\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  19%|█▊        | 36/193 [12:37<53:43, 20.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_갱시기',)] Epoch 200 ==============================\n"," Train Loss 0.06682 | Val Loss 0.56603 | SMAPE 1.04028\n","\n","[('담하_공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.16525 | Val Loss 0.28888 | SMAPE 0.56817\n","\n","[('담하_공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.12272 | Val Loss 0.28767 | SMAPE 0.56872\n","\n","[('담하_공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.10533 | Val Loss 0.28569 | SMAPE 0.56380\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  19%|█▉        | 37/193 [12:58<53:41, 20.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.08361 | Val Loss 0.29139 | SMAPE 0.57691\n","\n","[('담하_꼬막 비빔밥',)] Epoch 50 ==============================\n"," Train Loss 0.16686 | Val Loss 0.28048 | SMAPE 0.56145\n","\n","[('담하_꼬막 비빔밥',)] Epoch 100 ==============================\n"," Train Loss 0.15245 | Val Loss 0.26454 | SMAPE 0.53394\n","\n","[('담하_꼬막 비빔밥',)] Epoch 150 ==============================\n"," Train Loss 0.12732 | Val Loss 0.24988 | SMAPE 0.49888\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  20%|█▉        | 38/193 [13:19<54:01, 20.91s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_꼬막 비빔밥',)] Epoch 200 ==============================\n"," Train Loss 0.08945 | Val Loss 0.29260 | SMAPE 0.56702\n","\n","[('담하_느린마을 막걸리',)] Epoch 50 ==============================\n"," Train Loss 0.14955 | Val Loss 0.32985 | SMAPE 0.63843\n","\n","[('담하_느린마을 막걸리',)] Epoch 100 ==============================\n"," Train Loss 0.09504 | Val Loss 0.33417 | SMAPE 0.64843\n","\n","[('담하_느린마을 막걸리',)] Epoch 150 ==============================\n"," Train Loss 0.06586 | Val Loss 0.33227 | SMAPE 0.64424\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  20%|██        | 39/193 [13:40<53:26, 20.82s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_느린마을 막걸리',)] Epoch 200 ==============================\n"," Train Loss 0.04430 | Val Loss 0.31614 | SMAPE 0.60987\n","\n","[('담하_담하 한우 불고기',)] Epoch 50 ==============================\n"," Train Loss 0.17489 | Val Loss 0.33313 | SMAPE 0.64318\n","\n","[('담하_담하 한우 불고기',)] Epoch 100 ==============================\n"," Train Loss 0.14175 | Val Loss 0.33921 | SMAPE 0.65123\n","\n","[('담하_담하 한우 불고기',)] Epoch 150 ==============================\n"," Train Loss 0.10832 | Val Loss 0.32840 | SMAPE 0.63837\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  21%|██        | 40/193 [14:01<53:26, 20.96s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_담하 한우 불고기',)] Epoch 200 ==============================\n"," Train Loss 0.08382 | Val Loss 0.34003 | SMAPE 0.65920\n","\n","[('담하_담하 한우 불고기 정식',)] Epoch 50 ==============================\n"," Train Loss 0.21320 | Val Loss 0.40562 | SMAPE 0.79110\n","\n","[('담하_담하 한우 불고기 정식',)] Epoch 100 ==============================\n"," Train Loss 0.16451 | Val Loss 0.50931 | SMAPE 1.02160\n","\n","[('담하_담하 한우 불고기 정식',)] Epoch 150 ==============================\n"," Train Loss 0.13910 | Val Loss 0.47609 | SMAPE 0.99292\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  21%|██        | 41/193 [14:21<52:01, 20.54s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_담하 한우 불고기 정식',)] Epoch 200 ==============================\n"," Train Loss 0.11093 | Val Loss 0.56521 | SMAPE 1.19066\n","\n","[('담하_더덕 한우 지짐',)] Epoch 50 ==============================\n"," Train Loss 0.17691 | Val Loss 0.35300 | SMAPE 0.72482\n","\n","[('담하_더덕 한우 지짐',)] Epoch 100 ==============================\n"," Train Loss 0.14944 | Val Loss 0.24571 | SMAPE 0.48140\n","\n","[('담하_더덕 한우 지짐',)] Epoch 150 ==============================\n"," Train Loss 0.09506 | Val Loss 0.32176 | SMAPE 0.65405\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  22%|██▏       | 42/193 [14:42<52:12, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_더덕 한우 지짐',)] Epoch 200 ==============================\n"," Train Loss 0.06550 | Val Loss 0.32889 | SMAPE 0.67488\n","\n","[('담하_들깨 양지탕',)] Epoch 50 ==============================\n"," Train Loss 0.20277 | Val Loss 0.31953 | SMAPE 0.62167\n","\n","[('담하_들깨 양지탕',)] Epoch 100 ==============================\n"," Train Loss 0.16480 | Val Loss 0.34229 | SMAPE 0.66665\n","\n","[('담하_들깨 양지탕',)] Epoch 150 ==============================\n"," Train Loss 0.13216 | Val Loss 0.31904 | SMAPE 0.61662\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  22%|██▏       | 43/193 [15:02<51:27, 20.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_들깨 양지탕',)] Epoch 200 ==============================\n"," Train Loss 0.08487 | Val Loss 0.32113 | SMAPE 0.61334\n","\n","[('담하_라면사리',)] Epoch 50 ==============================\n"," Train Loss 0.21028 | Val Loss 0.31978 | SMAPE 0.67072\n","\n","[('담하_라면사리',)] Epoch 100 ==============================\n"," Train Loss 0.12653 | Val Loss 0.33916 | SMAPE 0.68634\n","\n","[('담하_라면사리',)] Epoch 150 ==============================\n"," Train Loss 0.09841 | Val Loss 0.35636 | SMAPE 0.70315\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  23%|██▎       | 44/193 [15:24<51:44, 20.84s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_라면사리',)] Epoch 200 ==============================\n"," Train Loss 0.08871 | Val Loss 0.36223 | SMAPE 0.71882\n","\n","[('담하_룸 이용료',)] Epoch 50 ==============================\n"," Train Loss 0.12199 | Val Loss 0.22529 | SMAPE 0.43087\n","\n","[('담하_룸 이용료',)] Epoch 100 ==============================\n"," Train Loss 0.08775 | Val Loss 0.21921 | SMAPE 0.43161\n","\n","[('담하_룸 이용료',)] Epoch 150 ==============================\n"," Train Loss 0.06036 | Val Loss 0.20751 | SMAPE 0.40295\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  23%|██▎       | 45/193 [15:45<51:45, 20.98s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_룸 이용료',)] Epoch 200 ==============================\n"," Train Loss 0.04651 | Val Loss 0.21336 | SMAPE 0.41901\n","\n","[('담하_메밀면 사리',)] Epoch 50 ==============================\n"," Train Loss 0.17221 | Val Loss 0.38271 | SMAPE 0.75640\n","\n","[('담하_메밀면 사리',)] Epoch 100 ==============================\n"," Train Loss 0.12508 | Val Loss 0.39748 | SMAPE 0.78283\n","\n","[('담하_메밀면 사리',)] Epoch 150 ==============================\n"," Train Loss 0.08798 | Val Loss 0.42820 | SMAPE 0.83366\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  24%|██▍       | 46/193 [16:05<50:55, 20.79s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_메밀면 사리',)] Epoch 200 ==============================\n"," Train Loss 0.06978 | Val Loss 0.42217 | SMAPE 0.81873\n","\n","[('담하_명인안동소주',)] Epoch 50 ==============================\n"," Train Loss 0.11997 | Val Loss 0.86199 | SMAPE 1.65277\n","\n","[('담하_명인안동소주',)] Epoch 100 ==============================\n"," Train Loss 0.11568 | Val Loss 0.85931 | SMAPE 1.69880\n","\n","[('담하_명인안동소주',)] Epoch 150 ==============================\n"," Train Loss 0.06675 | Val Loss 0.66169 | SMAPE 1.33241\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  24%|██▍       | 47/193 [16:26<50:19, 20.68s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_명인안동소주',)] Epoch 200 ==============================\n"," Train Loss 0.05480 | Val Loss 0.84307 | SMAPE 1.63370\n","\n","[('담하_명태회 비빔냉면',)] Epoch 50 ==============================\n"," Train Loss 0.21794 | Val Loss 0.34279 | SMAPE 0.69432\n","\n","[('담하_명태회 비빔냉면',)] Epoch 100 ==============================\n"," Train Loss 0.17062 | Val Loss 0.53572 | SMAPE 1.06294\n","\n","[('담하_명태회 비빔냉면',)] Epoch 150 ==============================\n"," Train Loss 0.12676 | Val Loss 0.38955 | SMAPE 0.76900\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  25%|██▍       | 48/193 [16:46<49:41, 20.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_명태회 비빔냉면',)] Epoch 200 ==============================\n"," Train Loss 0.08218 | Val Loss 0.52445 | SMAPE 1.04323\n","\n","[('담하_문막 복분자 칵테일',)] Epoch 50 ==============================\n"," Train Loss 0.09457 | Val Loss 0.88972 | SMAPE 1.62282\n","\n","[('담하_문막 복분자 칵테일',)] Epoch 100 ==============================\n"," Train Loss 0.08572 | Val Loss 0.18353 | SMAPE 0.34069\n","\n","[('담하_문막 복분자 칵테일',)] Epoch 150 ==============================\n"," Train Loss 0.06595 | Val Loss 0.50887 | SMAPE 1.01393\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  25%|██▌       | 49/193 [17:07<49:49, 20.76s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_문막 복분자 칵테일',)] Epoch 200 ==============================\n"," Train Loss 0.04695 | Val Loss 0.86290 | SMAPE 1.72263\n","\n","[('담하_봉평메밀 물냉면',)] Epoch 50 ==============================\n"," Train Loss 0.19089 | Val Loss 0.34610 | SMAPE 0.68929\n","\n","[('담하_봉평메밀 물냉면',)] Epoch 100 ==============================\n"," Train Loss 0.14355 | Val Loss 0.37454 | SMAPE 0.74280\n","\n","[('담하_봉평메밀 물냉면',)] Epoch 150 ==============================\n"," Train Loss 0.12024 | Val Loss 0.47579 | SMAPE 0.96102\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  26%|██▌       | 50/193 [17:28<49:44, 20.87s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_봉평메밀 물냉면',)] Epoch 200 ==============================\n"," Train Loss 0.08567 | Val Loss 0.55200 | SMAPE 1.08250\n","\n","[('담하_생목살 김치찌개',)] Epoch 50 ==============================\n"," Train Loss 0.15795 | Val Loss 0.30167 | SMAPE 0.59730\n","\n","[('담하_생목살 김치찌개',)] Epoch 100 ==============================\n"," Train Loss 0.12469 | Val Loss 0.30840 | SMAPE 0.59842\n","\n","[('담하_생목살 김치찌개',)] Epoch 150 ==============================\n"," Train Loss 0.08819 | Val Loss 0.30682 | SMAPE 0.61022\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  26%|██▋       | 51/193 [17:49<48:59, 20.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_생목살 김치찌개',)] Epoch 200 ==============================\n"," Train Loss 0.06341 | Val Loss 0.30639 | SMAPE 0.60010\n","\n","[('담하_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.15459 | Val Loss 0.20985 | SMAPE 0.41675\n","\n","[('담하_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.11672 | Val Loss 0.20048 | SMAPE 0.40620\n","\n","[('담하_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.08985 | Val Loss 0.20734 | SMAPE 0.41734\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  27%|██▋       | 52/193 [18:09<48:46, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.07093 | Val Loss 0.21409 | SMAPE 0.41522\n","\n","[('담하_은이버섯 갈비탕',)] Epoch 50 ==============================\n"," Train Loss 0.22147 | Val Loss 0.38247 | SMAPE 0.73892\n","\n","[('담하_은이버섯 갈비탕',)] Epoch 100 ==============================\n"," Train Loss 0.14984 | Val Loss 0.39096 | SMAPE 0.75697\n","\n","[('담하_은이버섯 갈비탕',)] Epoch 150 ==============================\n"," Train Loss 0.09751 | Val Loss 0.38286 | SMAPE 0.74192\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  27%|██▋       | 53/193 [18:29<47:51, 20.51s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_은이버섯 갈비탕',)] Epoch 200 ==============================\n"," Train Loss 0.06595 | Val Loss 0.38684 | SMAPE 0.75758\n","\n","[('담하_제로콜라',)] Epoch 50 ==============================\n"," Train Loss 0.13314 | Val Loss 0.20423 | SMAPE 0.39130\n","\n","[('담하_제로콜라',)] Epoch 100 ==============================\n"," Train Loss 0.10188 | Val Loss 0.21931 | SMAPE 0.43410\n","\n","[('담하_제로콜라',)] Epoch 150 ==============================\n"," Train Loss 0.07899 | Val Loss 0.21998 | SMAPE 0.41060\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  28%|██▊       | 54/193 [18:51<47:59, 20.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_제로콜라',)] Epoch 200 ==============================\n"," Train Loss 0.05115 | Val Loss 0.21846 | SMAPE 0.41057\n","\n","[('담하_참이슬',)] Epoch 50 ==============================\n"," Train Loss 0.18183 | Val Loss 0.31721 | SMAPE 0.61549\n","\n","[('담하_참이슬',)] Epoch 100 ==============================\n"," Train Loss 0.14008 | Val Loss 0.31313 | SMAPE 0.60705\n","\n","[('담하_참이슬',)] Epoch 150 ==============================\n"," Train Loss 0.09164 | Val Loss 0.32067 | SMAPE 0.63143\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  28%|██▊       | 55/193 [19:11<47:41, 20.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_참이슬',)] Epoch 200 ==============================\n"," Train Loss 0.06809 | Val Loss 0.31418 | SMAPE 0.62093\n","\n","[('담하_처음처럼',)] Epoch 50 ==============================\n"," Train Loss 0.15018 | Val Loss 0.25692 | SMAPE 0.50693\n","\n","[('담하_처음처럼',)] Epoch 100 ==============================\n"," Train Loss 0.10295 | Val Loss 0.24452 | SMAPE 0.48192\n","\n","[('담하_처음처럼',)] Epoch 150 ==============================\n"," Train Loss 0.07269 | Val Loss 0.23609 | SMAPE 0.46253\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  29%|██▉       | 56/193 [19:32<47:33, 20.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_처음처럼',)] Epoch 200 ==============================\n"," Train Loss 0.05023 | Val Loss 0.24212 | SMAPE 0.47481\n","\n","[('담하_카스',)] Epoch 50 ==============================\n"," Train Loss 0.16127 | Val Loss 0.31629 | SMAPE 0.63215\n","\n","[('담하_카스',)] Epoch 100 ==============================\n"," Train Loss 0.12113 | Val Loss 0.29965 | SMAPE 0.59527\n","\n","[('담하_카스',)] Epoch 150 ==============================\n"," Train Loss 0.07693 | Val Loss 0.32053 | SMAPE 0.64977\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  30%|██▉       | 57/193 [19:53<46:44, 20.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_카스',)] Epoch 200 ==============================\n"," Train Loss 0.05813 | Val Loss 0.30623 | SMAPE 0.61490\n","\n","[('담하_콜라',)] Epoch 50 ==============================\n"," Train Loss 0.17166 | Val Loss 0.24447 | SMAPE 0.48142\n","\n","[('담하_콜라',)] Epoch 100 ==============================\n"," Train Loss 0.12139 | Val Loss 0.23411 | SMAPE 0.46125\n","\n","[('담하_콜라',)] Epoch 150 ==============================\n"," Train Loss 0.08783 | Val Loss 0.22270 | SMAPE 0.44601\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  30%|███       | 58/193 [20:13<46:27, 20.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_콜라',)] Epoch 200 ==============================\n"," Train Loss 0.05518 | Val Loss 0.24249 | SMAPE 0.48130\n","\n","[('담하_테라',)] Epoch 50 ==============================\n"," Train Loss 0.17564 | Val Loss 0.32530 | SMAPE 0.64052\n","\n","[('담하_테라',)] Epoch 100 ==============================\n"," Train Loss 0.11405 | Val Loss 0.29786 | SMAPE 0.58595\n","\n","[('담하_테라',)] Epoch 150 ==============================\n"," Train Loss 0.07997 | Val Loss 0.29774 | SMAPE 0.58926\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  31%|███       | 59/193 [20:34<46:27, 20.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_테라',)] Epoch 200 ==============================\n"," Train Loss 0.05935 | Val Loss 0.28240 | SMAPE 0.54854\n","\n","[('담하_하동 매실 칵테일',)] Epoch 50 ==============================\n"," Train Loss 0.11806 | Val Loss 0.30833 | SMAPE 0.61545\n","\n","[('담하_하동 매실 칵테일',)] Epoch 100 ==============================\n"," Train Loss 0.09296 | Val Loss 0.33716 | SMAPE 0.64126\n","\n","[('담하_하동 매실 칵테일',)] Epoch 150 ==============================\n"," Train Loss 0.07881 | Val Loss 0.33151 | SMAPE 0.63858\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  31%|███       | 60/193 [20:55<45:54, 20.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_하동 매실 칵테일',)] Epoch 200 ==============================\n"," Train Loss 0.05769 | Val Loss 0.31997 | SMAPE 0.60254\n","\n","[('담하_한우 떡갈비 정식',)] Epoch 50 ==============================\n"," Train Loss 0.17743 | Val Loss 0.34960 | SMAPE 0.68744\n","\n","[('담하_한우 떡갈비 정식',)] Epoch 100 ==============================\n"," Train Loss 0.13582 | Val Loss 0.33707 | SMAPE 0.65721\n","\n","[('담하_한우 떡갈비 정식',)] Epoch 150 ==============================\n"," Train Loss 0.11102 | Val Loss 0.34580 | SMAPE 0.67255\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  32%|███▏      | 61/193 [21:16<45:51, 20.85s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 떡갈비 정식',)] Epoch 200 ==============================\n"," Train Loss 0.09040 | Val Loss 0.33874 | SMAPE 0.66391\n","\n","[('담하_한우 미역국 정식',)] Epoch 50 ==============================\n"," Train Loss 0.20979 | Val Loss 0.37132 | SMAPE 0.75061\n","\n","[('담하_한우 미역국 정식',)] Epoch 100 ==============================\n"," Train Loss 0.15978 | Val Loss 0.41906 | SMAPE 0.82920\n","\n","[('담하_한우 미역국 정식',)] Epoch 150 ==============================\n"," Train Loss 0.12498 | Val Loss 0.40021 | SMAPE 0.78472\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  32%|███▏      | 62/193 [21:36<45:12, 20.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 미역국 정식',)] Epoch 200 ==============================\n"," Train Loss 0.09129 | Val Loss 0.41394 | SMAPE 0.81476\n","\n","[('담하_한우 우거지 국밥',)] Epoch 50 ==============================\n"," Train Loss 0.22675 | Val Loss 0.32916 | SMAPE 0.65479\n","\n","[('담하_한우 우거지 국밥',)] Epoch 100 ==============================\n"," Train Loss 0.17372 | Val Loss 0.30923 | SMAPE 0.61328\n","\n","[('담하_한우 우거지 국밥',)] Epoch 150 ==============================\n"," Train Loss 0.15012 | Val Loss 0.32231 | SMAPE 0.63826\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  33%|███▎      | 63/193 [21:58<45:03, 20.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 우거지 국밥',)] Epoch 200 ==============================\n"," Train Loss 0.12461 | Val Loss 0.32944 | SMAPE 0.64994\n","\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 50 ==============================\n"," Train Loss 0.15613 | Val Loss 0.29196 | SMAPE 0.57651\n","\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 100 ==============================\n"," Train Loss 0.11335 | Val Loss 0.31621 | SMAPE 0.62084\n","\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 150 ==============================\n"," Train Loss 0.07034 | Val Loss 0.29701 | SMAPE 0.58321\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  33%|███▎      | 64/193 [22:17<44:03, 20.49s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 200 ==============================\n"," Train Loss 0.05494 | Val Loss 0.29546 | SMAPE 0.58502\n","\n","[('담하_황태해장국',)] Epoch 50 ==============================\n"," Train Loss 0.21588 | Val Loss 0.42462 | SMAPE 0.81350\n","\n","[('담하_황태해장국',)] Epoch 100 ==============================\n"," Train Loss 0.16811 | Val Loss 0.42767 | SMAPE 0.81571\n","\n","[('담하_황태해장국',)] Epoch 150 ==============================\n"," Train Loss 0.11054 | Val Loss 0.43199 | SMAPE 0.83761\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  34%|███▎      | 65/193 [22:38<43:56, 20.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_황태해장국',)] Epoch 200 ==============================\n"," Train Loss 0.08111 | Val Loss 0.42215 | SMAPE 0.81422\n","\n","[('라그로타_AUS (200g)',)] Epoch 50 ==============================\n"," Train Loss 0.13651 | Val Loss 0.66740 | SMAPE 1.31690\n","\n","[('라그로타_AUS (200g)',)] Epoch 100 ==============================\n"," Train Loss 0.10017 | Val Loss 0.58477 | SMAPE 1.10736\n","\n","[('라그로타_AUS (200g)',)] Epoch 150 ==============================\n"," Train Loss 0.09995 | Val Loss 0.55502 | SMAPE 1.06272\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  34%|███▍      | 66/193 [22:59<43:58, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_AUS (200g)',)] Epoch 200 ==============================\n"," Train Loss 0.07471 | Val Loss 0.67441 | SMAPE 1.31073\n","\n","[('라그로타_G-Charge(3)',)] Epoch 50 ==============================\n"," Train Loss 0.13073 | Val Loss 0.27542 | SMAPE 0.54838\n","\n","[('라그로타_G-Charge(3)',)] Epoch 100 ==============================\n"," Train Loss 0.09772 | Val Loss 0.29886 | SMAPE 0.59755\n","\n","[('라그로타_G-Charge(3)',)] Epoch 150 ==============================\n"," Train Loss 0.07113 | Val Loss 0.29139 | SMAPE 0.57882\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  35%|███▍      | 67/193 [23:20<43:26, 20.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_G-Charge(3)',)] Epoch 200 ==============================\n"," Train Loss 0.06117 | Val Loss 0.27559 | SMAPE 0.55980\n","\n","[('라그로타_Gls.Sileni',)] Epoch 50 ==============================\n"," Train Loss 0.16399 | Val Loss 0.22589 | SMAPE 0.43576\n","\n","[('라그로타_Gls.Sileni',)] Epoch 100 ==============================\n"," Train Loss 0.11285 | Val Loss 0.22472 | SMAPE 0.42490\n","\n","[('라그로타_Gls.Sileni',)] Epoch 150 ==============================\n"," Train Loss 0.06170 | Val Loss 0.24328 | SMAPE 0.45860\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  35%|███▌      | 68/193 [23:41<43:22, 20.82s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_Gls.Sileni',)] Epoch 200 ==============================\n"," Train Loss 0.04390 | Val Loss 0.23174 | SMAPE 0.43405\n","\n","[('라그로타_Gls.미션 서드',)] Epoch 50 ==============================\n"," Train Loss 0.17189 | Val Loss 0.31106 | SMAPE 0.59527\n","\n","[('라그로타_Gls.미션 서드',)] Epoch 100 ==============================\n"," Train Loss 0.11578 | Val Loss 0.32277 | SMAPE 0.63509\n","\n","[('라그로타_Gls.미션 서드',)] Epoch 150 ==============================\n"," Train Loss 0.06871 | Val Loss 0.32502 | SMAPE 0.63070\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  36%|███▌      | 69/193 [24:01<42:42, 20.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_Gls.미션 서드',)] Epoch 200 ==============================\n"," Train Loss 0.05349 | Val Loss 0.31789 | SMAPE 0.61856\n","\n","[('라그로타_Open Food',)] Epoch 50 ==============================\n"," Train Loss 0.14413 | Val Loss 0.21369 | SMAPE 0.40523\n","\n","[('라그로타_Open Food',)] Epoch 100 ==============================\n"," Train Loss 0.12733 | Val Loss 0.20007 | SMAPE 0.38186\n","\n","[('라그로타_Open Food',)] Epoch 150 ==============================\n"," Train Loss 0.10388 | Val Loss 0.18526 | SMAPE 0.35603\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  36%|███▋      | 70/193 [24:22<42:13, 20.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_Open Food',)] Epoch 200 ==============================\n"," Train Loss 0.08295 | Val Loss 0.18144 | SMAPE 0.35141\n","\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 50 ==============================\n"," Train Loss 0.16545 | Val Loss 0.61225 | SMAPE 1.26116\n","\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 100 ==============================\n"," Train Loss 0.11789 | Val Loss 0.34092 | SMAPE 0.64103\n","\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 150 ==============================\n"," Train Loss 0.07736 | Val Loss 0.42325 | SMAPE 0.85592\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  37%|███▋      | 71/193 [24:42<41:47, 20.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 200 ==============================\n"," Train Loss 0.05270 | Val Loss 0.52782 | SMAPE 1.06689\n","\n","[('라그로타_까르보나라',)] Epoch 50 ==============================\n"," Train Loss 0.11328 | Val Loss 0.86663 | SMAPE 1.72750\n","\n","[('라그로타_까르보나라',)] Epoch 100 ==============================\n"," Train Loss 0.12452 | Val Loss 0.40712 | SMAPE 0.77489\n","\n","[('라그로타_까르보나라',)] Epoch 150 ==============================\n"," Train Loss 0.10960 | Val Loss 0.64784 | SMAPE 1.24582\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  37%|███▋      | 72/193 [25:03<41:41, 20.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_까르보나라',)] Epoch 200 ==============================\n"," Train Loss 0.10021 | Val Loss 0.50184 | SMAPE 1.00752\n","\n","[('라그로타_모둠 해산물 플래터',)] Epoch 50 ==============================\n"," Train Loss 0.14027 | Val Loss 0.26519 | SMAPE 0.49931\n","\n","[('라그로타_모둠 해산물 플래터',)] Epoch 100 ==============================\n"," Train Loss 0.08092 | Val Loss 0.44616 | SMAPE 0.81806\n","\n","[('라그로타_모둠 해산물 플래터',)] Epoch 150 ==============================\n"," Train Loss 0.05376 | Val Loss 0.61625 | SMAPE 1.21896\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  38%|███▊      | 73/193 [25:24<41:38, 20.82s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_모둠 해산물 플래터',)] Epoch 200 ==============================\n"," Train Loss 0.03576 | Val Loss 0.66347 | SMAPE 1.29538\n","\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 50 ==============================\n"," Train Loss 0.14840 | Val Loss 0.23399 | SMAPE 0.46662\n","\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 100 ==============================\n"," Train Loss 0.10269 | Val Loss 0.24258 | SMAPE 0.48650\n","\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 150 ==============================\n"," Train Loss 0.08086 | Val Loss 0.24697 | SMAPE 0.49867\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  38%|███▊      | 74/193 [25:45<41:09, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 200 ==============================\n"," Train Loss 0.06798 | Val Loss 0.23601 | SMAPE 0.47454\n","\n","[('라그로타_버섯 크림 리조또',)] Epoch 50 ==============================\n"," Train Loss 0.08506 | Val Loss 0.55410 | SMAPE 1.09141\n","\n","[('라그로타_버섯 크림 리조또',)] Epoch 100 ==============================\n"," Train Loss 0.09543 | Val Loss 0.39565 | SMAPE 0.76181\n","\n","[('라그로타_버섯 크림 리조또',)] Epoch 150 ==============================\n"," Train Loss 0.05637 | Val Loss 0.47210 | SMAPE 0.87236\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  39%|███▉      | 75/193 [26:05<40:35, 20.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_버섯 크림 리조또',)] Epoch 200 ==============================\n"," Train Loss 0.05006 | Val Loss 0.46131 | SMAPE 0.85422\n","\n","[('라그로타_빵 추가 (1인)',)] Epoch 50 ==============================\n"," Train Loss 0.18068 | Val Loss 0.43275 | SMAPE 0.84702\n","\n","[('라그로타_빵 추가 (1인)',)] Epoch 100 ==============================\n"," Train Loss 0.12771 | Val Loss 0.43096 | SMAPE 0.84458\n","\n","[('라그로타_빵 추가 (1인)',)] Epoch 150 ==============================\n"," Train Loss 0.08308 | Val Loss 0.43246 | SMAPE 0.84276\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  39%|███▉      | 76/193 [26:25<39:36, 20.31s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_빵 추가 (1인)',)] Epoch 200 ==============================\n"," Train Loss 0.06440 | Val Loss 0.44032 | SMAPE 0.85282\n","\n","[('라그로타_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.11873 | Val Loss 0.19743 | SMAPE 0.39299\n","\n","[('라그로타_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.08157 | Val Loss 0.21836 | SMAPE 0.43305\n","\n","[('라그로타_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.05024 | Val Loss 0.20695 | SMAPE 0.41443\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  40%|███▉      | 77/193 [26:46<39:46, 20.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.03963 | Val Loss 0.20244 | SMAPE 0.40998\n","\n","[('라그로타_시저 샐러드 ',)] Epoch 50 ==============================\n"," Train Loss 0.16623 | Val Loss 0.35031 | SMAPE 0.71712\n","\n","[('라그로타_시저 샐러드 ',)] Epoch 100 ==============================\n"," Train Loss 0.10951 | Val Loss 0.91003 | SMAPE 1.82103\n","\n","[('라그로타_시저 샐러드 ',)] Epoch 150 ==============================\n"," Train Loss 0.07133 | Val Loss 0.95108 | SMAPE 1.88508\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  40%|████      | 78/193 [27:06<39:21, 20.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_시저 샐러드 ',)] Epoch 200 ==============================\n"," Train Loss 0.04706 | Val Loss 0.60325 | SMAPE 1.28897\n","\n","[('라그로타_아메리카노',)] Epoch 50 ==============================\n"," Train Loss 0.15064 | Val Loss 0.28459 | SMAPE 0.55741\n","\n","[('라그로타_아메리카노',)] Epoch 100 ==============================\n"," Train Loss 0.11381 | Val Loss 0.28130 | SMAPE 0.56169\n","\n","[('라그로타_아메리카노',)] Epoch 150 ==============================\n"," Train Loss 0.09492 | Val Loss 0.29079 | SMAPE 0.57543\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  41%|████      | 79/193 [27:28<39:23, 20.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_아메리카노',)] Epoch 200 ==============================\n"," Train Loss 0.07637 | Val Loss 0.30526 | SMAPE 0.61225\n","\n","[('라그로타_알리오 에 올리오 ',)] Epoch 50 ==============================\n"," Train Loss 0.16923 | Val Loss 0.45207 | SMAPE 0.87499\n","\n","[('라그로타_알리오 에 올리오 ',)] Epoch 100 ==============================\n"," Train Loss 0.13084 | Val Loss 0.54827 | SMAPE 1.07809\n","\n","[('라그로타_알리오 에 올리오 ',)] Epoch 150 ==============================\n"," Train Loss 0.08424 | Val Loss 0.41633 | SMAPE 0.82411\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  41%|████▏     | 80/193 [27:48<38:52, 20.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_알리오 에 올리오 ',)] Epoch 200 ==============================\n"," Train Loss 0.06405 | Val Loss 0.42332 | SMAPE 0.82739\n","\n","[('라그로타_양갈비 (4ps)',)] Epoch 50 ==============================\n"," Train Loss 0.09736 | Val Loss 0.71145 | SMAPE 1.35749\n","\n","[('라그로타_양갈비 (4ps)',)] Epoch 100 ==============================\n"," Train Loss 0.06820 | Val Loss 0.77398 | SMAPE 1.47434\n","\n","[('라그로타_양갈비 (4ps)',)] Epoch 150 ==============================\n"," Train Loss 0.05224 | Val Loss 0.78532 | SMAPE 1.49242\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  42%|████▏     | 81/193 [28:09<38:39, 20.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_양갈비 (4ps)',)] Epoch 200 ==============================\n"," Train Loss 0.06003 | Val Loss 0.37568 | SMAPE 0.67328\n","\n","[('라그로타_자몽리치에이드',)] Epoch 50 ==============================\n"," Train Loss 0.12178 | Val Loss 0.25779 | SMAPE 0.50208\n","\n","[('라그로타_자몽리치에이드',)] Epoch 100 ==============================\n"," Train Loss 0.08628 | Val Loss 0.27122 | SMAPE 0.53585\n","\n","[('라그로타_자몽리치에이드',)] Epoch 150 ==============================\n"," Train Loss 0.06678 | Val Loss 0.26538 | SMAPE 0.51809\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  42%|████▏     | 82/193 [28:29<38:06, 20.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_자몽리치에이드',)] Epoch 200 ==============================\n"," Train Loss 0.04929 | Val Loss 0.27292 | SMAPE 0.53935\n","\n","[('라그로타_제로콜라',)] Epoch 50 ==============================\n"," Train Loss 0.11734 | Val Loss 0.23431 | SMAPE 0.46675\n","\n","[('라그로타_제로콜라',)] Epoch 100 ==============================\n"," Train Loss 0.07411 | Val Loss 0.23525 | SMAPE 0.47429\n","\n","[('라그로타_제로콜라',)] Epoch 150 ==============================\n"," Train Loss 0.05534 | Val Loss 0.22392 | SMAPE 0.44425\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  43%|████▎     | 83/193 [28:50<37:38, 20.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_제로콜라',)] Epoch 200 ==============================\n"," Train Loss 0.04587 | Val Loss 0.21553 | SMAPE 0.42780\n","\n","[('라그로타_카스',)] Epoch 50 ==============================\n"," Train Loss 0.15358 | Val Loss 0.30109 | SMAPE 0.59780\n","\n","[('라그로타_카스',)] Epoch 100 ==============================\n"," Train Loss 0.08405 | Val Loss 0.31192 | SMAPE 0.62162\n","\n","[('라그로타_카스',)] Epoch 150 ==============================\n"," Train Loss 0.05724 | Val Loss 0.29521 | SMAPE 0.58928\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  44%|████▎     | 84/193 [29:11<37:41, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_카스',)] Epoch 200 ==============================\n"," Train Loss 0.05061 | Val Loss 0.29841 | SMAPE 0.59252\n","\n","[('라그로타_콜라',)] Epoch 50 ==============================\n"," Train Loss 0.16035 | Val Loss 0.25151 | SMAPE 0.50098\n","\n","[('라그로타_콜라',)] Epoch 100 ==============================\n"," Train Loss 0.11675 | Val Loss 0.26606 | SMAPE 0.52497\n","\n","[('라그로타_콜라',)] Epoch 150 ==============================\n"," Train Loss 0.08398 | Val Loss 0.26575 | SMAPE 0.53348\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  44%|████▍     | 85/193 [29:31<37:10, 20.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_콜라',)] Epoch 200 ==============================\n"," Train Loss 0.05306 | Val Loss 0.25797 | SMAPE 0.51548\n","\n","[('라그로타_하이네켄(생)',)] Epoch 50 ==============================\n"," Train Loss 0.17855 | Val Loss 0.37679 | SMAPE 0.74598\n","\n","[('라그로타_하이네켄(생)',)] Epoch 100 ==============================\n"," Train Loss 0.13285 | Val Loss 0.40972 | SMAPE 0.80878\n","\n","[('라그로타_하이네켄(생)',)] Epoch 150 ==============================\n"," Train Loss 0.10202 | Val Loss 0.41142 | SMAPE 0.82106\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  45%|████▍     | 86/193 [29:53<37:08, 20.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_하이네켄(생)',)] Epoch 200 ==============================\n"," Train Loss 0.06764 | Val Loss 0.39452 | SMAPE 0.77504\n","\n","[('라그로타_한우 (200g)',)] Epoch 50 ==============================\n"," Train Loss 0.09889 | Val Loss 0.55763 | SMAPE 0.80686\n","\n","[('라그로타_한우 (200g)',)] Epoch 100 ==============================\n"," Train Loss 0.08574 | Val Loss 0.46259 | SMAPE 0.77151\n","\n","[('라그로타_한우 (200g)',)] Epoch 150 ==============================\n"," Train Loss 0.06475 | Val Loss 0.91374 | SMAPE 1.79143\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  45%|████▌     | 87/193 [30:13<36:39, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_한우 (200g)',)] Epoch 200 ==============================\n"," Train Loss 0.05569 | Val Loss 0.80622 | SMAPE 1.67875\n","\n","[('라그로타_해산물 토마토 리조또',)] Epoch 50 ==============================\n"," Train Loss 0.16330 | Val Loss 0.46332 | SMAPE 0.84077\n","\n","[('라그로타_해산물 토마토 리조또',)] Epoch 100 ==============================\n"," Train Loss 0.10024 | Val Loss 0.38939 | SMAPE 0.70363\n","\n","[('라그로타_해산물 토마토 리조또',)] Epoch 150 ==============================\n"," Train Loss 0.05940 | Val Loss 0.31167 | SMAPE 0.61121\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  46%|████▌     | 88/193 [30:33<36:05, 20.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_해산물 토마토 리조또',)] Epoch 200 ==============================\n"," Train Loss 0.04646 | Val Loss 0.32197 | SMAPE 0.62027\n","\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 50 ==============================\n"," Train Loss 0.13839 | Val Loss 0.65268 | SMAPE 1.20984\n","\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 100 ==============================\n"," Train Loss 0.14184 | Val Loss 0.58246 | SMAPE 1.04054\n","\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 150 ==============================\n"," Train Loss 0.03726 | Val Loss 0.86219 | SMAPE 1.62589\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  46%|████▌     | 89/193 [30:55<36:00, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 200 ==============================\n"," Train Loss 0.03238 | Val Loss 0.65313 | SMAPE 1.19596\n","\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 50 ==============================\n"," Train Loss 0.16099 | Val Loss 0.31705 | SMAPE 0.59125\n","\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 100 ==============================\n"," Train Loss 0.11162 | Val Loss 0.32899 | SMAPE 0.62120\n","\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 150 ==============================\n"," Train Loss 0.06953 | Val Loss 0.35343 | SMAPE 0.66233\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  47%|████▋     | 90/193 [31:15<35:28, 20.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 200 ==============================\n"," Train Loss 0.05127 | Val Loss 0.34638 | SMAPE 0.65259\n","\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 50 ==============================\n"," Train Loss 0.32483 | Val Loss 0.39022 | SMAPE 0.74238\n","\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 100 ==============================\n"," Train Loss 0.25760 | Val Loss 0.40274 | SMAPE 0.77511\n","\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 150 ==============================\n"," Train Loss 0.21087 | Val Loss 0.41917 | SMAPE 0.82578\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  47%|████▋     | 91/193 [31:36<35:24, 20.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 200 ==============================\n"," Train Loss 0.17735 | Val Loss 0.41043 | SMAPE 0.82096\n","\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 50 ==============================\n"," Train Loss 0.18072 | Val Loss 0.95869 | SMAPE 1.93410\n","\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 100 ==============================\n"," Train Loss 0.14113 | Val Loss 0.85333 | SMAPE 1.70120\n","\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 150 ==============================\n"," Train Loss 0.10135 | Val Loss 0.95165 | SMAPE 1.91794\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  48%|████▊     | 92/193 [31:57<34:56, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 200 ==============================\n"," Train Loss 0.07188 | Val Loss 0.71321 | SMAPE 1.38534\n","\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 50 ==============================\n"," Train Loss 0.15439 | Val Loss 0.33315 | SMAPE 0.63224\n","\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 100 ==============================\n"," Train Loss 0.10785 | Val Loss 0.29834 | SMAPE 0.57669\n","\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 150 ==============================\n"," Train Loss 0.06844 | Val Loss 0.29550 | SMAPE 0.56345\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  48%|████▊     | 93/193 [32:18<34:51, 20.92s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 200 ==============================\n"," Train Loss 0.05147 | Val Loss 0.27521 | SMAPE 0.52750\n","\n","[('미라시아_BBQ Platter',)] Epoch 50 ==============================\n"," Train Loss 0.15155 | Val Loss 0.30094 | SMAPE 0.59974\n","\n","[('미라시아_BBQ Platter',)] Epoch 100 ==============================\n"," Train Loss 0.11678 | Val Loss 0.29972 | SMAPE 0.58953\n","\n","[('미라시아_BBQ Platter',)] Epoch 150 ==============================\n"," Train Loss 0.08796 | Val Loss 0.29388 | SMAPE 0.57658\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  49%|████▊     | 94/193 [32:38<34:15, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_BBQ Platter',)] Epoch 200 ==============================\n"," Train Loss 0.06644 | Val Loss 0.28881 | SMAPE 0.56604\n","\n","[('미라시아_BBQ 고기추가',)] Epoch 50 ==============================\n"," Train Loss 0.16051 | Val Loss 0.24264 | SMAPE 0.48597\n","\n","[('미라시아_BBQ 고기추가',)] Epoch 100 ==============================\n"," Train Loss 0.11783 | Val Loss 0.26594 | SMAPE 0.53213\n","\n","[('미라시아_BBQ 고기추가',)] Epoch 150 ==============================\n"," Train Loss 0.08527 | Val Loss 0.22250 | SMAPE 0.45013\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  49%|████▉     | 95/193 [32:59<33:49, 20.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_BBQ 고기추가',)] Epoch 200 ==============================\n"," Train Loss 0.05890 | Val Loss 0.24052 | SMAPE 0.49172\n","\n","[('미라시아_공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.16743 | Val Loss 0.88107 | SMAPE 1.77739\n","\n","[('미라시아_공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.20624 | Val Loss 0.86108 | SMAPE 1.74417\n","\n","[('미라시아_공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.13322 | Val Loss 0.98614 | SMAPE 1.97769\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  50%|████▉     | 96/193 [33:20<33:50, 20.93s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.14232 | Val Loss 0.94708 | SMAPE 1.81590\n","\n","[('미라시아_글라스와인 (레드)',)] Epoch 50 ==============================\n"," Train Loss 0.12508 | Val Loss 0.26210 | SMAPE 0.51771\n","\n","[('미라시아_글라스와인 (레드)',)] Epoch 100 ==============================\n"," Train Loss 0.09304 | Val Loss 0.24464 | SMAPE 0.47856\n","\n","[('미라시아_글라스와인 (레드)',)] Epoch 150 ==============================\n"," Train Loss 0.07367 | Val Loss 0.24949 | SMAPE 0.49466\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  50%|█████     | 97/193 [33:41<33:16, 20.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_글라스와인 (레드)',)] Epoch 200 ==============================\n"," Train Loss 0.05215 | Val Loss 0.25436 | SMAPE 0.50163\n","\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 50 ==============================\n"," Train Loss 0.10510 | Val Loss 0.18075 | SMAPE 0.30944\n","\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 100 ==============================\n"," Train Loss 0.06301 | Val Loss 0.13930 | SMAPE 0.24152\n","\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 150 ==============================\n"," Train Loss 0.03679 | Val Loss 0.14513 | SMAPE 0.25904\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  51%|█████     | 98/193 [34:02<33:07, 20.92s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 200 ==============================\n"," Train Loss 0.02682 | Val Loss 0.12640 | SMAPE 0.22565\n","\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 50 ==============================\n"," Train Loss 0.22677 | Val Loss 0.29581 | SMAPE 0.59397\n","\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 100 ==============================\n"," Train Loss 0.18731 | Val Loss 0.33218 | SMAPE 0.65190\n","\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 150 ==============================\n"," Train Loss 0.10969 | Val Loss 0.29730 | SMAPE 0.59155\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  51%|█████▏    | 99/193 [34:23<32:32, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 200 ==============================\n"," Train Loss 0.07742 | Val Loss 0.28695 | SMAPE 0.56694\n","\n","[('미라시아_버드와이저(무제한)',)] Epoch 50 ==============================\n"," Train Loss 0.18881 | Val Loss 0.36982 | SMAPE 0.72522\n","\n","[('미라시아_버드와이저(무제한)',)] Epoch 100 ==============================\n"," Train Loss 0.12869 | Val Loss 0.34819 | SMAPE 0.69270\n","\n","[('미라시아_버드와이저(무제한)',)] Epoch 150 ==============================\n"," Train Loss 0.09599 | Val Loss 0.33568 | SMAPE 0.67088\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  52%|█████▏    | 100/193 [34:44<32:20, 20.87s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_버드와이저(무제한)',)] Epoch 200 ==============================\n"," Train Loss 0.08149 | Val Loss 0.33653 | SMAPE 0.67599\n","\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 50 ==============================\n"," Train Loss 0.16480 | Val Loss 0.20723 | SMAPE 0.39179\n","\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 100 ==============================\n"," Train Loss 0.12060 | Val Loss 0.26829 | SMAPE 0.51586\n","\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 150 ==============================\n"," Train Loss 0.05812 | Val Loss 0.45569 | SMAPE 0.91144\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  52%|█████▏    | 101/193 [35:04<31:40, 20.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 200 ==============================\n"," Train Loss 0.05015 | Val Loss 0.62662 | SMAPE 1.22736\n","\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 50 ==============================\n"," Train Loss 0.14144 | Val Loss 0.23397 | SMAPE 0.43505\n","\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 100 ==============================\n"," Train Loss 0.08312 | Val Loss 0.39654 | SMAPE 0.78056\n","\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 150 ==============================\n"," Train Loss 0.06270 | Val Loss 0.54387 | SMAPE 1.11426\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  53%|█████▎    | 102/193 [35:25<31:20, 20.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 200 ==============================\n"," Train Loss 0.05311 | Val Loss 0.30386 | SMAPE 0.58310\n","\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 50 ==============================\n"," Train Loss 0.25794 | Val Loss 0.30580 | SMAPE 0.61047\n","\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 100 ==============================\n"," Train Loss 0.22295 | Val Loss 0.31468 | SMAPE 0.63869\n","\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 150 ==============================\n"," Train Loss 0.20897 | Val Loss 0.32040 | SMAPE 0.62455\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  53%|█████▎    | 103/193 [35:46<31:14, 20.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 200 ==============================\n"," Train Loss 0.20449 | Val Loss 0.31046 | SMAPE 0.62713\n","\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 50 ==============================\n"," Train Loss 0.11172 | Val Loss 0.09090 | SMAPE 0.14705\n","\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 100 ==============================\n"," Train Loss 0.06242 | Val Loss 0.12084 | SMAPE 0.20884\n","\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 150 ==============================\n"," Train Loss 0.04046 | Val Loss 0.12358 | SMAPE 0.21212\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  54%|█████▍    | 104/193 [36:07<30:56, 20.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 200 ==============================\n"," Train Loss 0.03086 | Val Loss 0.14510 | SMAPE 0.25546\n","\n","[('미라시아_브런치(대인) 주말',)] Epoch 50 ==============================\n"," Train Loss 0.24255 | Val Loss 0.44539 | SMAPE 0.87721\n","\n","[('미라시아_브런치(대인) 주말',)] Epoch 100 ==============================\n"," Train Loss 0.23239 | Val Loss 0.47332 | SMAPE 0.92922\n","\n","[('미라시아_브런치(대인) 주말',)] Epoch 150 ==============================\n"," Train Loss 0.22169 | Val Loss 0.44877 | SMAPE 0.85470\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  54%|█████▍    | 105/193 [36:28<30:46, 20.99s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치(대인) 주말',)] Epoch 200 ==============================\n"," Train Loss 0.20894 | Val Loss 0.51002 | SMAPE 0.98158\n","\n","[('미라시아_브런치(대인) 주중',)] Epoch 50 ==============================\n"," Train Loss 0.21150 | Val Loss 0.43296 | SMAPE 0.83456\n","\n","[('미라시아_브런치(대인) 주중',)] Epoch 100 ==============================\n"," Train Loss 0.17053 | Val Loss 0.46128 | SMAPE 0.88230\n","\n","[('미라시아_브런치(대인) 주중',)] Epoch 150 ==============================\n"," Train Loss 0.15332 | Val Loss 0.49102 | SMAPE 0.93895\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  55%|█████▍    | 106/193 [36:48<30:08, 20.79s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치(대인) 주중',)] Epoch 200 ==============================\n"," Train Loss 0.16527 | Val Loss 0.43642 | SMAPE 0.84936\n","\n","[('미라시아_브런치(어린이)',)] Epoch 50 ==============================\n"," Train Loss 0.17371 | Val Loss 0.50431 | SMAPE 0.97928\n","\n","[('미라시아_브런치(어린이)',)] Epoch 100 ==============================\n"," Train Loss 0.12464 | Val Loss 0.42961 | SMAPE 0.81559\n","\n","[('미라시아_브런치(어린이)',)] Epoch 150 ==============================\n"," Train Loss 0.10198 | Val Loss 0.43064 | SMAPE 0.83829\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  55%|█████▌    | 107/193 [37:09<29:58, 20.91s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치(어린이)',)] Epoch 200 ==============================\n"," Train Loss 0.08423 | Val Loss 0.42333 | SMAPE 0.80750\n","\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 50 ==============================\n"," Train Loss 0.18594 | Val Loss 0.29822 | SMAPE 0.59041\n","\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 100 ==============================\n"," Train Loss 0.14222 | Val Loss 0.47367 | SMAPE 0.93781\n","\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 150 ==============================\n"," Train Loss 0.08877 | Val Loss 0.46716 | SMAPE 0.92352\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  56%|█████▌    | 108/193 [37:29<29:13, 20.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 200 ==============================\n"," Train Loss 0.05743 | Val Loss 0.41655 | SMAPE 0.80708\n","\n","[('미라시아_스텔라(무제한)',)] Epoch 50 ==============================\n"," Train Loss 0.20077 | Val Loss 0.34143 | SMAPE 0.66179\n","\n","[('미라시아_스텔라(무제한)',)] Epoch 100 ==============================\n"," Train Loss 0.14320 | Val Loss 0.31223 | SMAPE 0.61963\n","\n","[('미라시아_스텔라(무제한)',)] Epoch 150 ==============================\n"," Train Loss 0.10127 | Val Loss 0.31988 | SMAPE 0.63509\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  56%|█████▋    | 109/193 [37:50<28:56, 20.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_스텔라(무제한)',)] Epoch 200 ==============================\n"," Train Loss 0.07220 | Val Loss 0.31330 | SMAPE 0.61424\n","\n","[('미라시아_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.14858 | Val Loss 0.33493 | SMAPE 0.63763\n","\n","[('미라시아_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.10085 | Val Loss 0.60430 | SMAPE 1.12341\n","\n","[('미라시아_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.07495 | Val Loss 0.27709 | SMAPE 0.53987\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  57%|█████▋    | 110/193 [38:11<28:41, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.05310 | Val Loss 0.53689 | SMAPE 1.03326\n","\n","[('미라시아_애플망고 에이드',)] Epoch 50 ==============================\n"," Train Loss 0.18954 | Val Loss 0.39452 | SMAPE 0.78128\n","\n","[('미라시아_애플망고 에이드',)] Epoch 100 ==============================\n"," Train Loss 0.12133 | Val Loss 0.37957 | SMAPE 0.74052\n","\n","[('미라시아_애플망고 에이드',)] Epoch 150 ==============================\n"," Train Loss 0.07034 | Val Loss 0.31881 | SMAPE 0.61698\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  58%|█████▊    | 111/193 [38:32<28:22, 20.76s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_애플망고 에이드',)] Epoch 200 ==============================\n"," Train Loss 0.05379 | Val Loss 0.34625 | SMAPE 0.67132\n","\n","[('미라시아_얼그레이 하이볼',)] Epoch 50 ==============================\n"," Train Loss 0.16498 | Val Loss 0.28923 | SMAPE 0.54751\n","\n","[('미라시아_얼그레이 하이볼',)] Epoch 100 ==============================\n"," Train Loss 0.11088 | Val Loss 0.31134 | SMAPE 0.59697\n","\n","[('미라시아_얼그레이 하이볼',)] Epoch 150 ==============================\n"," Train Loss 0.08879 | Val Loss 0.29553 | SMAPE 0.56987\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  58%|█████▊    | 112/193 [38:53<28:13, 20.91s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_얼그레이 하이볼',)] Epoch 200 ==============================\n"," Train Loss 0.06904 | Val Loss 0.28751 | SMAPE 0.55819\n","\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 50 ==============================\n"," Train Loss 0.14980 | Val Loss 0.27468 | SMAPE 0.53553\n","\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 100 ==============================\n"," Train Loss 0.12127 | Val Loss 0.25147 | SMAPE 0.49767\n","\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 150 ==============================\n"," Train Loss 0.09139 | Val Loss 0.24578 | SMAPE 0.47624\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  59%|█████▊    | 113/193 [39:14<27:43, 20.79s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 200 ==============================\n"," Train Loss 0.07352 | Val Loss 0.24314 | SMAPE 0.47266\n","\n","[('미라시아_유자 하이볼',)] Epoch 50 ==============================\n"," Train Loss 0.14090 | Val Loss 0.30100 | SMAPE 0.57199\n","\n","[('미라시아_유자 하이볼',)] Epoch 100 ==============================\n"," Train Loss 0.11615 | Val Loss 0.30709 | SMAPE 0.58311\n","\n","[('미라시아_유자 하이볼',)] Epoch 150 ==============================\n"," Train Loss 0.07991 | Val Loss 0.28634 | SMAPE 0.55243\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  59%|█████▉    | 114/193 [39:35<27:43, 21.06s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_유자 하이볼',)] Epoch 200 ==============================\n"," Train Loss 0.05701 | Val Loss 0.30732 | SMAPE 0.59351\n","\n","[('미라시아_잭 애플 토닉',)] Epoch 50 ==============================\n"," Train Loss 0.12529 | Val Loss 0.88799 | SMAPE 1.81685\n","\n","[('미라시아_잭 애플 토닉',)] Epoch 100 ==============================\n"," Train Loss 0.09434 | Val Loss 0.94036 | SMAPE 1.82204\n","\n","[('미라시아_잭 애플 토닉',)] Epoch 150 ==============================\n"," Train Loss 0.07514 | Val Loss 1.00789 | SMAPE 1.99872\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  60%|█████▉    | 115/193 [39:56<27:06, 20.85s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_잭 애플 토닉',)] Epoch 200 ==============================\n"," Train Loss 0.04886 | Val Loss 0.99241 | SMAPE 1.96322\n","\n","[('미라시아_칠리 치즈 프라이',)] Epoch 50 ==============================\n"," Train Loss 0.12822 | Val Loss 0.20149 | SMAPE 0.39322\n","\n","[('미라시아_칠리 치즈 프라이',)] Epoch 100 ==============================\n"," Train Loss 0.09907 | Val Loss 0.40845 | SMAPE 0.79401\n","\n","[('미라시아_칠리 치즈 프라이',)] Epoch 150 ==============================\n"," Train Loss 0.07013 | Val Loss 0.43431 | SMAPE 0.84016\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  60%|██████    | 116/193 [40:17<26:46, 20.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_칠리 치즈 프라이',)] Epoch 200 ==============================\n"," Train Loss 0.04657 | Val Loss 0.23994 | SMAPE 0.46750\n","\n","[('미라시아_코카콜라',)] Epoch 50 ==============================\n"," Train Loss 0.18223 | Val Loss 0.38181 | SMAPE 0.78042\n","\n","[('미라시아_코카콜라',)] Epoch 100 ==============================\n"," Train Loss 0.13785 | Val Loss 0.49901 | SMAPE 1.03855\n","\n","[('미라시아_코카콜라',)] Epoch 150 ==============================\n"," Train Loss 0.09206 | Val Loss 0.48624 | SMAPE 0.95911\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  61%|██████    | 117/193 [40:38<26:36, 21.00s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_코카콜라',)] Epoch 200 ==============================\n"," Train Loss 0.06639 | Val Loss 0.46498 | SMAPE 0.92531\n","\n","[('미라시아_코카콜라(제로)',)] Epoch 50 ==============================\n"," Train Loss 0.15373 | Val Loss 0.25828 | SMAPE 0.50685\n","\n","[('미라시아_코카콜라(제로)',)] Epoch 100 ==============================\n"," Train Loss 0.11497 | Val Loss 0.24498 | SMAPE 0.49447\n","\n","[('미라시아_코카콜라(제로)',)] Epoch 150 ==============================\n"," Train Loss 0.07625 | Val Loss 0.52599 | SMAPE 1.08278\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  61%|██████    | 118/193 [40:59<26:08, 20.92s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_코카콜라(제로)',)] Epoch 200 ==============================\n"," Train Loss 0.05416 | Val Loss 0.57935 | SMAPE 1.19060\n","\n","[('미라시아_콥 샐러드',)] Epoch 50 ==============================\n"," Train Loss 0.10351 | Val Loss 0.31252 | SMAPE 0.57878\n","\n","[('미라시아_콥 샐러드',)] Epoch 100 ==============================\n"," Train Loss 0.06917 | Val Loss 0.33541 | SMAPE 0.61233\n","\n","[('미라시아_콥 샐러드',)] Epoch 150 ==============================\n"," Train Loss 0.05602 | Val Loss 0.31453 | SMAPE 0.57945\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  62%|██████▏   | 119/193 [41:20<26:00, 21.09s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_콥 샐러드',)] Epoch 200 ==============================\n"," Train Loss 0.04673 | Val Loss 0.35187 | SMAPE 0.63511\n","\n","[('미라시아_파스타면 추가(150g)',)] Epoch 50 ==============================\n"," Train Loss 0.15778 | Val Loss 0.18427 | SMAPE 0.36186\n","\n","[('미라시아_파스타면 추가(150g)',)] Epoch 100 ==============================\n"," Train Loss 0.09914 | Val Loss 0.18793 | SMAPE 0.37242\n","\n","[('미라시아_파스타면 추가(150g)',)] Epoch 150 ==============================\n"," Train Loss 0.07671 | Val Loss 0.55151 | SMAPE 1.10533\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  62%|██████▏   | 120/193 [41:41<25:26, 20.90s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_파스타면 추가(150g)',)] Epoch 200 ==============================\n"," Train Loss 0.05324 | Val Loss 0.70727 | SMAPE 1.40076\n","\n","[('미라시아_핑크레몬에이드',)] Epoch 50 ==============================\n"," Train Loss 0.16680 | Val Loss 0.17525 | SMAPE 0.34952\n","\n","[('미라시아_핑크레몬에이드',)] Epoch 100 ==============================\n"," Train Loss 0.11352 | Val Loss 0.24573 | SMAPE 0.48952\n","\n","[('미라시아_핑크레몬에이드',)] Epoch 150 ==============================\n"," Train Loss 0.07503 | Val Loss 0.23166 | SMAPE 0.47011\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  63%|██████▎   | 121/193 [42:02<25:09, 20.96s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_핑크레몬에이드',)] Epoch 200 ==============================\n"," Train Loss 0.04642 | Val Loss 0.20547 | SMAPE 0.41179\n","\n","[('연회장_Cass Beer',)] Epoch 50 ==============================\n"," Train Loss 0.20434 | Val Loss 0.35689 | SMAPE 0.65410\n","\n","[('연회장_Cass Beer',)] Epoch 100 ==============================\n"," Train Loss 0.15143 | Val Loss 0.36004 | SMAPE 0.68998\n","\n","[('연회장_Cass Beer',)] Epoch 150 ==============================\n"," Train Loss 0.10875 | Val Loss 0.36801 | SMAPE 0.68100\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  63%|██████▎   | 122/193 [42:22<24:40, 20.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Cass Beer',)] Epoch 200 ==============================\n"," Train Loss 0.08422 | Val Loss 0.36453 | SMAPE 0.66652\n","\n","[('연회장_Conference L1',)] Epoch 50 ==============================\n"," Train Loss 0.05758 | Val Loss 0.06658 | SMAPE 0.03628\n","\n","[('연회장_Conference L1',)] Epoch 100 ==============================\n"," Train Loss 0.05886 | Val Loss 0.06699 | SMAPE 0.03602\n","\n","[('연회장_Conference L1',)] Epoch 150 ==============================\n"," Train Loss 0.05635 | Val Loss 0.06633 | SMAPE 0.03600\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  64%|██████▎   | 123/193 [42:43<24:14, 20.78s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference L1',)] Epoch 200 ==============================\n"," Train Loss 0.04866 | Val Loss 0.06805 | SMAPE 0.04727\n","\n","[('연회장_Conference L2',)] Epoch 50 ==============================\n"," Train Loss 0.05177 | Val Loss 0.04659 | SMAPE 0.05249\n","\n","[('연회장_Conference L2',)] Epoch 100 ==============================\n"," Train Loss 0.05202 | Val Loss 0.04021 | SMAPE 0.03834\n","\n","[('연회장_Conference L2',)] Epoch 150 ==============================\n"," Train Loss 0.05087 | Val Loss 0.04096 | SMAPE 0.03923\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  64%|██████▍   | 124/193 [43:04<24:04, 20.94s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference L2',)] Epoch 200 ==============================\n"," Train Loss 0.04675 | Val Loss 0.04150 | SMAPE 0.03875\n","\n","[('연회장_Conference L3',)] Epoch 50 ==============================\n"," Train Loss 0.05384 | Val Loss 0.05288 | SMAPE 0.01236\n","\n","[('연회장_Conference L3',)] Epoch 100 ==============================\n"," Train Loss 0.04829 | Val Loss 0.05259 | SMAPE 0.01102\n","\n","[('연회장_Conference L3',)] Epoch 150 ==============================\n"," Train Loss 0.03627 | Val Loss 0.06689 | SMAPE 0.05299\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  65%|██████▍   | 125/193 [43:24<23:13, 20.50s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference L3',)] Epoch 200 ==============================\n"," Train Loss 0.02608 | Val Loss 0.11898 | SMAPE 0.17975\n","\n","[('연회장_Conference M1',)] Epoch 50 ==============================\n"," Train Loss 0.05278 | Val Loss 0.04836 | SMAPE 0.00903\n","\n","[('연회장_Conference M1',)] Epoch 100 ==============================\n"," Train Loss 0.05255 | Val Loss 0.04689 | SMAPE 0.00820\n","\n","[('연회장_Conference M1',)] Epoch 150 ==============================\n"," Train Loss 0.05414 | Val Loss 0.04838 | SMAPE 0.00678\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  65%|██████▌   | 126/193 [43:45<23:07, 20.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference M1',)] Epoch 200 ==============================\n"," Train Loss 0.05217 | Val Loss 0.04894 | SMAPE 0.01206\n","\n","[('연회장_Conference M8',)] Epoch 50 ==============================\n"," Train Loss 0.05936 | Val Loss 0.05138 | SMAPE 0.00621\n","\n","[('연회장_Conference M8',)] Epoch 100 ==============================\n"," Train Loss 0.05716 | Val Loss 0.05175 | SMAPE 0.00772\n","\n","[('연회장_Conference M8',)] Epoch 150 ==============================\n"," Train Loss 0.05603 | Val Loss 0.05240 | SMAPE 0.00748\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  66%|██████▌   | 127/193 [44:05<22:39, 20.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference M8',)] Epoch 200 ==============================\n"," Train Loss 0.05362 | Val Loss 0.05047 | SMAPE 0.00315\n","\n","[('연회장_Conference M9',)] Epoch 50 ==============================\n"," Train Loss 0.05770 | Val Loss 0.05009 | SMAPE 0.01025\n","\n","[('연회장_Conference M9',)] Epoch 100 ==============================\n"," Train Loss 0.05543 | Val Loss 0.05116 | SMAPE 0.01059\n","\n","[('연회장_Conference M9',)] Epoch 150 ==============================\n"," Train Loss 0.03905 | Val Loss 0.08978 | SMAPE 0.07614\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  66%|██████▋   | 128/193 [44:27<22:31, 20.78s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference M9',)] Epoch 200 ==============================\n"," Train Loss 0.03029 | Val Loss 0.17805 | SMAPE 0.24759\n","\n","[('연회장_Convention Hall',)] Epoch 50 ==============================\n"," Train Loss 0.04708 | Val Loss 0.01859 | SMAPE 0.00508\n","\n","[('연회장_Convention Hall',)] Epoch 100 ==============================\n"," Train Loss 0.04666 | Val Loss 0.01844 | SMAPE 0.00666\n","\n","[('연회장_Convention Hall',)] Epoch 150 ==============================\n"," Train Loss 0.04605 | Val Loss 0.01851 | SMAPE 0.00525\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  67%|██████▋   | 129/193 [44:46<21:51, 20.48s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Convention Hall',)] Epoch 200 ==============================\n"," Train Loss 0.04603 | Val Loss 0.01621 | SMAPE 0.00147\n","\n","[('연회장_Cookie Platter',)] Epoch 50 ==============================\n"," Train Loss 0.20450 | Val Loss 0.33615 | SMAPE 0.65499\n","\n","[('연회장_Cookie Platter',)] Epoch 100 ==============================\n"," Train Loss 0.14085 | Val Loss 0.36728 | SMAPE 0.73150\n","\n","[('연회장_Cookie Platter',)] Epoch 150 ==============================\n"," Train Loss 0.09982 | Val Loss 0.36948 | SMAPE 0.72802\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  67%|██████▋   | 130/193 [45:07<21:38, 20.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Cookie Platter',)] Epoch 200 ==============================\n"," Train Loss 0.07731 | Val Loss 0.38052 | SMAPE 0.75084\n","\n","[('연회장_Grand Ballroom',)] Epoch 50 ==============================\n"," Train Loss 0.08217 | Val Loss 0.07734 | SMAPE 0.05966\n","\n","[('연회장_Grand Ballroom',)] Epoch 100 ==============================\n"," Train Loss 0.07503 | Val Loss 0.10580 | SMAPE 0.11141\n","\n","[('연회장_Grand Ballroom',)] Epoch 150 ==============================\n"," Train Loss 0.06827 | Val Loss 0.14293 | SMAPE 0.19302\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  68%|██████▊   | 131/193 [45:28<21:26, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Grand Ballroom',)] Epoch 200 ==============================\n"," Train Loss 0.06234 | Val Loss 0.22094 | SMAPE 0.33741\n","\n","[('연회장_OPUS 2',)] Epoch 50 ==============================\n"," Train Loss 0.07178 | Val Loss 0.04952 | SMAPE 0.00577\n","\n","[('연회장_OPUS 2',)] Epoch 100 ==============================\n"," Train Loss 0.06934 | Val Loss 0.05833 | SMAPE 0.02560\n","\n","[('연회장_OPUS 2',)] Epoch 150 ==============================\n"," Train Loss 0.07336 | Val Loss 0.05085 | SMAPE 0.00720\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  68%|██████▊   | 132/193 [45:49<21:07, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_OPUS 2',)] Epoch 200 ==============================\n"," Train Loss 0.06358 | Val Loss 0.04724 | SMAPE 0.00698\n","\n","[('연회장_Regular Coffee',)] Epoch 50 ==============================\n"," Train Loss 0.17724 | Val Loss 0.36862 | SMAPE 0.72777\n","\n","[('연회장_Regular Coffee',)] Epoch 100 ==============================\n"," Train Loss 0.12086 | Val Loss 0.39206 | SMAPE 0.78460\n","\n","[('연회장_Regular Coffee',)] Epoch 150 ==============================\n"," Train Loss 0.11335 | Val Loss 0.37506 | SMAPE 0.73573\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  69%|██████▉   | 133/193 [46:11<20:57, 20.96s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Regular Coffee',)] Epoch 200 ==============================\n"," Train Loss 0.10495 | Val Loss 0.37673 | SMAPE 0.73909\n","\n","[('연회장_골뱅이무침',)] Epoch 50 ==============================\n"," Train Loss 0.10535 | Val Loss 0.24390 | SMAPE 0.46939\n","\n","[('연회장_골뱅이무침',)] Epoch 100 ==============================\n"," Train Loss 0.07133 | Val Loss 0.27010 | SMAPE 0.50720\n","\n","[('연회장_골뱅이무침',)] Epoch 150 ==============================\n"," Train Loss 0.05460 | Val Loss 0.28225 | SMAPE 0.54372\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  69%|██████▉   | 134/193 [46:31<20:32, 20.89s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_골뱅이무침',)] Epoch 200 ==============================\n"," Train Loss 0.04376 | Val Loss 0.29537 | SMAPE 0.57196\n","\n","[('연회장_공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.19322 | Val Loss 0.53338 | SMAPE 1.07751\n","\n","[('연회장_공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.15638 | Val Loss 0.60963 | SMAPE 1.20886\n","\n","[('연회장_공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.12193 | Val Loss 0.56264 | SMAPE 1.10155\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  70%|██████▉   | 135/193 [46:53<20:22, 21.07s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.08417 | Val Loss 0.77144 | SMAPE 1.51331\n","\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 50 ==============================\n"," Train Loss 0.15716 | Val Loss 0.32156 | SMAPE 0.58352\n","\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 100 ==============================\n"," Train Loss 0.11158 | Val Loss 0.31894 | SMAPE 0.62216\n","\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 150 ==============================\n"," Train Loss 0.08189 | Val Loss 0.31623 | SMAPE 0.61308\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  70%|███████   | 136/193 [47:13<19:49, 20.88s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 200 ==============================\n"," Train Loss 0.05776 | Val Loss 0.31042 | SMAPE 0.60896\n","\n","[('연회장_로제 치즈떡볶이',)] Epoch 50 ==============================\n"," Train Loss 0.14021 | Val Loss 0.22736 | SMAPE 0.45211\n","\n","[('연회장_로제 치즈떡볶이',)] Epoch 100 ==============================\n"," Train Loss 0.09104 | Val Loss 0.21470 | SMAPE 0.41801\n","\n","[('연회장_로제 치즈떡볶이',)] Epoch 150 ==============================\n"," Train Loss 0.06978 | Val Loss 0.21227 | SMAPE 0.41498\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  71%|███████   | 137/193 [47:34<19:30, 20.91s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_로제 치즈떡볶이',)] Epoch 200 ==============================\n"," Train Loss 0.05512 | Val Loss 0.21821 | SMAPE 0.42346\n","\n","[('연회장_마라샹궈',)] Epoch 50 ==============================\n"," Train Loss 0.15141 | Val Loss 0.81241 | SMAPE 1.63229\n","\n","[('연회장_마라샹궈',)] Epoch 100 ==============================\n"," Train Loss 0.10099 | Val Loss 0.45807 | SMAPE 0.92477\n","\n","[('연회장_마라샹궈',)] Epoch 150 ==============================\n"," Train Loss 0.06789 | Val Loss 0.77812 | SMAPE 1.56279\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  72%|███████▏  | 138/193 [47:56<19:19, 21.09s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_마라샹궈',)] Epoch 200 ==============================\n"," Train Loss 0.05332 | Val Loss 0.75667 | SMAPE 1.52049\n","\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 50 ==============================\n"," Train Loss 0.14202 | Val Loss 0.26464 | SMAPE 0.51201\n","\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 100 ==============================\n"," Train Loss 0.08538 | Val Loss 0.27586 | SMAPE 0.54249\n","\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 150 ==============================\n"," Train Loss 0.05564 | Val Loss 0.27203 | SMAPE 0.53111\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  72%|███████▏  | 139/193 [48:16<18:51, 20.95s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 200 ==============================\n"," Train Loss 0.04533 | Val Loss 0.27579 | SMAPE 0.53663\n","\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 50 ==============================\n"," Train Loss 0.11883 | Val Loss 0.23026 | SMAPE 0.44019\n","\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 100 ==============================\n"," Train Loss 0.08654 | Val Loss 0.23783 | SMAPE 0.45272\n","\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 150 ==============================\n"," Train Loss 0.06808 | Val Loss 0.24146 | SMAPE 0.45903\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  73%|███████▎  | 140/193 [48:38<18:38, 21.11s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 200 ==============================\n"," Train Loss 0.05268 | Val Loss 0.24683 | SMAPE 0.46424\n","\n","[('연회장_삼겹살추가 (200g)',)] Epoch 50 ==============================\n"," Train Loss 0.13733 | Val Loss 0.39436 | SMAPE 0.74475\n","\n","[('연회장_삼겹살추가 (200g)',)] Epoch 100 ==============================\n"," Train Loss 0.09214 | Val Loss 0.76453 | SMAPE 1.44715\n","\n","[('연회장_삼겹살추가 (200g)',)] Epoch 150 ==============================\n"," Train Loss 0.08224 | Val Loss 0.88406 | SMAPE 1.74757\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  73%|███████▎  | 141/193 [48:58<18:10, 20.96s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_삼겹살추가 (200g)',)] Epoch 200 ==============================\n"," Train Loss 0.05942 | Val Loss 0.85128 | SMAPE 1.64984\n","\n","[('연회장_야채추가',)] Epoch 50 ==============================\n"," Train Loss 0.09559 | Val Loss 0.21377 | SMAPE 0.42343\n","\n","[('연회장_야채추가',)] Epoch 100 ==============================\n"," Train Loss 0.06788 | Val Loss 0.19031 | SMAPE 0.37505\n","\n","[('연회장_야채추가',)] Epoch 150 ==============================\n"," Train Loss 0.04399 | Val Loss 0.21741 | SMAPE 0.42505\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  74%|███████▎  | 142/193 [49:20<17:54, 21.08s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_야채추가',)] Epoch 200 ==============================\n"," Train Loss 0.03349 | Val Loss 0.23210 | SMAPE 0.43818\n","\n","[('연회장_왕갈비치킨',)] Epoch 50 ==============================\n"," Train Loss 0.14391 | Val Loss 0.89231 | SMAPE 1.78887\n","\n","[('연회장_왕갈비치킨',)] Epoch 100 ==============================\n"," Train Loss 0.09839 | Val Loss 1.01020 | SMAPE 1.97552\n","\n","[('연회장_왕갈비치킨',)] Epoch 150 ==============================\n"," Train Loss 0.07597 | Val Loss 0.92562 | SMAPE 1.79786\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  74%|███████▍  | 143/193 [49:41<17:29, 20.99s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_왕갈비치킨',)] Epoch 200 ==============================\n"," Train Loss 0.04843 | Val Loss 0.99841 | SMAPE 1.96356\n","\n","[('연회장_주먹밥 (2ea)',)] Epoch 50 ==============================\n"," Train Loss 0.14520 | Val Loss 0.22801 | SMAPE 0.42941\n","\n","[('연회장_주먹밥 (2ea)',)] Epoch 100 ==============================\n"," Train Loss 0.09680 | Val Loss 0.21467 | SMAPE 0.41435\n","\n","[('연회장_주먹밥 (2ea)',)] Epoch 150 ==============================\n"," Train Loss 0.06937 | Val Loss 0.21113 | SMAPE 0.40470\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  75%|███████▍  | 144/193 [50:01<17:04, 20.90s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_주먹밥 (2ea)',)] Epoch 200 ==============================\n"," Train Loss 0.05342 | Val Loss 0.21446 | SMAPE 0.40903\n","\n","[('카페테리아_공깃밥(추가)',)] Epoch 50 ==============================\n"," Train Loss 0.20901 | Val Loss 0.38850 | SMAPE 0.76446\n","\n","[('카페테리아_공깃밥(추가)',)] Epoch 100 ==============================\n"," Train Loss 0.17167 | Val Loss 0.35931 | SMAPE 0.70872\n","\n","[('카페테리아_공깃밥(추가)',)] Epoch 150 ==============================\n"," Train Loss 0.14934 | Val Loss 0.34995 | SMAPE 0.69466\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  75%|███████▌  | 145/193 [50:22<16:35, 20.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_공깃밥(추가)',)] Epoch 200 ==============================\n"," Train Loss 0.13670 | Val Loss 0.32907 | SMAPE 0.65538\n","\n","[('카페테리아_구슬아이스크림',)] Epoch 50 ==============================\n"," Train Loss 0.25872 | Val Loss 0.50163 | SMAPE 1.00056\n","\n","[('카페테리아_구슬아이스크림',)] Epoch 100 ==============================\n"," Train Loss 0.25931 | Val Loss 0.12880 | SMAPE 0.25740\n","\n","[('카페테리아_구슬아이스크림',)] Epoch 150 ==============================\n"," Train Loss 0.16943 | Val Loss 0.32689 | SMAPE 0.65367\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  76%|███████▌  | 146/193 [50:42<16:06, 20.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_구슬아이스크림',)] Epoch 200 ==============================\n"," Train Loss 0.12025 | Val Loss 0.41998 | SMAPE 0.83983\n","\n","[('카페테리아_단체식 13000(신)',)] Epoch 50 ==============================\n"," Train Loss 0.19658 | Val Loss 0.35257 | SMAPE 0.69878\n","\n","[('카페테리아_단체식 13000(신)',)] Epoch 100 ==============================\n"," Train Loss 0.14470 | Val Loss 0.41706 | SMAPE 0.79685\n","\n","[('카페테리아_단체식 13000(신)',)] Epoch 150 ==============================\n"," Train Loss 0.09329 | Val Loss 0.38742 | SMAPE 0.76768\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  76%|███████▌  | 147/193 [51:03<15:55, 20.78s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_단체식 13000(신)',)] Epoch 200 ==============================\n"," Train Loss 0.07574 | Val Loss 0.40347 | SMAPE 0.79205\n","\n","[('카페테리아_단체식 18000(신)',)] Epoch 50 ==============================\n"," Train Loss 0.17427 | Val Loss 0.42481 | SMAPE 0.82077\n","\n","[('카페테리아_단체식 18000(신)',)] Epoch 100 ==============================\n"," Train Loss 0.12314 | Val Loss 0.42786 | SMAPE 0.82889\n","\n","[('카페테리아_단체식 18000(신)',)] Epoch 150 ==============================\n"," Train Loss 0.09287 | Val Loss 0.41499 | SMAPE 0.80996\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  77%|███████▋  | 148/193 [51:23<15:31, 20.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_단체식 18000(신)',)] Epoch 200 ==============================\n"," Train Loss 0.06762 | Val Loss 0.41082 | SMAPE 0.79364\n","\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 50 ==============================\n"," Train Loss 0.18449 | Val Loss 0.32877 | SMAPE 0.65268\n","\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 100 ==============================\n"," Train Loss 0.16368 | Val Loss 0.36184 | SMAPE 0.72151\n","\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 150 ==============================\n"," Train Loss 0.12980 | Val Loss 0.35284 | SMAPE 0.69445\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  77%|███████▋  | 149/193 [51:45<15:16, 20.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 200 ==============================\n"," Train Loss 0.11148 | Val Loss 0.34100 | SMAPE 0.67573\n","\n","[('카페테리아_복숭아 아이스티',)] Epoch 50 ==============================\n"," Train Loss 0.24065 | Val Loss 0.64793 | SMAPE 1.29005\n","\n","[('카페테리아_복숭아 아이스티',)] Epoch 100 ==============================\n"," Train Loss 0.17168 | Val Loss 0.77120 | SMAPE 1.53349\n","\n","[('카페테리아_복숭아 아이스티',)] Epoch 150 ==============================\n"," Train Loss 0.13671 | Val Loss 0.75209 | SMAPE 1.49521\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  78%|███████▊  | 150/193 [52:05<14:53, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_복숭아 아이스티',)] Epoch 200 ==============================\n"," Train Loss 0.10171 | Val Loss 0.78523 | SMAPE 1.55956\n","\n","[('카페테리아_새우 볶음밥',)] Epoch 50 ==============================\n"," Train Loss 0.18935 | Val Loss 0.35772 | SMAPE 0.72697\n","\n","[('카페테리아_새우 볶음밥',)] Epoch 100 ==============================\n"," Train Loss 0.14701 | Val Loss 0.35760 | SMAPE 0.71407\n","\n","[('카페테리아_새우 볶음밥',)] Epoch 150 ==============================\n"," Train Loss 0.13325 | Val Loss 0.34646 | SMAPE 0.69922\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  78%|███████▊  | 151/193 [52:26<14:31, 20.76s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_새우 볶음밥',)] Epoch 200 ==============================\n"," Train Loss 0.10383 | Val Loss 0.36893 | SMAPE 0.73353\n","\n","[('카페테리아_새우튀김 우동',)] Epoch 50 ==============================\n"," Train Loss 0.19823 | Val Loss 0.61673 | SMAPE 1.22751\n","\n","[('카페테리아_새우튀김 우동',)] Epoch 100 ==============================\n"," Train Loss 0.13485 | Val Loss 0.73721 | SMAPE 1.46389\n","\n","[('카페테리아_새우튀김 우동',)] Epoch 150 ==============================\n"," Train Loss 0.17064 | Val Loss 0.73251 | SMAPE 1.44834\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  79%|███████▉  | 152/193 [52:46<14:04, 20.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_새우튀김 우동',)] Epoch 200 ==============================\n"," Train Loss 0.13411 | Val Loss 0.80417 | SMAPE 1.60060\n","\n","[('카페테리아_샷 추가',)] Epoch 50 ==============================\n"," Train Loss 0.24550 | Val Loss 0.00269 | SMAPE 0.00000\n","\n","[('카페테리아_샷 추가',)] Epoch 100 ==============================\n"," Train Loss 0.20249 | Val Loss 0.00288 | SMAPE 0.00000\n","\n","[('카페테리아_샷 추가',)] Epoch 150 ==============================\n"," Train Loss 0.15317 | Val Loss 0.00234 | SMAPE 0.00000\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  79%|███████▉  | 153/193 [53:06<13:38, 20.47s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_샷 추가',)] Epoch 200 ==============================\n"," Train Loss 0.10074 | Val Loss 0.00259 | SMAPE 0.00000\n","\n","[('카페테리아_수제 등심 돈까스',)] Epoch 50 ==============================\n"," Train Loss 0.20169 | Val Loss 0.35117 | SMAPE 0.69858\n","\n","[('카페테리아_수제 등심 돈까스',)] Epoch 100 ==============================\n"," Train Loss 0.16760 | Val Loss 0.34709 | SMAPE 0.69300\n","\n","[('카페테리아_수제 등심 돈까스',)] Epoch 150 ==============================\n"," Train Loss 0.14054 | Val Loss 0.33148 | SMAPE 0.66508\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  80%|███████▉  | 154/193 [53:28<13:28, 20.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_수제 등심 돈까스',)] Epoch 200 ==============================\n"," Train Loss 0.11941 | Val Loss 0.33075 | SMAPE 0.65816\n","\n","[('카페테리아_아메리카노(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.17045 | Val Loss 0.38966 | SMAPE 0.77812\n","\n","[('카페테리아_아메리카노(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.14877 | Val Loss 0.54827 | SMAPE 1.09368\n","\n","[('카페테리아_아메리카노(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.12662 | Val Loss 0.59724 | SMAPE 1.19223\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  80%|████████  | 155/193 [53:48<13:03, 20.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_아메리카노(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.10785 | Val Loss 0.61417 | SMAPE 1.22673\n","\n","[('카페테리아_아메리카노(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.11424 | Val Loss 0.84439 | SMAPE 1.68001\n","\n","[('카페테리아_아메리카노(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.07840 | Val Loss 0.85949 | SMAPE 1.71000\n","\n","[('카페테리아_아메리카노(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.06922 | Val Loss 0.88953 | SMAPE 1.76919\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  81%|████████  | 156/193 [54:09<12:47, 20.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_아메리카노(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.05830 | Val Loss 0.87537 | SMAPE 1.74201\n","\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 50 ==============================\n"," Train Loss 0.18080 | Val Loss 0.31504 | SMAPE 0.62400\n","\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 100 ==============================\n"," Train Loss 0.15102 | Val Loss 0.36105 | SMAPE 0.70821\n","\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 150 ==============================\n"," Train Loss 0.13471 | Val Loss 0.35603 | SMAPE 0.69548\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  81%|████████▏ | 157/193 [54:30<12:27, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 200 ==============================\n"," Train Loss 0.10586 | Val Loss 0.38263 | SMAPE 0.74993\n","\n","[('카페테리아_어린이 돈까스',)] Epoch 50 ==============================\n"," Train Loss 0.17558 | Val Loss 0.30142 | SMAPE 0.61700\n","\n","[('카페테리아_어린이 돈까스',)] Epoch 100 ==============================\n"," Train Loss 0.13513 | Val Loss 0.31160 | SMAPE 0.62720\n","\n","[('카페테리아_어린이 돈까스',)] Epoch 150 ==============================\n"," Train Loss 0.11049 | Val Loss 0.31805 | SMAPE 0.64640\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  82%|████████▏ | 158/193 [54:51<12:07, 20.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_어린이 돈까스',)] Epoch 200 ==============================\n"," Train Loss 0.09192 | Val Loss 0.30471 | SMAPE 0.60844\n","\n","[('카페테리아_오픈푸드',)] Epoch 50 ==============================\n"," Train Loss 0.88739 | Val Loss 0.70357 | SMAPE 1.45977\n","\n","[('카페테리아_오픈푸드',)] Epoch 100 ==============================\n"," Train Loss 0.60136 | Val Loss 0.31661 | SMAPE 0.73239\n","\n","[('카페테리아_오픈푸드',)] Epoch 150 ==============================\n"," Train Loss 0.67422 | Val Loss 0.43057 | SMAPE 0.70847\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  82%|████████▏ | 159/193 [55:12<11:49, 20.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_오픈푸드',)] Epoch 200 ==============================\n"," Train Loss 0.56290 | Val Loss 0.24722 | SMAPE 0.50436\n","\n","[('카페테리아_진사골 설렁탕',)] Epoch 50 ==============================\n"," Train Loss 0.11378 | Val Loss 0.81912 | SMAPE 1.57957\n","\n","[('카페테리아_진사골 설렁탕',)] Epoch 100 ==============================\n"," Train Loss 0.13404 | Val Loss 0.80357 | SMAPE 1.59443\n","\n","[('카페테리아_진사골 설렁탕',)] Epoch 150 ==============================\n"," Train Loss 0.14425 | Val Loss 0.85479 | SMAPE 1.62728\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  83%|████████▎ | 160/193 [55:32<11:22, 20.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_진사골 설렁탕',)] Epoch 200 ==============================\n"," Train Loss 0.09990 | Val Loss 0.82681 | SMAPE 1.58434\n","\n","[('카페테리아_짜장면',)] Epoch 50 ==============================\n"," Train Loss 0.22186 | Val Loss 0.31301 | SMAPE 0.64825\n","\n","[('카페테리아_짜장면',)] Epoch 100 ==============================\n"," Train Loss 0.17277 | Val Loss 0.31028 | SMAPE 0.63373\n","\n","[('카페테리아_짜장면',)] Epoch 150 ==============================\n"," Train Loss 0.14005 | Val Loss 0.32639 | SMAPE 0.65829\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  83%|████████▎ | 161/193 [55:53<11:03, 20.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짜장면',)] Epoch 200 ==============================\n"," Train Loss 0.12871 | Val Loss 0.32222 | SMAPE 0.64779\n","\n","[('카페테리아_짜장밥',)] Epoch 50 ==============================\n"," Train Loss 0.15316 | Val Loss 0.23397 | SMAPE 0.46801\n","\n","[('카페테리아_짜장밥',)] Epoch 100 ==============================\n"," Train Loss 0.10706 | Val Loss 0.24492 | SMAPE 0.49289\n","\n","[('카페테리아_짜장밥',)] Epoch 150 ==============================\n"," Train Loss 0.08578 | Val Loss 0.23182 | SMAPE 0.45822\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  84%|████████▍ | 162/193 [56:13<10:39, 20.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짜장밥',)] Epoch 200 ==============================\n"," Train Loss 0.07357 | Val Loss 0.22747 | SMAPE 0.45623\n","\n","[('카페테리아_짬뽕',)] Epoch 50 ==============================\n"," Train Loss 0.21272 | Val Loss 0.30867 | SMAPE 0.62723\n","\n","[('카페테리아_짬뽕',)] Epoch 100 ==============================\n"," Train Loss 0.16357 | Val Loss 0.37359 | SMAPE 0.74279\n","\n","[('카페테리아_짬뽕',)] Epoch 150 ==============================\n"," Train Loss 0.12714 | Val Loss 0.35719 | SMAPE 0.69790\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  84%|████████▍ | 163/193 [56:35<10:25, 20.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짬뽕',)] Epoch 200 ==============================\n"," Train Loss 0.11229 | Val Loss 0.35301 | SMAPE 0.69386\n","\n","[('카페테리아_짬뽕밥',)] Epoch 50 ==============================\n"," Train Loss 0.19119 | Val Loss 0.30059 | SMAPE 0.59555\n","\n","[('카페테리아_짬뽕밥',)] Epoch 100 ==============================\n"," Train Loss 0.14781 | Val Loss 0.31645 | SMAPE 0.62789\n","\n","[('카페테리아_짬뽕밥',)] Epoch 150 ==============================\n"," Train Loss 0.12918 | Val Loss 0.31052 | SMAPE 0.61942\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  85%|████████▍ | 164/193 [56:55<10:01, 20.76s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짬뽕밥',)] Epoch 200 ==============================\n"," Train Loss 0.10981 | Val Loss 0.33982 | SMAPE 0.66890\n","\n","[('카페테리아_치즈돈까스',)] Epoch 50 ==============================\n"," Train Loss 0.22430 | Val Loss 0.35359 | SMAPE 0.70863\n","\n","[('카페테리아_치즈돈까스',)] Epoch 100 ==============================\n"," Train Loss 0.17053 | Val Loss 0.35692 | SMAPE 0.70761\n","\n","[('카페테리아_치즈돈까스',)] Epoch 150 ==============================\n"," Train Loss 0.14694 | Val Loss 0.34467 | SMAPE 0.68963\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  85%|████████▌ | 165/193 [57:16<09:44, 20.87s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_치즈돈까스',)] Epoch 200 ==============================\n"," Train Loss 0.12609 | Val Loss 0.37613 | SMAPE 0.75507\n","\n","[('카페테리아_카페라떼(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.18178 | Val Loss 0.50388 | SMAPE 1.00538\n","\n","[('카페테리아_카페라떼(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.13168 | Val Loss 0.82817 | SMAPE 1.65080\n","\n","[('카페테리아_카페라떼(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.09668 | Val Loss 0.84858 | SMAPE 1.69343\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  86%|████████▌ | 166/193 [57:37<09:24, 20.91s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_카페라떼(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.06911 | Val Loss 0.90607 | SMAPE 1.80878\n","\n","[('카페테리아_카페라떼(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.14649 | Val Loss 0.88342 | SMAPE 1.76075\n","\n","[('카페테리아_카페라떼(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.15291 | Val Loss 0.90807 | SMAPE 1.80521\n","\n","[('카페테리아_카페라떼(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.09654 | Val Loss 0.92284 | SMAPE 1.83634\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  87%|████████▋ | 167/193 [57:58<09:03, 20.90s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_카페라떼(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.07856 | Val Loss 0.87670 | SMAPE 1.74367\n","\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 50 ==============================\n"," Train Loss 0.16113 | Val Loss 0.32466 | SMAPE 0.62951\n","\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 100 ==============================\n"," Train Loss 0.11638 | Val Loss 0.34733 | SMAPE 0.67636\n","\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 150 ==============================\n"," Train Loss 0.08789 | Val Loss 0.37064 | SMAPE 0.70816\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  87%|████████▋ | 168/193 [58:19<08:39, 20.79s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 200 ==============================\n"," Train Loss 0.06556 | Val Loss 0.34873 | SMAPE 0.67712\n","\n","[('포레스트릿_꼬치어묵',)] Epoch 50 ==============================\n"," Train Loss 0.31690 | Val Loss 0.36775 | SMAPE 0.70478\n","\n","[('포레스트릿_꼬치어묵',)] Epoch 100 ==============================\n"," Train Loss 0.30497 | Val Loss 0.47498 | SMAPE 0.91354\n","\n","[('포레스트릿_꼬치어묵',)] Epoch 150 ==============================\n"," Train Loss 0.23104 | Val Loss 0.35903 | SMAPE 0.73209\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  88%|████████▊ | 169/193 [58:39<08:13, 20.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_꼬치어묵',)] Epoch 200 ==============================\n"," Train Loss 0.20308 | Val Loss 0.37452 | SMAPE 0.75163\n","\n","[('포레스트릿_떡볶이',)] Epoch 50 ==============================\n"," Train Loss 0.43224 | Val Loss 0.45521 | SMAPE 1.03012\n","\n","[('포레스트릿_떡볶이',)] Epoch 100 ==============================\n"," Train Loss 0.29635 | Val Loss 0.35805 | SMAPE 0.73751\n","\n","[('포레스트릿_떡볶이',)] Epoch 150 ==============================\n"," Train Loss 0.26065 | Val Loss 0.43031 | SMAPE 0.83726\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  88%|████████▊ | 170/193 [59:00<07:57, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_떡볶이',)] Epoch 200 ==============================\n"," Train Loss 0.22263 | Val Loss 0.46192 | SMAPE 0.91212\n","\n","[('포레스트릿_복숭아 아이스티',)] Epoch 50 ==============================\n"," Train Loss 0.30529 | Val Loss 0.89591 | SMAPE 1.78202\n","\n","[('포레스트릿_복숭아 아이스티',)] Epoch 100 ==============================\n"," Train Loss 0.25418 | Val Loss 0.90759 | SMAPE 1.80482\n","\n","[('포레스트릿_복숭아 아이스티',)] Epoch 150 ==============================\n"," Train Loss 0.24193 | Val Loss 0.92374 | SMAPE 1.82887\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  89%|████████▊ | 171/193 [59:20<07:32, 20.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_복숭아 아이스티',)] Epoch 200 ==============================\n"," Train Loss 0.19985 | Val Loss 0.91981 | SMAPE 1.81925\n","\n","[('포레스트릿_생수',)] Epoch 50 ==============================\n"," Train Loss 0.33227 | Val Loss 0.48437 | SMAPE 0.94401\n","\n","[('포레스트릿_생수',)] Epoch 100 ==============================\n"," Train Loss 0.26775 | Val Loss 0.42952 | SMAPE 0.85578\n","\n","[('포레스트릿_생수',)] Epoch 150 ==============================\n"," Train Loss 0.24656 | Val Loss 0.43834 | SMAPE 0.88276\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  89%|████████▉ | 172/193 [59:41<07:15, 20.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_생수',)] Epoch 200 ==============================\n"," Train Loss 0.21466 | Val Loss 0.42270 | SMAPE 0.86316\n","\n","[('포레스트릿_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.34688 | Val Loss 0.41178 | SMAPE 0.94672\n","\n","[('포레스트릿_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.24607 | Val Loss 0.36373 | SMAPE 0.70845\n","\n","[('포레스트릿_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.20421 | Val Loss 0.37643 | SMAPE 0.77453\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  90%|████████▉ | 173/193 [1:00:02<06:54, 20.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.18915 | Val Loss 0.36183 | SMAPE 0.70749\n","\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.24801 | Val Loss 0.37537 | SMAPE 0.73995\n","\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.20421 | Val Loss 0.37698 | SMAPE 0.75674\n","\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.16494 | Val Loss 0.42167 | SMAPE 0.81782\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  90%|█████████ | 174/193 [1:00:23<06:33, 20.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.13870 | Val Loss 0.39139 | SMAPE 0.76546\n","\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.23886 | Val Loss 0.35688 | SMAPE 0.70583\n","\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.19472 | Val Loss 0.39658 | SMAPE 0.77175\n","\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.15929 | Val Loss 0.39682 | SMAPE 0.77726\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  91%|█████████ | 175/193 [1:00:44<06:15, 20.87s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.13317 | Val Loss 0.41501 | SMAPE 0.82929\n","\n","[('포레스트릿_치즈 핫도그',)] Epoch 50 ==============================\n"," Train Loss 0.29621 | Val Loss 0.31794 | SMAPE 0.63330\n","\n","[('포레스트릿_치즈 핫도그',)] Epoch 100 ==============================\n"," Train Loss 0.23088 | Val Loss 0.36281 | SMAPE 0.74033\n","\n","[('포레스트릿_치즈 핫도그',)] Epoch 150 ==============================\n"," Train Loss 0.19178 | Val Loss 0.38555 | SMAPE 0.77334\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  91%|█████████ | 176/193 [1:01:04<05:52, 20.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_치즈 핫도그',)] Epoch 200 ==============================\n"," Train Loss 0.18330 | Val Loss 0.38441 | SMAPE 0.76320\n","\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.17023 | Val Loss 0.35098 | SMAPE 0.70505\n","\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.13352 | Val Loss 0.33786 | SMAPE 0.68171\n","\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.11718 | Val Loss 0.33193 | SMAPE 0.66785\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  92%|█████████▏| 177/193 [1:01:25<05:30, 20.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.09373 | Val Loss 0.35025 | SMAPE 0.69880\n","\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.17618 | Val Loss 0.34304 | SMAPE 0.67210\n","\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.13991 | Val Loss 0.37102 | SMAPE 0.75991\n","\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.11212 | Val Loss 0.35124 | SMAPE 0.70510\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  92%|█████████▏| 178/193 [1:01:45<05:07, 20.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.09024 | Val Loss 0.32616 | SMAPE 0.64775\n","\n","[('포레스트릿_코카콜라',)] Epoch 50 ==============================\n"," Train Loss 0.33524 | Val Loss 0.42707 | SMAPE 0.82433\n","\n","[('포레스트릿_코카콜라',)] Epoch 100 ==============================\n"," Train Loss 0.27113 | Val Loss 0.38069 | SMAPE 0.75323\n","\n","[('포레스트릿_코카콜라',)] Epoch 150 ==============================\n"," Train Loss 0.22521 | Val Loss 0.35166 | SMAPE 0.71952\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  93%|█████████▎| 179/193 [1:02:06<04:50, 20.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_코카콜라',)] Epoch 200 ==============================\n"," Train Loss 0.19523 | Val Loss 0.35441 | SMAPE 0.73115\n","\n","[('포레스트릿_페스츄리 소시지',)] Epoch 50 ==============================\n"," Train Loss 0.27109 | Val Loss 0.28842 | SMAPE 0.59012\n","\n","[('포레스트릿_페스츄리 소시지',)] Epoch 100 ==============================\n"," Train Loss 0.22836 | Val Loss 0.30405 | SMAPE 0.61842\n","\n","[('포레스트릿_페스츄리 소시지',)] Epoch 150 ==============================\n"," Train Loss 0.20794 | Val Loss 0.32433 | SMAPE 0.65505\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  93%|█████████▎| 180/193 [1:02:27<04:28, 20.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_페스츄리 소시지',)] Epoch 200 ==============================\n"," Train Loss 0.17487 | Val Loss 0.32411 | SMAPE 0.62672\n","\n","[('화담숲주막_느린마을 막걸리',)] Epoch 50 ==============================\n"," Train Loss 0.15574 | Val Loss 0.20680 | SMAPE 0.38059\n","\n","[('화담숲주막_느린마을 막걸리',)] Epoch 100 ==============================\n"," Train Loss 0.13125 | Val Loss 0.23383 | SMAPE 0.44965\n","\n","[('화담숲주막_느린마을 막걸리',)] Epoch 150 ==============================\n"," Train Loss 0.10743 | Val Loss 0.22092 | SMAPE 0.42779\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  94%|█████████▍| 181/193 [1:02:48<04:09, 20.79s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_느린마을 막걸리',)] Epoch 200 ==============================\n"," Train Loss 0.08718 | Val Loss 0.25088 | SMAPE 0.46913\n","\n","[('화담숲주막_단호박 식혜 ',)] Epoch 50 ==============================\n"," Train Loss 0.18091 | Val Loss 0.22710 | SMAPE 0.43113\n","\n","[('화담숲주막_단호박 식혜 ',)] Epoch 100 ==============================\n"," Train Loss 0.16057 | Val Loss 0.22374 | SMAPE 0.43321\n","\n","[('화담숲주막_단호박 식혜 ',)] Epoch 150 ==============================\n"," Train Loss 0.12600 | Val Loss 0.25995 | SMAPE 0.48207\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  94%|█████████▍| 182/193 [1:03:09<03:49, 20.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_단호박 식혜 ',)] Epoch 200 ==============================\n"," Train Loss 0.10941 | Val Loss 0.25774 | SMAPE 0.49488\n","\n","[('화담숲주막_병천순대',)] Epoch 50 ==============================\n"," Train Loss 0.13910 | Val Loss 0.18426 | SMAPE 0.34365\n","\n","[('화담숲주막_병천순대',)] Epoch 100 ==============================\n"," Train Loss 0.10903 | Val Loss 0.19558 | SMAPE 0.37593\n","\n","[('화담숲주막_병천순대',)] Epoch 150 ==============================\n"," Train Loss 0.08805 | Val Loss 0.20652 | SMAPE 0.39685\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  95%|█████████▍| 183/193 [1:03:29<03:27, 20.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_병천순대',)] Epoch 200 ==============================\n"," Train Loss 0.07159 | Val Loss 0.19713 | SMAPE 0.37423\n","\n","[('화담숲주막_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.20803 | Val Loss 0.28733 | SMAPE 0.57560\n","\n","[('화담숲주막_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.17636 | Val Loss 0.30058 | SMAPE 0.58442\n","\n","[('화담숲주막_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.13580 | Val Loss 0.31438 | SMAPE 0.61254\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  95%|█████████▌| 184/193 [1:03:50<03:07, 20.81s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.12521 | Val Loss 0.31018 | SMAPE 0.61421\n","\n","[('화담숲주막_참살이 막걸리',)] Epoch 50 ==============================\n"," Train Loss 0.17112 | Val Loss 0.23830 | SMAPE 0.45235\n","\n","[('화담숲주막_참살이 막걸리',)] Epoch 100 ==============================\n"," Train Loss 0.14153 | Val Loss 0.29997 | SMAPE 0.58887\n","\n","[('화담숲주막_참살이 막걸리',)] Epoch 150 ==============================\n"," Train Loss 0.11406 | Val Loss 0.29388 | SMAPE 0.55596\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  96%|█████████▌| 185/193 [1:04:10<02:43, 20.48s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_참살이 막걸리',)] Epoch 200 ==============================\n"," Train Loss 0.08621 | Val Loss 0.28723 | SMAPE 0.54383\n","\n","[('화담숲주막_찹쌀식혜',)] Epoch 50 ==============================\n"," Train Loss 0.18114 | Val Loss 0.31435 | SMAPE 0.60353\n","\n","[('화담숲주막_찹쌀식혜',)] Epoch 100 ==============================\n"," Train Loss 0.15151 | Val Loss 0.25250 | SMAPE 0.48829\n","\n","[('화담숲주막_찹쌀식혜',)] Epoch 150 ==============================\n"," Train Loss 0.13684 | Val Loss 0.27627 | SMAPE 0.54432\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  96%|█████████▋| 186/193 [1:04:31<02:25, 20.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_찹쌀식혜',)] Epoch 200 ==============================\n"," Train Loss 0.10627 | Val Loss 0.28600 | SMAPE 0.56634\n","\n","[('화담숲주막_콜라',)] Epoch 50 ==============================\n"," Train Loss 0.21013 | Val Loss 0.27917 | SMAPE 0.54684\n","\n","[('화담숲주막_콜라',)] Epoch 100 ==============================\n"," Train Loss 0.17452 | Val Loss 0.31917 | SMAPE 0.62486\n","\n","[('화담숲주막_콜라',)] Epoch 150 ==============================\n"," Train Loss 0.15926 | Val Loss 0.30472 | SMAPE 0.59282\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  97%|█████████▋| 187/193 [1:04:52<02:03, 20.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_콜라',)] Epoch 200 ==============================\n"," Train Loss 0.13270 | Val Loss 0.31329 | SMAPE 0.61466\n","\n","[('화담숲주막_해물파전',)] Epoch 50 ==============================\n"," Train Loss 0.13229 | Val Loss 0.18075 | SMAPE 0.34111\n","\n","[('화담숲주막_해물파전',)] Epoch 100 ==============================\n"," Train Loss 0.09181 | Val Loss 0.20100 | SMAPE 0.38489\n","\n","[('화담숲주막_해물파전',)] Epoch 150 ==============================\n"," Train Loss 0.06915 | Val Loss 0.20246 | SMAPE 0.38667\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  97%|█████████▋| 188/193 [1:05:13<01:43, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_해물파전',)] Epoch 200 ==============================\n"," Train Loss 0.06176 | Val Loss 0.20853 | SMAPE 0.39813\n","\n","[('화담숲카페_메밀미숫가루',)] Epoch 50 ==============================\n"," Train Loss 0.19880 | Val Loss 0.29360 | SMAPE 0.56383\n","\n","[('화담숲카페_메밀미숫가루',)] Epoch 100 ==============================\n"," Train Loss 0.16908 | Val Loss 0.31885 | SMAPE 0.62010\n","\n","[('화담숲카페_메밀미숫가루',)] Epoch 150 ==============================\n"," Train Loss 0.15023 | Val Loss 0.34583 | SMAPE 0.64031\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  98%|█████████▊| 189/193 [1:05:33<01:22, 20.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_메밀미숫가루',)] Epoch 200 ==============================\n"," Train Loss 0.12013 | Val Loss 0.32753 | SMAPE 0.62780\n","\n","[('화담숲카페_아메리카노 HOT',)] Epoch 50 ==============================\n"," Train Loss 0.19564 | Val Loss 0.29083 | SMAPE 0.54601\n","\n","[('화담숲카페_아메리카노 HOT',)] Epoch 100 ==============================\n"," Train Loss 0.15143 | Val Loss 0.27744 | SMAPE 0.53378\n","\n","[('화담숲카페_아메리카노 HOT',)] Epoch 150 ==============================\n"," Train Loss 0.12735 | Val Loss 0.26871 | SMAPE 0.51934\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  98%|█████████▊| 190/193 [1:05:54<01:02, 20.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_아메리카노 HOT',)] Epoch 200 ==============================\n"," Train Loss 0.09822 | Val Loss 0.27457 | SMAPE 0.53401\n","\n","[('화담숲카페_아메리카노 ICE',)] Epoch 50 ==============================\n"," Train Loss 0.23365 | Val Loss 0.31647 | SMAPE 0.60407\n","\n","[('화담숲카페_아메리카노 ICE',)] Epoch 100 ==============================\n"," Train Loss 0.18411 | Val Loss 0.35760 | SMAPE 0.68568\n","\n","[('화담숲카페_아메리카노 ICE',)] Epoch 150 ==============================\n"," Train Loss 0.16080 | Val Loss 0.34766 | SMAPE 0.69218\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  99%|█████████▉| 191/193 [1:06:15<00:41, 20.82s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_아메리카노 ICE',)] Epoch 200 ==============================\n"," Train Loss 0.16175 | Val Loss 0.36602 | SMAPE 0.71656\n","\n","[('화담숲카페_카페라떼 ICE',)] Epoch 50 ==============================\n"," Train Loss 0.21754 | Val Loss 0.30307 | SMAPE 0.57300\n","\n","[('화담숲카페_카페라떼 ICE',)] Epoch 100 ==============================\n"," Train Loss 0.16350 | Val Loss 0.33444 | SMAPE 0.61312\n","\n","[('화담숲카페_카페라떼 ICE',)] Epoch 150 ==============================\n"," Train Loss 0.12993 | Val Loss 0.33526 | SMAPE 0.63653\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  99%|█████████▉| 192/193 [1:06:36<00:20, 20.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_카페라떼 ICE',)] Epoch 200 ==============================\n"," Train Loss 0.10311 | Val Loss 0.32563 | SMAPE 0.61329\n","\n","[('화담숲카페_현미뻥스크림',)] Epoch 50 ==============================\n"," Train Loss 0.22601 | Val Loss 0.39204 | SMAPE 0.75036\n","\n","[('화담숲카페_현미뻥스크림',)] Epoch 100 ==============================\n"," Train Loss 0.17498 | Val Loss 0.39714 | SMAPE 0.77516\n","\n","[('화담숲카페_현미뻥스크림',)] Epoch 150 ==============================\n"," Train Loss 0.15189 | Val Loss 0.42273 | SMAPE 0.81154\n"]},{"output_type":"stream","name":"stderr","text":["Training LSTM: 100%|██████████| 193/193 [1:06:56<00:00, 20.81s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_현미뻥스크림',)] Epoch 200 ==============================\n"," Train Loss 0.11965 | Val Loss 0.40433 | SMAPE 0.77351\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# 데이터 준비\n","data[\"is_sandwich_norm\"] = data[\"is_sandwich\"].fillna(0) / 5.0\n","\n","features = cols + [\"매출수량\", \"영업일자\", \"영업장명_메뉴명\", \"is_sandwich_norm\"]\n","dataset_lstm = data[features]\n","\n","losses = [WeightedSMAPELoss(eps = 1e-8), WeightedHuberLoss(delta = 1.0, zeros = False, eps = 1e-8)]\n","loss_weights = [0.5, 0.5]\n","lstm = LSTMModel(lookback = 28, hidden_dim = 128, num_layers = 3, predict = 7, dropout = 0.3)\n","\n","lookback, predict, batch_size, epochs = 28, 7, 16, 200\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","trained_lstm = lstm.train_lstm(train_df = dataset_lstm, cols = cols, enc_cols = None, num_cols = num_cols,\n","                               device = device, epochs = epochs, batch_size = batch_size, lr = 1e-3, dropout = 0.4,\n","                               losses = losses, loss_weights = loss_weights, n_splits = 3, print_every = 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUZFsOC5p1sp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755282893459,"user_tz":-540,"elapsed":2233,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"a378fd9b-3a77-4111-d832-23bd3e8fb264"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU 버전 모델 저장 완료!\n"]}],"source":["hidden_dim = 128\n","num_layers = 3\n","model_path = f'/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 8/lstm_models_{hidden_dim}_{num_layers}.pkl'\n","lstm.save_lstm_model_cpu(trained_lstm, model_path)"]},{"cell_type":"markdown","metadata":{"id":"Qqtu8A59P6Kg"},"source":["#### 예측하기"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"BJpzrc5WYXsZ","executionInfo":{"status":"ok","timestamp":1755340546748,"user_tz":-540,"elapsed":12906,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["# 저장된 모델 로드 - CPU\n","lookback, predict, batch_size, epochs = 28, 7, 16, 200\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 8/lstm_models_128_3.pkl'\n","lstm = LSTMModel(lookback = 28, predict = 7)\n","trained_lstm = lstm.load_saved_model(model_path)"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"zzm7n6SEP7lB","executionInfo":{"status":"ok","timestamp":1755340568571,"user_tz":-540,"elapsed":39,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["class PredictionFunctions():\n","    def __init__(self, test_df = None, trained_models = None, test_prefix = None, cols = None, enc_cols = None, lookback = 28, predict = 7):\n","        self.test_df = test_df\n","        self.trained_models = trained_models\n","        self.test_prefix = test_prefix\n","        self.cols = cols\n","        self.enc_cols = enc_cols or []\n","        self.lookback = lookback\n","        self.predict = predict\n","\n","    def predict_class(self, test_df, trained_models, test_prefix : str, cols : list, enc_cols : list, lookback = 28, predict = 7):\n","        \"\"\"\n","        Input : test_df - test data, trained_models - list(menu : {model, encoder}), cols - x 변수들\n","        Output : [영업일자, 영업장명_메뉴명, 매출여부] DataFrame\n","        \"\"\"\n","        results = []\n","\n","        for store_menu_tup, store_test in test_df.groupby(['영업장명_메뉴명']):\n","            store_menu = store_menu_tup[0]\n","            # 훈련된 모델에 메뉴가 있는 경우만 진행\n","            if store_menu not in trained_models:\n","                continue\n","\n","            # 모델 불러오기\n","            model = trained_models[store_menu][\"model\"]\n","            encoder = trained_models[store_menu].get('encoder', None)\n","            threshold = trained_models[store_menu].get(\"threshold\", 0.5)\n","\n","            # 변수 추가하기\n","            mv = Make_Variables()\n","            store_test['영업일자'] = pd.to_datetime(store_test['영업일자'])\n","            store_test_sorted = store_test.sort_values('영업일자')\n","            last_date = store_test_sorted['영업일자'].iloc[-1]\n","\n","            future_df = mv.make_variables_test(date = last_date, test_df = store_test, predict = 7)\n","            if enc_cols:\n","                encoded = encoder.transform(future_df[enc_cols])\n","                encoded_df = pd.DataFrame(encoded, columns = enc_cols, index = future_df.index)\n","                future_df[enc_cols] = encoded_df\n","            x = future_df[cols]\n","\n","            if hasattr(model, \"classes_\"):\n","                pos_idx = int(np.where(model.classes_ == 1)[0][0])\n","            else:\n","                pos_idx = 1\n","\n","            proba = model.predict_proba(x)[:, pos_idx]\n","            y_hat = (proba >= threshold).astype(int)\n","\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, y_hat):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출여부': val\n","                })\n","\n","        return pd.DataFrame(results)\n","\n","    def predict_reg(self, test_df, trained_models, test_prefix : str, cols : list, enc_cols : list, lookback = 28, predict = 7):\n","        \"\"\"\n","        Input : test_df - test data, trained_models - list(menu : {model, encoder}), cols - x 변수들\n","        Output : [영업일자, 영업장명_메뉴명, 매출수량] DataFrame\n","        \"\"\"\n","        results = []\n","\n","        for store_menu_tup, store_test in test_df.groupby(['영업장명_메뉴명']):\n","            store_menu = store_menu_tup[0]\n","            # 훈련된 모델에 메뉴가 있는 경우만 진행\n","            if store_menu not in trained_models:\n","                continue\n","\n","            # 모델 불러오기\n","            model = trained_models[store_menu][\"model\"]\n","            encoder = trained_models[store_menu].get('encoder', None)\n","\n","            # 변수 추가하기\n","            mv = Make_Variables()\n","            store_test['영업일자'] = pd.to_datetime(store_test['영업일자'])\n","            store_test_sorted = store_test.sort_values('영업일자')\n","            last_date = store_test_sorted['영업일자'].iloc[-1]\n","\n","            future_df = mv.make_variables_test(date = last_date, test_df = store_test, predict = 7)\n","            if enc_cols:\n","                encoded = encoder.transform(future_df[enc_cols])\n","                encoded_df = pd.DataFrame(encoded, columns = enc_cols, index = future_df.index)\n","                future_df[enc_cols] = encoded_df\n","            future_df = future_df[cols]\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, model.predict(future_df)):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출수량': val\n","                })\n","\n","        return pd.DataFrame(results)\n","\n","    def predict_lstm(self, test_df, trained_models, test_prefix : str, cols : list, enc_cols : list, num_cols : list, lookback = 28, predict = 7, device = None):\n","        \"\"\"\n","        Input : test_df - test data, trained_models - list(menu : { model}), cols - x 변수들\n","        Output : [영업일자, 영업장명_메뉴명, 매출수량] DataFrame\n","        \"\"\"\n","\n","        if device is None:\n","            device = getattr(self, \"device\", \"cpu\")\n","        device = torch.device(device)\n","\n","        results = []\n","\n","        # 매장, 메뉴별로 그룹화해서 예측\n","        for store_menu, store_test in test_df.groupby(['영업장명_메뉴명']):\n","            # 훈련된 모델에 메뉴가 있는 경우만 진행\n","            if store_menu not in trained_models:\n","                continue\n","\n","            # 모델, scaler 불러오기\n","            state = trained_models[store_menu]['model']\n","            meta = trained_models[store_menu]['meta']\n","            encoders = trained_models[store_menu].get('encoders', None)\n","            features_scaler = trained_models[store_menu]['features_scaler']\n","            target_scaler = trained_models[store_menu]['target_scaler']\n","\n","            # LSTM 모델 생성\n","            model = MultiOutputLSTM(\n","                input_dim=meta['input_dim'],\n","                hidden_dim=meta['hidden_dim'],\n","                num_layers=meta['num_layers'],\n","                output_dim=meta['output_dim']\n","            )\n","\n","            model.load_state_dict(state)\n","            model = model.to(device).eval()\n","\n","            # LSTM 입력으로 활용할 최근 lookback 만큼의 데이터 가져오기\n","            mv = Make_Variables()\n","            store_test = store_test.sort_values('영업일자')\n","            store_test = mv.make_variables_train(data = store_test)\n","            store_test_sorted = store_test.sort_values('영업일자')\n","\n","            features = cols + [\"매출수량\"]\n","            if len(store_test_sorted) < lookback:\n","                continue\n","\n","            recent_df = store_test_sorted[features].iloc[-lookback:].copy()\n","            if len(recent_df) < lookback:\n","                continue # lookback 만큼의 데이터가 없으면 예측 안 하고 넘어가기\n","\n","            ##### 요기서 변수 추가\n","            last_date = store_test_sorted['영업일자'].iloc[-1]\n","            recent_df_for_mv = store_test_sorted[features + ['영업장명_메뉴명', '영업일자']].iloc[-lookback:].copy()\n","            future_df = mv.make_variables_test(date = last_date, test_df = recent_df_for_mv, predict = 7)\n","            future_df['매출수량'] = 0.0\n","            full_df = pd.concat([recent_df, future_df[features]], axis = 0)\n","\n","            # enc_cols 정규화\n","            if enc_cols:\n","                for col in enc_cols:\n","                    if col not in full_df.columns:\n","                        continue\n","                    if col in encoders:\n","                        le = encoders[col]\n","                        full_df[col] = le.transform(full_df[col].astype(str)) ##### str로 바꿔봄...\n","                    else:\n","                        full_df[col] = full_df[col].astype(int)\n","\n","            # num_cols 스케일링\n","            full_df[num_cols] = features_scaler.transform(full_df[num_cols])\n","\n","            x_input_vals = full_df[cols].values\n","            x_input = x_input_vals[:lookback]\n","            x_input = torch.tensor([x_input]).float().to(device)\n","\n","            # 예측 수행\n","            with torch.no_grad():\n","                pred_scaled = model(x_input).squeeze().cpu().numpy()\n","\n","            # 역정규화\n","            restored = []\n","            for i in range(predict):\n","                dummy = np.zeros((1, len(features)))\n","                dummy[0, features.index(\"매출수량\")] = pred_scaled[i]\n","                restored_val = target_scaler.inverse_transform(dummy)[0, features.index(\"매출수량\")]\n","                restored.append(max(restored_val, 0)) # 음수 나오면 0으로 처리\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, restored):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출수량(lstm)': val\n","                })\n","\n","        return pd.DataFrame(results)"]},{"cell_type":"markdown","metadata":{"id":"PnTZIj8uXAdw"},"source":["#### 예측값 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"eP7il3f1stSF"},"outputs":[],"source":["import re\n","all_preds_class = []\n","all_preds_reg = []\n","all_preds_lstm = []\n","\n","# 모든 test_*.csv 순회\n","test_files = sorted(glob.glob('DATA/test/TEST_*.csv'))\n","predictions = PredictionFunctions()\n","\n","for path in test_files:\n","    test_df = pd.read_csv(path)\n","\n","    # 파일명에서 접두어 추출 (예: TEST_00)\n","    filename = os.path.basename(path)\n","    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n","\n","    # lstm 넣고\n","    pred_lstm = predictions.predict_lstm(test_df, trained_lstm, test_prefix, cols, enc_cols = None, num_cols, device = 'cpu')\n","    all_preds_lstm.append(pred_lstm)\n","\n","df_lstm  = pd.concat(all_preds_lstm, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1755177209162,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"VxHGu172_DMW","outputId":"7163ceb2-cb1f-4721-9df9-e60affd02abc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["13510"]},"metadata":{},"execution_count":22}],"source":["len(df_lstm)"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"Au8Nlw1HXCVN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755341064085,"user_tz":-540,"elapsed":490460,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"fdca3f10-8947-44c5-f405-45ae007a466e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4146410540.py:178: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n","  x_input = torch.tensor([x_input]).float().to(device)\n"]},{"output_type":"stream","name":"stdout","text":["예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n"]}],"source":["import re\n","all_preds_class = []\n","all_preds_reg = []\n","all_preds_lstm = []\n","\n","\n","# 모든 test_*.csv 순회\n","test_files = sorted(glob.glob('DATA/test/TEST_*.csv'))\n","predictions = PredictionFunctions()\n","\n","for path in test_files:\n","    test_df = pd.read_csv(path)\n","\n","    # 파일명에서 접두어 추출 (예: TEST_00)\n","    filename = os.path.basename(path)\n","    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n","\n","    # 일단 분류 모델 넣고\n","    pred_class = predictions.predict_class(test_df, models_class, test_prefix, cols, enc_cols = None)\n","    all_preds_class.append(pred_class)\n","\n","    # 1 나오면 회귀 모델 넣고\n","    pred_reg = predictions.predict_reg(test_df, models_reg, test_prefix, cols, enc_cols = None)\n","    all_preds_reg.append(pred_reg)\n","\n","    # lstm 넣고\n","    pred_lstm = predictions.predict_lstm(test_df, trained_lstm, test_prefix, cols, enc_cols = None, num_cols = num_cols)\n","    all_preds_lstm.append(pred_lstm)\n","\n","    print(\"예측 완료 !\")\n","\n","df_class = pd.concat(all_preds_class, ignore_index = True)\n","df_reg   = pd.concat(all_preds_reg, ignore_index = True)\n","df_lstm  = pd.concat(all_preds_lstm, ignore_index = True)"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":123,"status":"ok","timestamp":1755341672491,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"Qz2PdvvhDu3J","outputId":"1dfea15b-dcb1-4a00-a9bd-016075b9ecaf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         영업일자                영업장명_메뉴명  매출수량(lstm)  매출여부  매출수량(reg)\n","0  TEST_00+1일      느티나무 셀프BBQ_1인 수저세트   10.007466     1  12.256191\n","1  TEST_00+1일    느티나무 셀프BBQ_BBQ55(단체)   32.985085     0  78.131004\n","2  TEST_00+1일  느티나무 셀프BBQ_대여료 30,000원    7.921399     1   9.553818\n","3  TEST_00+1일  느티나무 셀프BBQ_대여료 60,000원    4.646937     1   1.381822\n","4  TEST_00+1일  느티나무 셀프BBQ_대여료 90,000원    1.028644     1   1.663972"],"text/html":["\n","  <div id=\"df-82585b2c-9263-48be-8fd6-60cdff517d8a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>영업일자</th>\n","      <th>영업장명_메뉴명</th>\n","      <th>매출수량(lstm)</th>\n","      <th>매출여부</th>\n","      <th>매출수량(reg)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_1인 수저세트</td>\n","      <td>10.007466</td>\n","      <td>1</td>\n","      <td>12.256191</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_BBQ55(단체)</td>\n","      <td>32.985085</td>\n","      <td>0</td>\n","      <td>78.131004</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 30,000원</td>\n","      <td>7.921399</td>\n","      <td>1</td>\n","      <td>9.553818</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 60,000원</td>\n","      <td>4.646937</td>\n","      <td>1</td>\n","      <td>1.381822</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 90,000원</td>\n","      <td>1.028644</td>\n","      <td>1</td>\n","      <td>1.663972</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82585b2c-9263-48be-8fd6-60cdff517d8a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-82585b2c-9263-48be-8fd6-60cdff517d8a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-82585b2c-9263-48be-8fd6-60cdff517d8a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-d96a2d64-d8b2-4293-92e0-a545b817de06\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d96a2d64-d8b2-4293-92e0-a545b817de06')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-d96a2d64-d8b2-4293-92e0-a545b817de06 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"full_pred_df","summary":"{\n  \"name\": \"full_pred_df\",\n  \"rows\": 13510,\n  \"fields\": [\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc77c\\uc790\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"TEST_03+2\\uc77c\",\n          \"TEST_00+1\\uc77c\",\n          \"TEST_07+1\\uc77c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc7a5\\uba85_\\uba54\\ub274\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"\\ub2f4\\ud558_\\uba54\\ubc00\\uba74 \\uc0ac\\ub9ac\",\n          \"\\uc5f0\\ud68c\\uc7a5_\\ub9c8\\ub77c\\uc0f9\\uad88\",\n          \"\\ub77c\\uadf8\\ub85c\\ud0c0_\\uc2a4\\ud504\\ub77c\\uc774\\ud2b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9(lstm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.1681221435764,\n        \"min\": 0.0,\n        \"max\": 794.5006749033928,\n        \"num_unique_values\": 13324,\n        \"samples\": [\n          3.37537869811058,\n          1.243477463722229,\n          1.9652827978134155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9(reg)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 13388,\n        \"samples\": [\n          2.6444215774536133,\n          11.623211860656738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":66}],"source":["full_pred_df = pd.merge(df_class, df_reg, on=['영업일자', '영업장명_메뉴명'], how='outer')\n","full_pred_df.rename(columns={'매출수량': '매출수량(reg)'}, inplace=True)\n","\n","df_lstm_plz = df_lstm.copy()\n","df_lstm_plz['영업장명_메뉴명'] = df_lstm['영업장명_메뉴명'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n","\n","full_pred_df = pd.merge(df_lstm_plz, full_pred_df, on=['영업일자', '영업장명_메뉴명'], how='outer')\n","full_pred_df.head()"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":91,"status":"ok","timestamp":1755341673445,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"IZ5UFb0GD6B3","outputId":"0b595bb7-d972-4651-9fe3-f1d1ccd5b429"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             영업일자                영업장명_메뉴명       매출수량\n","0      TEST_00+1일      느티나무 셀프BBQ_1인 수저세트  10.794520\n","1      TEST_00+1일    느티나무 셀프BBQ_BBQ55(단체)  32.985085\n","2      TEST_00+1일  느티나무 셀프BBQ_대여료 30,000원   8.492745\n","3      TEST_00+1일  느티나무 셀프BBQ_대여료 60,000원   3.504147\n","4      TEST_00+1일  느티나무 셀프BBQ_대여료 90,000원   1.251009\n","...           ...                     ...        ...\n","13505  TEST_09+7일            화담숲카페_메밀미숫가루  40.375656\n","13506  TEST_09+7일         화담숲카페_아메리카노 HOT  29.454053\n","13507  TEST_09+7일         화담숲카페_아메리카노 ICE  99.645001\n","13508  TEST_09+7일          화담숲카페_카페라떼 ICE  23.086480\n","13509  TEST_09+7일            화담숲카페_현미뻥스크림  45.046979\n","\n","[13510 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-3f4bbb4e-4b3a-4835-bbf2-5ab123471280\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>영업일자</th>\n","      <th>영업장명_메뉴명</th>\n","      <th>매출수량</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_1인 수저세트</td>\n","      <td>10.794520</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_BBQ55(단체)</td>\n","      <td>32.985085</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 30,000원</td>\n","      <td>8.492745</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 60,000원</td>\n","      <td>3.504147</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 90,000원</td>\n","      <td>1.251009</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13505</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_메밀미숫가루</td>\n","      <td>40.375656</td>\n","    </tr>\n","    <tr>\n","      <th>13506</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_아메리카노 HOT</td>\n","      <td>29.454053</td>\n","    </tr>\n","    <tr>\n","      <th>13507</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_아메리카노 ICE</td>\n","      <td>99.645001</td>\n","    </tr>\n","    <tr>\n","      <th>13508</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_카페라떼 ICE</td>\n","      <td>23.086480</td>\n","    </tr>\n","    <tr>\n","      <th>13509</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_현미뻥스크림</td>\n","      <td>45.046979</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13510 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f4bbb4e-4b3a-4835-bbf2-5ab123471280')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3f4bbb4e-4b3a-4835-bbf2-5ab123471280 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3f4bbb4e-4b3a-4835-bbf2-5ab123471280');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-bd9c6bcb-609e-41fe-840d-8d5eb562fcf5\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd9c6bcb-609e-41fe-840d-8d5eb562fcf5')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-bd9c6bcb-609e-41fe-840d-8d5eb562fcf5 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_90258d8b-b29c-415f-86bf-aa5d3ba12b20\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('full_pred_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_90258d8b-b29c-415f-86bf-aa5d3ba12b20 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('full_pred_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"full_pred_df","summary":"{\n  \"name\": \"full_pred_df\",\n  \"rows\": 13510,\n  \"fields\": [\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc77c\\uc790\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"TEST_03+2\\uc77c\",\n          \"TEST_00+1\\uc77c\",\n          \"TEST_07+1\\uc77c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc7a5\\uba85_\\uba54\\ub274\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"\\ub2f4\\ud558_\\uba54\\ubc00\\uba74 \\uc0ac\\ub9ac\",\n          \"\\uc5f0\\ud68c\\uc7a5_\\ub9c8\\ub77c\\uc0f9\\uad88\",\n          \"\\ub77c\\uadf8\\ub85c\\ud0c0_\\uc2a4\\ud504\\ub77c\\uc774\\ud2b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.03602221633604,\n        \"min\": 0.0,\n        \"max\": 790.4160697907209,\n        \"num_unique_values\": 13338,\n        \"samples\": [\n          0.9962377101182938,\n          24.51079372689128,\n          6.108338069915772\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":67}],"source":["full_pred_df['매출수량'] = np.where(\n","    full_pred_df['매출여부'] == 1,\n","    full_pred_df['매출수량(reg)'] * 0.35 + full_pred_df['매출수량(lstm)'] * 0.65,\n","    full_pred_df['매출수량(lstm)']\n",")\n","\n","full_pred_df.drop(columns=['매출여부', '매출수량(reg)', '매출수량(lstm)'], inplace=True)\n","full_pred_df"]},{"cell_type":"code","source":["def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n","    # (영업일자, 메뉴) → 매출수량 딕셔너리로 변환\n","    pred_dict = dict(zip(\n","        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n","        pred_df['매출수량'].astype(float)\n","    ))\n","\n","    final_df = sample_submission.copy()\n","\n","    menu_cols = final_df.columns[1:]\n","    final_df[menu_cols] = final_df[menu_cols].astype(float)\n","\n","    for row_idx in final_df.index:\n","        date = final_df.loc[row_idx, '영업일자']\n","        for col in final_df.columns[1:]:  # 메뉴명들\n","            final_df.loc[row_idx, col] = pred_dict.get((date, col), 0)\n","\n","    return final_df"],"metadata":{"id":"CX6vl--KGkiO","executionInfo":{"status":"ok","timestamp":1755341675194,"user_tz":-540,"elapsed":10,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","execution_count":77,"metadata":{"id":"5_Hoods1EDeM","executionInfo":{"status":"ok","timestamp":1755342102817,"user_tz":-540,"elapsed":9137,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[],"source":["full_pred_df_notzero = full_pred_df.copy()\n","full_pred_df_notzero.loc[full_pred_df_notzero['매출수량'].abs() < 1e-5, '매출수량'] = 1\n","\n","sample_submission = pd.read_csv('DATA/sample_submission.csv')\n","final_hybrid = convert_to_submission_format(full_pred_df_notzero, sample_submission)\n","final_hybrid.to_csv('baseline_submission_hybrid.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"markdown","source":["##### 다른 제출 시도들"],"metadata":{"id":"_AOW_k2VNy9u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zlrRIwTEFJe"},"outputs":[],"source":["df_lstm_plz = df_lstm.copy()\n","df_lstm_plz['영업장명_메뉴명'] = df_lstm['영업장명_메뉴명'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n","df_lstm_end = df_lstm_plz.rename(columns = {'매출수량(lstm)' : '매출수량'})\n","\n","# 1 변환\n","df_lstm_end.loc[df_lstm_end['매출수량'].abs() < 1e-9, '매출수량'] = 1\n","\n","sample_submission = pd.read_csv('DATA/sample_submission.csv')\n","final_lstm = convert_to_submission_format(df_lstm_end, sample_submission)\n","final_lstm.to_csv('baseline_submission_lstm.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRvPfGjjPtz0"},"outputs":[],"source":["full_pred_df_notzero = full_pred_df.copy()\n","full_pred_df_notzero.loc[full_pred_df_notzero['매출수량'].abs() < 1e-9, '매출수량'] = 1"]},{"cell_type":"code","source":["df_reg_notzero = df_reg.copy()\n","df_reg_notzero.loc[df_reg_notzero['매출수량'].abs() < 1e-9, '매출수량'] = 1\n","\n","sample_submission = pd.read_csv('DATA/sample_submission.csv')\n","final_hybrid = convert_to_submission_format(df_reg, sample_submission)\n","final_hybrid.to_csv('baseline_submission_reg.csv', index=False, encoding='utf-8-sig')"],"metadata":{"id":"vlQbxRFuFtUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ug9aRCJQXbk"},"outputs":[],"source":["sample_submission = pd.read_csv('DATA/sample_submission.csv')\n","final_hybrid = convert_to_submission_format(full_pred_df_notzero, sample_submission)\n","final_hybrid.to_csv('baseline_submission_hybrid_notzero.csv', index=False, encoding='utf-8-sig')"]}],"metadata":{"colab":{"collapsed_sections":["Qbp0yN6WBSq5","_AOW_k2VNy9u"],"provenance":[],"mount_file_id":"1ZwmKhvJmzmxSCJo8xfdzeNQCFMKtpTq0","authorship_tag":"ABX9TyO40a/mcvEf0hbY0YBUKI/k"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
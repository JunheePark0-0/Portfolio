{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"isT265wQhJU0"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from pathlib import Path\n","\n","import datetime\n","from datetime import timedelta\n","# !pip install holidays\n","import holidays\n","\n","os.chdir(\"/content/drive/MyDrive/3. Grad School/LG Aimers\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANnKbGzih5yO"},"outputs":[],"source":["# 데이터 불러오기\n","data = pd.read_csv(\"DATA/train/train.csv\")"]},{"cell_type":"markdown","metadata":{"id":"W3rcw_Bbh-nB"},"source":["#### 파생변수 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6NiJd97h_-N"},"outputs":[],"source":["# 월(month) -> 계절 매핑 딕셔너리\n","month_to_season = {\n","    1: \"Winter\", 2: \"Winter\", 12: \"Winter\",\n","    3: \"Spring\", 4: \"Spring\", 5: \"Spring\",\n","    6: \"Summer\", 7: \"Summer\", 8: \"Summer\",\n","    9: \"Autumn\", 10: \"Autumn\", 11: \"Autumn\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WusevNkYqMwZ"},"outputs":[],"source":["# 월별 가중치 매핑\n","# monthly_weights = {\n","#     1: 1.5, 2: 1.5, 3: 0.5,\n","#     4: 0.8, 5: 0.8, 6: 0.8,\n","#     7: 1.2, 8: 1.2, 9: 0.8,\n","#     10: 0.8, 11: 0.8, 12: 1.2}\n","\n","monthly_weights = {\n","    1: 2.2, 2: 1.8, 3: 0.3,\n","    4: 1.01, 5: 0.7, 6: 0.8,\n","    7: 0.5, 8: 0.5, 9: 0.8,\n","    10: 1.55, 11: 1.03, 12: 1.4}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39ITfoSm14y4"},"outputs":[],"source":["# 요일별 가중치 매핑\n","# weekly_weights = {\n","#     \"Monday\": 0.8, \"Tuesday\": 0.8, \"Wednesday\": 0.8,\n","#     \"Thursday\": 0.8, \"Friday\": 1.2, \"Saturday\": 1.7,\n","#     \"Sunday\": 1.5}\n","\n","weekly_weights = {\n","    \"Monday\": 0.78, \"Tuesday\": 0.85, \"Wednesday\": 0.81,\n","    \"Thursday\": 9.9, \"Friday\": 1.2, \"Saturday\": 1.53,\n","    \"Sunday\": 1.3}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n5Bo-6_MYg5Q"},"outputs":[],"source":["class Make_Variables():\n","        def __init__(self, data = None, date = None, predict = 7, month_to_season = None, monthly_weights = None, weekly_weights = None):\n","            self.data = data\n","            self.date = date\n","            self.predict = predict\n","            self.month_to_season = month_to_season\n","            self.monthly_weights = monthly_weights\n","            self.weekly_weights = weekly_weights\n","\n","        def update_kor_holidays(self):\n","            \"\"\"국경일 추가\"\"\"\n","            kor_holidays = holidays.KR(years = [2023, 2024, 2025])\n","            kor_holidays.update({\n","                # datetime.date(2023,2,14) : \"Valentine's Day\",\n","                # datetime.date(2023,3,14) : \"White Day\",\n","                # datetime.date(2023,11,11) : \"Pepero Day\",\n","                # datetime.date(2024,2,14) : \"Valentine's Day\",\n","                # datetime.date(2024,3,14) : \"White Day\",\n","                # datetime.date(2024,11,11) : \"Pepero Day\",\n","                # datetime.date(2025,2,14) : \"Valentine's Day\",\n","                # datetime.date(2025,3,14) : \"White Day\",\n","                # datetime.date(2025,11,11) : \"Pepero Day\",\n","\n","                datetime.date(2024,10,1) : \"Temporary Holiday\", # 국군의 날 임시공휴일\n","                datetime.date(2025,1,27) : \"Temporary Holiday\", # 설날 임시공휴일\n","                datetime.date(2025,3,3) : \"Temporary Holiday\", # 삼일절 대체공휴일\n","                datetime.date(2025, 5, 29) : \"Election Period\",\n","                datetime.date(2025, 5, 30) : \"Election Period\",\n","                datetime.date(2025, 6, 3) : \"Presidential Election Day\"})\n","            return kor_holidays\n","\n","        def check_holidays(self, date, kor_holidays) -> int:\n","            \"\"\"날짜 받아서 공휴일/주말 여부 출력\"\"\"\n","            # date = pd.Timestamp(date)\n","            if isinstance(date, pd.Series):\n","                check_holiday = date.dt.date.isin(kor_holidays)\n","                check_weekend = date.dt.weekday >= 5\n","            else:\n","                check_holiday = date.date() in kor_holidays\n","                check_weekend = date.weekday() >= 5\n","            is_holiday = (check_holiday | check_weekend)\n","            return is_holiday\n","\n","        def get_sandwich_score(self, data, is_holiday_col) -> pd.DataFrame:\n","            \"\"\"데이터프레임 기준으로 샌드위치 점수 계산\"\"\"\n","            data = data.reset_index(drop = True)\n","            data['is_sandwich'] = 0\n","            is_holiday = data[is_holiday_col].astype(int)\n","            for idx in range(len(data)):\n","                if idx == 0 or idx == len(data) - 1: # 첫날, 마지막 날\n","                    continue\n","\n","                # 앞/뒤 하루씩 봤을 때 모두 휴일 -> 5점\n","                if (is_holiday.iloc[idx - 1] == 1) and (is_holiday.iloc[idx + 1] == 1): # 하루 전이랑 다음 날이 공휴일이면\n","                    data.iloc[idx, data.columns.get_loc('is_sandwich')] = 5\n","\n","                # 앞/뒤 이틀씩 봤을 때 휴일 3일 -> 3점, 2일 -> 2점\n","                elif idx > 1 and idx < len(is_holiday) - 2: # 셋째날, 마지막에서 세 번째 날\n","                    start_idx = idx - 2\n","                    end_idx = idx + 2\n","                    nearby_holidays = (is_holiday.iloc[start_idx : end_idx + 1].sum() - is_holiday.iloc[idx])\n","                    if nearby_holidays == 3:\n","                        data.iloc[idx, data.columns.get_loc('is_sandwich')] = 3\n","                    elif nearby_holidays == 2:\n","                        data.iloc[idx, data.columns.get_loc('is_sandwich')] = 2\n","                    else:\n","                        data.iloc[idx, data.columns.get_loc('is_sandwich')] = 0\n","            return data\n","\n","        def get_sandwich_score_for_dates(self, date, kor_holidays) -> int:\n","            \"\"\"특정 날짜를 받아와서 앞뒤 날짜를 구하고, 샌드위치 점수 계산\"\"\"\n","            # 하루씩\n","            prev_date, next_date = date - timedelta(days = 1), date + timedelta(days = 1)\n","            prev_hol, next_hol = self.check_holidays(prev_date, kor_holidays), self.check_holidays(next_date, kor_holidays) # T/F Bool\n","            if prev_hol and next_hol: # 바로 다음 날들이 휴일이라면\n","                return 3\n","            days_offsets = [-2, -1, 1, 2] # 앞뒤로 이틀 살펴보기\n","            nearby_holidays = sum(self.check_holidays(date + timedelta(days = d), kor_holidays) for d in days_offsets)\n","            if nearby_holidays == 3: # 앞뒤 4일 중에 3일이 휴일이면\n","                return 2\n","            elif nearby_holidays == 2: # 앞뒤 4일 중에 2일이 휴일이면\n","                return 1\n","            else:\n","                return 0\n","\n","        def get_month_weights(self, data = None, monthly_weights = monthly_weights):\n","            \"\"\"월별 가중치 부여\"\"\"\n","            # 데이터프레임 들어오면\n","            if data is not None:\n","                data['month_weight'] = data['month'].map(monthly_weights)\n","                return data\n","\n","        def get_week_weights(self, data = None, weekly_weights = weekly_weights):\n","            \"\"\"요일별 가중치 부여\"\"\"\n","            # 데이터프레임 들어오면\n","            if data is not None:\n","                data['week_weight'] = data['weekday'].map(weekly_weights)\n","                return data\n","\n","        def get_prev_days(self, data, test_df = None, date = None, menu = None, howmany = 7):\n","            \"\"\"\n","            일요일 날짜 받아와서 직전 주차의 일-토 매출수량 평균 계산\n","            주의 - test data에서 생성할 때는 참고할 데이터와 붙여넣을 데이터가 다름\n","            data : 참고할 데이터\n","            test_df : 참고할 데이터\n","            \"\"\"\n","            if test_df is None:\n","                # 혹시 모르니까 검증\n","                if date.weekday() == 6:\n","                    # 이전 날짜들\n","                    prev_start = date - timedelta(days = howmany)\n","                    prev_end = date - timedelta(days = 1)\n","                    prev_data = data[(data['영업일자'] >= prev_start) & (data['영업일자'] <= prev_end) & (data['영업장명_메뉴명'] == menu)]\n","                    prev_avg = prev_data['매출수량'].mean()\n","                    prev_sd = prev_data['매출수량'].std()\n","                    # 첫 주 0으로 처리\n","                    if pd.isna(prev_avg):\n","                        prev_avg = 0\n","                    if pd.isna(prev_sd):\n","                        prev_sd = 0\n","                    week_end = date + timedelta(days = 6)\n","                    curr_mask = (data['영업일자'] >= date) & (data['영업일자'] <= week_end) & (data['영업장명_메뉴명'] == menu)\n","                    colname_mean = f\"prev_avg_{howmany}\"\n","                    colname_sd = f\"prev_sd_{howmany}\"\n","                    data.loc[curr_mask, colname_mean] = prev_avg\n","                    data.loc[curr_mask, colname_sd] = prev_sd\n","                    return data\n","                else:\n","                    return np.nan\n","\n","            # test data라면\n","            else:\n","                # 혹시 모르니까 검증\n","                if date.weekday() == 6:\n","                    # 이전 날짜들\n","                    prev_start = date - timedelta(days = howmany)\n","                    prev_end = date - timedelta(days = 1)\n","                    prev_data = test_df[(test_df['영업일자'] >= prev_start) & (test_df['영업일자'] <= prev_end) & (test_df['영업장명_메뉴명'] == menu)]\n","                    prev_avg = prev_data['매출수량'].mean()\n","                    prev_sd = prev_data['매출수량'].std()\n","                    # 첫 주 0으로 처리\n","                    if pd.isna(prev_avg):\n","                        prev_avg = 0\n","                    if pd.isna(prev_sd):\n","                        prev_sd = 0\n","                    week_end = date + timedelta(days = 6)\n","                    curr_mask = (data['영업일자'] >= date) & (data['영업일자'] <= week_end) & (data['영업장명_메뉴명'] == menu)\n","                    colname_mean = f\"prev_avg_{howmany}\"\n","                    colname_sd = f\"prev_sd_{howmany}\"\n","                    data.loc[curr_mask, colname_mean] = prev_avg\n","                    data.loc[curr_mask, colname_sd] = prev_sd\n","                    return data\n","                else:\n","                    return np.nan\n","\n","\n","        # train, test 공통\n","        def make_fund_variables(self, data, month_to_season = month_to_season):\n","            # 영업일자 -> datetime\n","            data['영업일자'] = pd.to_datetime(data['영업일자'])\n","\n","            # 연, 월, 일, 요일 분리\n","            data['year'] = data['영업일자'].dt.year\n","            data['month'] = data['영업일자'].dt.month\n","            data['day'] = data['영업일자'].dt.day\n","            data['weekday'] = data['영업일자'].dt.day_name()\n","            data['weekday_enc'] = data['영업일자'].dt.weekday\n","\n","            # 계절 변수 생성\n","            data['season'] = data['month'].map(month_to_season)\n","\n","            # 연도 차이 변수 생성\n","            data['year_enc'] = data['year'] - 2023\n","\n","            # 월, 일, 요일 사이클릭 변환\n","            data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n","            data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n","\n","            data['day_sin'] = np.sin(2 * np.pi * data['day'] / 31)\n","            data['day_cos'] = np.cos(2 * np.pi * data['day'] / 31)\n","\n","            data['weekday_sin'] = np.sin(2 * np.pi * data['weekday_enc'] / 7)\n","            data['weekday_cos'] = np.cos(2 * np.pi * data['weekday_enc'] / 7)\n","\n","            # 공휴일 확인\n","            kor_holidays = self.update_kor_holidays()\n","            check_holiday = data['영업일자'].dt.date.isin(kor_holidays)\n","            check_weekend = data['weekday'].isin(['Saturday', 'Sunday'])\n","            data['is_holiday'] = (check_holiday | check_weekend).astype(int) # 공휴일 + 주말\n","            data['holiday_name'] = data['영업일자'].dt.date.map(kor_holidays)\n","\n","            return data\n","\n","        # train의 입력 데이터\n","        def make_variables_train(self, data):\n","            data = self.make_fund_variables(data)\n","            kor_holidays = self.update_kor_holidays()\n","\n","            ### 샌드위치 데이\n","            data = self.get_sandwich_score(data, 'is_holiday')\n","\n","            # 샌드위치 - 첫날\n","            first = data['영업일자'].min()\n","            data.loc[data['영업일자'] == first, 'is_sandwich'] = self.get_sandwich_score_for_dates(first, kor_holidays)\n","            second = data['영업일자'].min() + timedelta(days = 1)\n","            data.loc[data['영업일자'] == second, 'is_sandwich'] = self.get_sandwich_score_for_dates(second, kor_holidays)\n","\n","            # 샌드위치 - 마지막 날\n","            last = data['영업일자'].max()\n","            data.loc[data['영업일자'] == last, 'is_sandwich'] = self.get_sandwich_score_for_dates(last, kor_holidays)\n","            before = data['영업일자'].max() - timedelta(days = 1)\n","            data.loc[data['영업일자'] == before, 'is_sandwich'] = self.get_sandwich_score_for_dates(before, kor_holidays)\n","\n","            # 샌드위치 포함한 공휴일\n","            data['is_holiday_sandwich'] = data['is_holiday'].astype(int) | (data['is_sandwich'] > 0).astype(int)\n","\n","            ### 월별 가중치\n","            data = self.get_month_weights(data, monthly_weights)\n","\n","            ### 요일별 가중치\n","            data = self.get_week_weights(data, weekly_weights)\n","\n","            ### 직전 주차 평균\n","            sundays = data[data['weekday'] == \"Sunday\"][[\"영업일자\", \"영업장명_메뉴명\"]].copy()\n","            for _, row in sundays.iterrows():\n","                date = row['영업일자']\n","                menu = row['영업장명_메뉴명']\n","                data = self.get_prev_days(data = data, date = date, menu = menu, howmany = 7)\n","                data = self.get_prev_days(data = data, date = date, menu = menu, howmany = 14)\n","                data = self.get_prev_days(data = data, date = date, menu = menu, howmany = 21)\n","\n","            ### 영업장명, 메뉴명 분리\n","            if '영업장명_메뉴명' in data.columns:\n","                data[['영업장명', '메뉴명']] = data['영업장명_메뉴명'].str.split('_', expand = True)\n","\n","            ### 음수 처리\n","            negative = data[data['매출수량'] < 0]\n","\n","            for idx, row in negative.iterrows():\n","                num = row['매출수량']\n","                if num < -10:\n","                    date = row['영업일자']\n","                    menu = row['영업장명_메뉴명']\n","                    prev_date = pd.to_datetime(date) - pd.Timedelta(days = 1)\n","                    prev_row = data[(data['영업일자'] == prev_date) & (data['영업장명_메뉴명'] == menu)]\n","\n","                    if prev_row.iloc[0][\"매출수량\"] >= abs(num):\n","                        data.loc[prev_row.index[0], '매출수량'] += num\n","\n","            # 남은 건 전부 0으로\n","            data.loc[data['매출수량'] < 0, '매출수량'] = 0\n","\n","            return data\n","\n","        # 예측하고자 하는 날들\n","        def make_variables_test(self, date, test_df, predict):\n","            \"\"\"\n","            date : 최종 날짜 (입력 7일 중 가장 마지막) - TimeStamp\n","            test_df : 예측할 때 참고해올 데이터 -> 이거로 직전 주차 평균 생성\n","            \"\"\"\n","            date = pd.to_datetime(date)\n","            future_dates = [date + timedelta(days = i + 1) for i in range(predict)]\n","            future_df = pd.DataFrame({'영업일자' : future_dates})\n","\n","            menus_df = (test_df[['영업장명_메뉴명']].drop_duplicates().reset_index(drop = True))\n","            future_df = future_df.merge(menus_df, how='cross')\n","\n","            kor_holidays = self.update_kor_holidays()\n","\n","            # 기본적인 변수들\n","            future_df = self.make_fund_variables(future_df)\n","\n","            future_df['영업일자'] = pd.to_datetime(future_df['영업일자']).dt.normalize()\n","\n","            # 샌드위치\n","            future_df['is_sandwich'] = future_df['영업일자'].apply(lambda d: self.get_sandwich_score_for_dates(d, kor_holidays))\n","\n","             # 샌드위치 포함한 공휴일\n","            future_df['is_holiday_sandwich'] = future_df['is_holiday'].astype(int) | (future_df['is_sandwich'] > 0).astype(int)\n","\n","            # 월별 가중치\n","            future_df = self.get_month_weights(future_df, monthly_weights)\n","\n","            # 요일별 가중치\n","            future_df = self.get_week_weights(future_df, weekly_weights)\n","\n","            # 직전 주차 평균 -> 이거는 test 까지 받아오고 생각해야 함..\n","            sundays =  future_df.loc[future_df['weekday'] == \"Sunday\", ['영업일자', '영업장명_메뉴명']].copy()\n","            for _, row in sundays.iterrows():\n","                date = row['영업일자']\n","                menu = row['영업장명_메뉴명']\n","                future_df = self.get_prev_days(data = future_df, test_df = test_df, date = date, menu = menu, howmany = 7)\n","                future_df = self.get_prev_days(data = future_df, test_df = test_df, date = date, menu = menu, howmany = 14)\n","                future_df = self.get_prev_days(data = future_df, test_df = test_df, date = date, menu = menu, howmany = 21)\n","\n","            return future_df"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"eSOBveVOoNIS"},"outputs":[],"source":["# 그냥 전부 만들면 돼\n","mv = Make_Variables()\n","data = mv.make_variables_train(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1755069295751,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"igarBBY4-iYw","outputId":"4380c8c7-0885-4b3f-b140-6d1ad483647b"},"outputs":[{"name":"stdout","output_type":"stream","text":["기존 공휴일 :  33389\n","샌드위치 :  579\n","샌드위치 포함 공휴일 :  33968\n"]}],"source":["print(\"기존 공휴일 : \", data['is_holiday'].sum().item())\n","print(\"샌드위치 : \", data['is_sandwich'].sum().item())\n","print(\"샌드위치 포함 공휴일 : \", data['is_holiday_sandwich'].sum().item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPZoqlrc-rxW"},"outputs":[],"source":["import pickle\n","data.to_pickle(\"/content/drive/MyDrive/3. Grad School/LG Aimers/DATA/train_data_new.pickle\")"]},{"cell_type":"markdown","metadata":{"id":"_xQZUH_KcAni"},"source":["#### 저장된 데이터 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llh2iAftY62P"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQk40UmYKn7K"},"outputs":[],"source":["cols =  [\"year_enc\", \"month_sin\", \"month_cos\", \"day_sin\", \"day_cos\", \"weekday_sin\", \"weekday_cos\", \"season\", \"is_holiday\", \"is_sandwich\", \"is_holiday_sandwich\", \"month_weight\", \"week_weight\",\n","         \"prev_avg_7\", \"prev_avg_14\", \"prev_avg_21\", \"prev_sd_7\", \"prev_sd_14\", \"prev_sd_21\"]\n","enc_cols = [\"season\", \"is_holiday\", \"is_holiday_sandwich\"]\n","# lstm에서는 minmaxscaling 해주는 게 안전\n","num_cols = [\"is_sandwich\", \"month_weight\", \"week_weight\", \"prev_avg_7\", \"prev_avg_14\", \"prev_avg_21\", \"prev_sd_7\", \"prev_sd_14\", \"prev_sd_21\"]"]},{"cell_type":"markdown","metadata":{"id":"u9ImcgXgKdEC"},"source":["#### 매출 여부 (분류)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":8385,"status":"ok","timestamp":1755315365169,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"YwyEf8ZCKgIE","outputId":"2390da6d-7baa-4866-f761-f71c6c79c567"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting category_encoders\n","  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n","Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n","Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: category_encoders\n","Successfully installed category_encoders-2.8.1\n"]}],"source":["from xgboost import XGBClassifier\n","from sklearn.model_selection import TimeSeriesSplit\n","! pip install category_encoders\n","from category_encoders import TargetEncoder\n","from sklearn.metrics import f1_score\n","from typing import Dict, List, Optional, Any\n","from collections import defaultdict\n","import pickle\n","import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBEA6_DYKRXo"},"outputs":[],"source":["class ClassificationModel():\n","    def __init__(self, data = None, cols = None, enc_cols = None, model_path = None):\n","        self.data = data\n","        self.cols = cols\n","        self.enc_cols = enc_cols\n","\n","    def fit_model_cv(self, data : pd.DataFrame, cols : List[str], enc_cols : List[str]) -> pd.DataFrame:\n","        \"\"\"\n","        data - 전체 dataset\n","        cols - 전체 변수들\n","        enc_cols - 인코딩 진행할 변수들 (범주형)\n","        \"\"\"\n","        oof_parts = []\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values('영업일자')\n","\n","            # 나중에 oof 저장할 때 사용할 것들\n","            org_idx = group_df.index\n","            oof_proba = np.full(len(group_df), np.nan)\n","\n","            # x, y 분리\n","            x = group_df[cols]\n","            y = group_df[\"매출_여부\"]\n","\n","            # time series split\n","            tscv = TimeSeriesSplit(n_splits = 3)\n","\n","            # 각 split 별로\n","            for fold, (train_idx, val_idx) in enumerate(tscv.split(x)):\n","\n","                x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n","                x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n","\n","                # 수량 전부 0이거나 0 아닌 날 없으면 학습 불가\n","                if y_train.nunique() < 2:\n","                    print(f\"{menu} 학습 불가\")\n","                    continue\n","\n","                # 범주형 변수 인코딩\n","                target_encoder = TargetEncoder()\n","                target_encoder.fit(x_train[enc_cols], y_train)\n","\n","                x_train = pd.concat([\n","                    target_encoder.transform(x_train[enc_cols]),\n","                    x_train[[c for c in cols if c not in enc_cols]]\n","                ], axis = 1)\n","\n","                x_val = pd.concat([\n","                    target_encoder.transform(x_val[enc_cols]),\n","                    x_val[[c for c in cols if c not in enc_cols]]\n","                ], axis = 1)\n","\n","                # 모델 설정\n","                xgb_model = XGBClassifier(random_state = 1471)\n","\n","                # 모델 학습\n","                xgb_model.fit(x_train, y_train)\n","                oof_proba[val_idx] = xgb_model.predict_proba(x_val)[:, 1]\n","\n","            part = pd.DataFrame({\n","                \"index\": org_idx.values,\n","                \"영업장명_메뉴명\": menu,\n","                \"y_true\": group_df[\"매출_여부\"].values,\n","                \"y_proba\": oof_proba\n","            }).set_index(\"index\")\n","\n","            oof_parts.append(part)\n","\n","        oof_df = pd.concat(oof_parts).sort_index()\n","        return oof_df\n","\n","\n","    def tuning_cv(self, data, cols, enc_cols, param_grid):\n","        \"\"\"\n","        메뉴별로 하이퍼파라미터 튜닝 진행 (성능 보고.. 추가 진행? )\n","        \"\"\"\n","        best_params_by_menu = {}\n","\n","        return None\n","\n","\n","    def tune_threshold(self, oof_df : pd.DataFrame, metric = 'f1') -> Dict[str, float]:\n","        \"\"\"\n","        메뉴별로 OOF 데이터프레임을 받아와서\n","        threshold를 최적화\n","        metric으로는 f1 사용\n","        \"\"\"\n","        best_thresholds = {}\n","\n","        for menu, group_df in oof_df.groupby(\"영업장명_메뉴명\"):\n","            y_true = group_df[\"y_true\"].values\n","            y_proba = group_df[\"y_proba\"].values\n","\n","            # 초기값 진행\n","            best_score, best_thr = -1, 0.5\n","            for thr in np.linspace(0.05, 0.95, 51):\n","                y_pred = (y_proba >= thr).astype(int)\n","                score = f1_score(y_true, y_pred, zero_division = 0)\n","                if score > best_score:\n","                    best_score = score\n","                    best_thr = thr\n","\n","            best_thresholds[menu] = best_thr\n","\n","        return best_thresholds\n","\n","\n","    def get_final_model(self, data, cols, enc_cols, thresholds, hyperparameters_dict = None) -> Dict[str, Dict[str, Any]]:\n","        \"\"\"\n","        메뉴별로 튜닝된 하이퍼파라미터, threshold를 반영하여\n","        최종 모델 적합\n","        \"\"\"\n","        models = {}\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values('영업일자')\n","\n","            # 범주형 변수 처리 - 전체 데이터로\n","            target_encoder_full = TargetEncoder()\n","            group_df[enc_cols] = target_encoder_full.fit_transform(group_df[enc_cols], group_df['매출_여부'])\n","\n","            # x, y 분리\n","            x_full = group_df[cols]\n","            y_full = group_df[\"매출_여부\"]\n","\n","            # 하이퍼파라미터\n","            hyperparameters = hyperparameters_dict.get(menu, {}) if hyperparameters_dict else {}\n","\n","            # 모델 설정\n","            xgb_model_full = XGBClassifier(random_state = 1471, **hyperparameters)\n","\n","            # 모델 학습\n","            xgb_model_full.fit(x_full, y_full)\n","\n","            models[menu] = {\n","                \"model\" : xgb_model_full,\n","                \"encoder\" : target_encoder_full,\n","                \"threshold\" : thresholds.get(menu, 0.5)}\n","\n","        return models\n","\n","    def fit_whole_model(self, data, cols, enc_cols) -> Dict[str, Dict[str, Any]]:\n","        oof_df = self.fit_model_cv(data, cols, enc_cols)\n","        print(\"CV 완료!\")\n","        thresholds = self.tune_threshold(oof_df)\n","        print(\"threshold 탐색 완료!\")\n","        models = self.get_final_model(data, cols, enc_cols, thresholds)\n","        return models\n","\n","    def save_cls_model(self, models, model_path):\n","        joblib.dump(models, model_path)\n","        print(\"모델 저장 완료!\")\n","\n","    def load_saved_model(self, model_path):\n","        models = joblib.load(model_path)\n","        return models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwQhR-vQO84K"},"outputs":[],"source":["classification = ClassificationModel()\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 3/cls_models.pkl'\n","\n","data_zero = data.copy()\n","data_zero['매출_여부'] = data_zero['매출수량'].apply(lambda x:1 if x > 0 else 0)\n","\n","models = classification.fit_whole_model(data = data_zero, cols = cols, enc_cols = enc_cols)\n","classification.save_cls_model(models, model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpJeynRUZsjN"},"outputs":[],"source":["# 다시 불러오기\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 6/cls_models.pkl'\n","classification = ClassificationModel()\n","models_class = classification.load_saved_model(model_path)"]},{"cell_type":"code","source":["    def predict_reg_model(self, test_df, trained_model, test_prefix : str, cols : list, enc_cols : list, data, lookback = 28, predict = 7):\n","        \"\"\"\n","        Input : test_df - test data, trained_model - {~~}, original_data : train할 때 사용한 데이터 (data)\n","        Output : [영업일자, 영업장명_메뉴명, 매출수량] DataFrame\n","        \"\"\"\n","        results = []\n","\n","        # 모델 불러오기\n","        model = trained_model[\"model\"]\n","        encoder = trained_model[\"encoder\"]\n","\n","        # 변수 추가하기\n","        mv = Make_Variables()\n","\n","        for store_menu, store_df in test_df.groupby(['영업장명_메뉴명']):\n","\n","            store_df['영업일자'] = pd.to_datetime(store_df['영업일자'])\n","            store_df_sorted = store_df.sort_values('영업일자')\n","            last_date = store_df_sorted['영업일자'].iloc[-1]\n","\n","            future_df = mv.make_variables_test(date = last_date, test_df = store_df, original_data = data, predict = 7)\n","            if enc_cols:\n","                future_df[enc_cols] = encoder.transform(future_df[enc_cols])\n","\n","            # 사용할 변수만\n","            future_df = future_df[cols]\n","\n","            # 로그 변환 처리\n","            predicted = model.predict(future_df)\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, predicted):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출수량': val\n","                })\n","\n","        return pd.DataFrame(results)"],"metadata":{"id":"QN7l-eAg_zYv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i2wKL_C6P2Bp"},"source":["#### 매출 예측 (회귀)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7PqUIigSomp"},"outputs":[],"source":["from xgboost import XGBRegressor\n","# ! pip install category_encoders\n","from category_encoders import TargetEncoder\n","from sklearn.model_selection import TimeSeriesSplit\n","from collections import defaultdict\n","from itertools import product\n","import pickle\n","import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CY881cMBP4Ka"},"outputs":[],"source":["class RegressionModel():\n","    def __init__(self, data = None, cols = None, enc_cols = None, model_path = None):\n","        self.data = data\n","        self.cols = cols\n","        self.enc_cols = enc_cols\n","\n","    def smape_score(self, y_true, y_pred, eps = 1e-8):\n","        y_true = np.asarray(y_true, dtype=float)\n","        y_pred = np.asarray(y_pred, dtype=float)\n","        denom = np.abs(y_true) + np.abs(y_pred)\n","        denom = np.where(denom < eps, eps, denom)\n","        return 200.0 * np.mean(np.abs(y_true - y_pred) / denom)\n","\n","    def tuning_cv(self, data : pd.DataFrame, cols : List[str], enc_cols : List[str], param_grid = None) -> Dict[str, Dict]:\n","        \"\"\"\n","        메뉴별로 하이퍼파라미터 튜닝 진행\n","        \"\"\"\n","        best_params_by_menu = {}\n","\n","        if param_grid is None:\n","            param_grid = {\n","                \"min_child_weight\" : [1, 5],\n","                \"max_depth\" : [5, 6, 7],\n","                \"subsample\" : [0.7, 0.9],\n","                \"n_estimators\" : [100, 150],\n","                \"learning_rate\" : [0.03, 0.05]}\n","\n","        keys = list(param_grid.keys())\n","        combos = list(product(*[param_grid[k] for k in keys]))\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values(\"영업일자\")\n","\n","            x = group_df[cols]\n","            y = group_df[\"매출수량\"]\n","\n","            # time series split\n","            tscv = TimeSeriesSplit(n_splits = 3)\n","\n","            # 초기값\n","            best_smape = np.inf\n","            best_params = None\n","\n","            for values in combos:\n","                params = dict(zip(keys, values))\n","\n","                base_params = {\"random_state\" : 1478}\n","                base_params.update(params)\n","\n","                fold_smapes : List[float] = []\n","\n","                for fold, (train_idx, val_idx) in enumerate(tscv.split(x)):\n","\n","                    x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n","                    x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n","\n","                    # 데이터 수 적으면 학습 불가\n","                    if len(x_train) < 20:\n","                        print(f\"{menu} 튜닝 불가)\")\n","                        continue\n","\n","                    # 범주형 변수 인코딩\n","                    target_encoder = TargetEncoder()\n","                    target_encoder.fit(x_train[enc_cols], y_train)\n","\n","                    x_train = pd.concat([\n","                        target_encoder.transform(x_train[enc_cols]),\n","                        x_train[[c for c in cols if c not in enc_cols]]\n","                    ], axis = 1)\n","\n","                    x_val = pd.concat([\n","                        target_encoder.transform(x_val[enc_cols]),\n","                        x_val[[c for c in cols if c not in enc_cols]]\n","                    ], axis = 1)\n","\n","                    # 모델 설정\n","                    xgb_model = XGBRegressor(**base_params)\n","\n","                    # 모델 학습\n","                    xgb_model.fit(x_train, y_train)\n","\n","                    pred = xgb_model.predict(x_val)\n","                    smape = self.smape_score(y_val, pred)\n","                    fold_smapes.append(smape)\n","\n","                mean_smape = float(np.mean(fold_smapes))\n","\n","                if mean_smape < best_smape:\n","                    best_smape = mean_smape\n","                    best_params = base_params\n","\n","            if best_params is not None:\n","                best_params_by_menu[menu] = best_params\n","\n","        return best_params_by_menu\n","\n","\n","    def get_final_model(self, data, cols, enc_cols, hyperparameters_dict : dict[str, dict[str, Any]] = None)  -> Dict[str, Dict[str, Any]]:\n","        \"\"\"\n","        data, validation_reg - train, validation dataset\n","        cols - 전체 변수들\n","        enc_cols - 인코딩 진행할 변수들 (범주형)\n","        \"\"\"\n","        models = {}\n","\n","        for menu, group_df in data.groupby(\"영업장명_메뉴명\"):\n","\n","            group_df = group_df.sort_values(\"영업일자\")\n","\n","            # 데이터 수 적으면 학습 불가\n","            if len(group_df) < 10:\n","                print(f\"{menu} 학습 불가\")\n","                continue\n","\n","            # 범주형 변수 처리\n","            target_encoder_full = TargetEncoder()\n","            group_df[enc_cols] = target_encoder_full.fit_transform(group_df[enc_cols], group_df['매출수량'])\n","\n","            # x, y 분리\n","            x_full = group_df[cols]\n","            y_full = group_df[\"매출수량\"]\n","\n","            # 하이퍼파라미터 불러오기\n","            params = hyperparameters_dict.get(menu, {}) if hyperparameters_dict else {}\n","\n","            base_params = {\"random_state\" : 1478}\n","            base_params.update(params)\n","\n","            # 모델 설정\n","            xgb_model_full = XGBRegressor(**base_params)\n","\n","            # 모델 학습\n","            xgb_model_full.fit(x_full, y_full)\n","\n","            models[menu] = {\n","                \"model\" : xgb_model_full,\n","                \"hyperparameters\" : base_params,\n","                \"encoder\" : target_encoder_full\n","            }\n","\n","        return models\n","\n","    def fit_whole_model(self, data, cols, enc_cols) -> Dict[str, Dict[str, Any]]:\n","        best_params_by_menu = self.tuning_cv(data, cols, enc_cols)\n","        print(\"튜닝 완료!\")\n","        models = self.get_final_model(data, cols, enc_cols, best_params_by_menu)\n","        return models\n","\n","    def save_reg_model(self, models, model_path):\n","        joblib.dump(models, model_path)\n","        print(\"모델 저장 완료!\")\n","\n","    def load_saved_model(self, model_path):\n","        models = joblib.load(model_path)\n","        return models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2208435,"status":"ok","timestamp":1755273963548,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"2oFlYQvtTIwS","outputId":"99882861-0a6d-412c-de10-6c1bfcae4d75"},"outputs":[{"output_type":"stream","name":"stdout","text":["튜닝 완료!\n","모델 저장 완료!\n"]}],"source":["regression = RegressionModel()\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 6/reg_models.pkl'\n","\n","data_notzero = data[data['매출수량'] > 0]\n","\n","models = regression.fit_whole_model(data = data_notzero, cols = cols, enc_cols = enc_cols)\n","regression.save_reg_model(models, model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ev79J1ENbN19"},"outputs":[],"source":["# 다시 불러오기\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 6/reg_models.pkl'\n","regression = RegressionModel()\n","models_reg = regression.load_saved_model(model_path)"]},{"cell_type":"markdown","metadata":{"id":"0d2L76egP4Yi"},"source":["#### 매출 예측 (시계열)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBR9gHpRP50T"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import TimeSeriesSplit\n","import random\n","import glob\n","import joblib\n","\n","import torch\n","import torch.nn as nn\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXjwjBNVTvWB"},"outputs":[],"source":["### Random Seed & Parameters\n","def set_seed(seed = 1471):\n","    random.seed(seed) # 일반 seed\n","    np.random.seed(seed) # numpy 난수 고정\n","    torch.manual_seed(seed) # CPU 난수 고정\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_seed(1478)"]},{"cell_type":"markdown","source":["##### Loss Functions"],"metadata":{"id":"Qbp0yN6WBSq5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GznnD4qlTz0r"},"outputs":[],"source":["# weight 직접 입력해서 반영 가능\n","class WeightedSMAPELoss(nn.Module):\n","    def __init__(self, eps=1e-8):\n","        super().__init__()\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true, w=None):\n","        num = (y_pred - y_true).abs()\n","        den = (y_pred.abs() + y_true.abs()).clamp(min=self.eps)\n","        smape = 2.0 * num / (den)\n","\n","        mask = (y_true != 0).float()\n","        if w is None:\n","            w = torch.ones_like(y_true)\n","        else:\n","            if w.dim() == 1:\n","                w = w.view(-1, 1)\n","            w = w.expand_as(y_true)\n","\n","        w_mask = w * mask\n","        denom = w_mask.sum().clamp(min=self.eps)\n","        loss = (smape * w_mask).sum() / denom\n","        return loss\n","\n","# weighted huberLoss\n","class WeightedHuberLoss(nn.Module):\n","    def __init__(self, delta = 1.0, zeros : bool = False, eps = 1e-8):\n","        \"\"\"\n","        delta -L2 -> L1로 전환되는 임계값\n","        zeros - y_true = 0인 샘플 제외할지 여부\n","        eps - 분모가 0이 되는 것을 방지하기 위한 작은 값\n","        \"\"\"\n","        super().__init__()\n","        self.delta = float(delta)\n","        self.zeros = bool(zeros)\n","        self.eps = float(eps)\n","\n","    def forward(self, y_pred, y_true, w = None):\n","        \"\"\"\n","        w -  (N, ) 형태로 된 가중치\n","        \"\"\"\n","        error = y_pred - y_true\n","        abs_error = error.abs()\n","        huber = torch.where(\n","            abs_error <= self.delta,\n","            0.5 * error**2,\n","            self.delta * (abs_error - 0.5 * self.delta),\n","        )\n","\n","        if self.zeros:\n","            mask = (y_true != 0).float()\n","        else:\n","            mask = torch.ones_like(y_true)\n","\n","        if w is None:\n","            w_full = torch.ones_like(y_true)\n","        else:\n","            if w.dim() == 1:\n","                w = w.view(-1, 1) # (N, 1)로 확장\n","            w_full = w.expand_as(y_true).float()\n","\n","        w_mask = w_full * mask\n","        denom = w_mask.sum().clamp(min=self.eps)\n","        return (huber * w_mask).sum() / denom\n","\n","# SMAPE + Huber Loss\n","class CombinationLoss(nn.Module):\n","    def __init__(self, losses, weights):\n","        \"\"\"\n","        losses - 결합할 손실 리스트\n","        weights - 각 손실의 가중치 리스트\n","        \"\"\"\n","        super().__init__()\n","        if not losses or len(losses) != len(weights):\n","            raise ValueError(\"loss 배열과 weight 배열의 길이가 다릅니다.\")\n","        self.losses = nn.ModuleList(losses)\n","\n","        weight_tensor = torch.tensor(weights, dtype=torch.float32)\n","        self.weights = weight_tensor / weight_tensor.sum()\n","\n","    def forward(self, y_pred, y_true, w = None):\n","        \"\"\"\n","        w - 공통 가중치\n","        \"\"\"\n","        total_loss = 0.0\n","        device_weights = self.weights.to(y_pred.device)\n","        for i, lf in enumerate(self.losses):\n","            loss = lf(y_pred, y_true, w)\n","            total_loss += device_weights[i] * loss\n","        return total_loss"]},{"cell_type":"code","source":["def build_menu_weights(\n","    df: pd.DataFrame,\n","    menu_key: str = \"영업장명_메뉴명\",\n","    target_col: str = \"매출수량\",\n","    dispersion: str = \"p95-p5\",   # \"range\" | \"iqr\" | \"std\" | \"p95-p5\"\n","    alpha: float = 1.0,            # 민감도 (↑ 크면 가중치 차이 커짐)\n","    clip: tuple = (0.25, 4.0),     # 과도한 비율 방지\n","    eps: float = 1e-6\n",") -> dict:\n","    \"\"\"\n","    메뉴별 난이도(분산/범위) 기반 가중치 (간극 ↑ -> 가중치 ↑)\n","    반환: {menu_key -> weight}\n","    \"\"\"\n","    disp_vals = {}\n","    for k, g in df.groupby(menu_key):\n","        y = g[target_col].to_numpy()\n","        if len(y) == 0:\n","            disp = 0.0\n","        else:\n","            if dispersion == \"range\":\n","                disp = float(np.max(y) - np.min(y))\n","            elif dispersion == \"iqr\":\n","                q75, q25 = np.percentile(y, [75, 25])\n","                disp = float(q75 - q25)\n","            elif dispersion == \"std\":\n","                disp = float(np.std(y))\n","            else:  # \"p95-p5\"\n","                q95, q5 = np.percentile(y, [95, 5])\n","                disp = float(q95 - q5)\n","        disp_vals[k] = disp\n","\n","    # 분포 → 가중치 (단조증가), 평균 1로 정규화\n","    disp_series = pd.Series(disp_vals)\n","    # 0도 있을 수 있으니 +eps, 로그스케일 쓰고 싶으면 바꿔도 됨\n","    raw_w = (disp_series + eps) ** alpha\n","    w = raw_w / raw_w.mean()\n","\n","    # 과도한 값 클램프 (옵션)\n","    w = w.clip(lower=clip[0], upper=clip[1])\n","    return w.to_dict()\n","\n","def build_store_weights(\n","    df: pd.DataFrame,\n","    store_col: str = \"영업장명\",\n","    menu_col: str = \"메뉴명\",      # 없으면 아래에서 자동 fallback\n","    combined_key: str = \"영업장명_메뉴명\",\n","    beta: float = 1.0,             # 메뉴 가짓수 민감도\n","    clip: tuple = (0.5, 3.0)\n",") -> dict:\n","    \"\"\"\n","    음식점별 메뉴 가짓수 기반 가중치 (가짓수 ↑ -> 가중치 ↑)\n","    반환: {store -> weight}\n","    \"\"\"\n","    if (store_col in df.columns) and (menu_col in df.columns):\n","        n_menu = df.groupby(store_col)[menu_col].nunique()\n","    else:\n","        # fallback: combined_key에서 store를 추출 (최초 '_' 기준 split)\n","        def get_store(x: str) -> str:\n","            # 필요하면 사용자 규칙에 맞게 수정\n","            return str(x).split(\"_\", 1)[0]\n","        tmp = df[[combined_key]].copy()\n","        tmp[store_col] = tmp[combined_key].astype(str).map(get_store)\n","        # store별 unique combined_key 개수 = 메뉴 가짓수로 근사\n","        n_menu = tmp.groupby(store_col)[combined_key].nunique()\n","\n","    raw_w = (n_menu.astype(float) + 1e-6) ** beta\n","    w = raw_w / raw_w.mean()\n","    w = w.clip(lower=clip[0], upper=clip[1])\n","    return w.to_dict()"],"metadata":{"id":"V4LzzOZ4RAaS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### LSTMModel"],"metadata":{"id":"e3d0i4MHBU4x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1brZnPwP96i"},"outputs":[],"source":["class MultiOutputLSTM(nn.Module):\n","        def __init__(self, input_dim = 1, hidden_dim = 256, num_layers = 4, output_dim = 7, dropout = 0.4):\n","            \"\"\" 7개 값 예측 (PREDICT 만큼의 날짜의 값을 예측하고자 함)\"\"\"\n","            super(MultiOutputLSTM, self).__init__()\n","            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first = True, dropout = dropout)\n","            self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        def forward(self, x):\n","            out, _ = self.lstm(x)\n","            return self.fc(out[:, -1, :]) # 마지막 시점 출력만 선택해서 fc에 넣음 -> (batch * output_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6J9ebzOPnOM"},"outputs":[],"source":["class LSTMModel():\n","    def __init__(self, data = None, cols = None, enc_cols = None, num_cols = None, scaler = None,\n","                 lookback = 28, predict = 7, hidden_dim = 256, num_layers = 4, device = \"cuda\", epochs = 200, batch_size = 16, dropout = 0.4,\n","                 delta = 0.1, val_ratio = 0.2, horizon_weight_mode = \"linear\",\n","                 lr = 0.04, losses = None, loss_weights = [0.5, 0.5], menu_weights = None):\n","        self.data = data\n","        self.cols = cols\n","        self.enc_cols = enc_cols\n","        self.scaler = scaler\n","\n","        self.lookback = lookback\n","        self.predict = predict\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.device = torch.device(device)\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.dropout = dropout\n","\n","        self.delta = delta\n","        self.val_ratio = val_ratio\n","        self.horizon_weight_mode = horizon_weight_mode\n","        self.lr = float(lr)\n","        self.losses = losses\n","        self.loss_weights = loss_weights\n","        self.menu_weights = menu_weights\n","\n","    # enc_cols는 LabelEncoding\n","    def label_encoding_lstm(self, data, enc_cols):\n","        encoders = {}\n","        for col in enc_cols:\n","            if data[col].dtype == 'object' or data[col].dtype.name == 'bool' or data[col].dtype.name == 'category':\n","                le = LabelEncoder()\n","                data[col] = le.fit_transform(data[col])\n","                encoders[col] = le\n","        return data, encoders\n","\n","    def minmax_scaling_features(self, data, num_cols):\n","        scaler = MinMaxScaler()\n","        data[num_cols] = scaler.fit_transform(data[num_cols])\n","        return data, scaler\n","\n","    # 매출수량은 MinMaxScaling\n","    def minmax_scaling_target(self, data):\n","        scaler = MinMaxScaler()\n","        data['매출수량'] = scaler.fit_transform(data[['매출수량']])\n","        return data, scaler\n","\n","    def build_horizon_weights(self, predict = 7):\n","        \"\"\"\n","        수평선(예측일) 가중치 벡터 생성.\n","        - 'linear': 1..predict 선형 가중 후 정규화\n","        - 'uniform': 동일 가중\n","        \"\"\"\n","        if self.horizon_weight_mode == \"uniform\":\n","            w = torch.ones(predict)\n","        else:\n","            # 기본: 뒤쪽일수록 더 큰 가중\n","            w = torch.arange(1, predict + 1).float()\n","        w = w / w.sum()\n","        return w\n","\n","    def compute_smape(self, y_pred, y_true, eps=1e-8):\n","        \"\"\"정규화 스케일에서의 SMAPE( y_true==0 은 마스킹 )\"\"\"\n","        num = (y_pred - y_true).abs()\n","        den = (y_pred.abs() + y_true.abs()).clamp(min=eps)\n","        smape = 2.0 * num / den\n","        mask = (y_true != 0).float()\n","        denom = mask.sum().clamp(min=eps)\n","        return (smape * mask).sum().item() / denom.item()\n","\n","    def _tss_last_split_indices(self, n_samples: int, n_splits: int = 3):\n","        \"\"\"\n","        마지막 TimeSeriesSplit fold의 (train_idx, val_idx)만 반환.\n","        누수 방지를 위해 gap = lookback + predict - 1 권장.\n","        \"\"\"\n","        idx = np.arange(n_samples)\n","        tscv = TimeSeriesSplit(n_splits=n_splits, gap=self.lookback + self.predict - 1)\n","        tr_idx, va_idx = None, None\n","        for tr, va in tscv.split(idx):\n","            tr_idx, va_idx = tr, va\n","        return tr_idx, va_idx\n","\n","    def _make_windows(self, x: np.ndarray, y: np.ndarray):\n","        \"\"\"\n","        구간 내부에서만 윈도우 생성 (누수 없음)\n","        x: (T, F), y: (T,)\n","        return: x:(N, lookback, F), y:(N, predict) or (None, None)\n","        \"\"\"\n","        T = len(x)\n","        xs, ys = [], []\n","        for i in range(T - self.lookback - self.predict + 1):\n","            xs.append(x[i:i+self.lookback])\n","            ys.append(y[i+self.lookback:i+self.lookback+self.predict])\n","        if not xs:\n","            return None, None\n","        return np.stack(xs).astype(np.float32), np.stack(ys).astype(np.float32)\n","\n","#############################################################################\n","    def train_lstm(self, train_df, cols, enc_cols, num_cols,\n","                   device, epochs, batch_size, lr, dropout,\n","                   losses, loss_weights,\n","                   n_splits : int = 3, print_every = 50):\n","        \"\"\"\n","        영업장, 메뉴별로 LSTM 모델 훈련, 각각을 trained_models에 저장\n","        Loss - CombinationLoss([WeightedSMAPELoss(), WeightedHuberLoss()], [0.5, 0.5]\n","        \"\"\"\n","        trained_models = {}\n","        horizon_w = self.build_horizon_weights(self.predict).to(device)\n","\n","        # Loss 구성\n","        comb_loss = CombinationLoss(losses = losses, weights = loss_weights).to(device)\n","\n","        # store_menu : 영업장명_메뉴명 / group : 나머지 데이터\n","        for store_menu, group in tqdm(train_df.groupby([\"영업장명_메뉴명\"]), desc = \"Training LSTM\"):\n","\n","            # 날짜 순으로 정렬해서 데이터가 너무 적으면 -> 학습 생략\n","            store_train = group.sort_values(\"영업일자\").copy()\n","            if len(store_train) < self.lookback + self.predict:\n","                continue\n","\n","            # ===== TimeSeriesSplit: 마지막 폴드를 검증으로 사용 =====\n","            tr_idx, va_idx = self._tss_last_split_indices(len(store_train), n_splits=n_splits)\n","            df_tr = store_train.iloc[tr_idx].copy()\n","            df_va = store_train.iloc[va_idx].copy()\n","\n","            # ===== 인코더/스케일러는 train(df_tr)에만 fit, df_tr/df_va에 transform (누수 방지) =====\n","            encoders = {}\n","            if enc_cols:\n","                for c in enc_cols:\n","                    le = LabelEncoder()\n","                    df_tr[c] = le.fit_transform(df_tr[c].astype(str))\n","                    # val에서 미지 카테고리 안전 처리\n","                    cls2idx = {cls: i for i, cls in enumerate(le.classes_)}\n","                    df_va[c] = df_va[c].astype(str).map(lambda v: cls2idx.get(v, -1))\n","                    encoders[c] = le\n","\n","            features_scaler = None\n","            if num_cols:\n","                features_scaler = MinMaxScaler()\n","                df_tr[num_cols] = features_scaler.fit_transform(df_tr[num_cols])\n","                df_va[num_cols] = features_scaler.transform(df_va[num_cols])\n","\n","            target_scaler = MinMaxScaler()\n","            df_tr[['매출수량']] = target_scaler.fit_transform(df_tr[['매출수량']])\n","            df_va[['매출수량']] = target_scaler.transform(df_va[['매출수량']])\n","\n","            # ===== 원시 배열 =====\n","            X_tr = df_tr[cols].to_numpy(dtype=np.float32)\n","            y_tr = df_tr['매출수량'].to_numpy(dtype=np.float32)\n","            X_va = df_va[cols].to_numpy(dtype=np.float32)\n","            y_va = df_va['매출수량'].to_numpy(dtype=np.float32)\n","\n","            # ===== 세그먼트 내부에서만 윈도우 생성 (경계 누수 없음) =====\n","            x_tr_np, y_tr_np = self._make_windows(X_tr, y_tr)\n","            x_va_np, y_va_np = self._make_windows(X_va, y_va)\n","            if x_tr_np is None or x_va_np is None:\n","                continue\n","\n","            # 텐서 이동\n","            x_train = torch.tensor(x_tr_np).to(device)         # (N_tr, lookback, F)\n","            y_train = torch.tensor(y_tr_np).to(device)         # (N_tr, predict)\n","            x_val   = torch.tensor(x_va_np).to(device)\n","            y_val   = torch.tensor(y_va_np).to(device)\n","\n","            # 모델 초기화 (영업장_메뉴별로 다른 모델)\n","            model = MultiOutputLSTM(input_dim = len(cols),\n","                                    hidden_dim = self.hidden_dim,\n","                                    num_layers = self.num_layers,\n","                                    output_dim = self.predict,\n","                                    dropout = dropout).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n","            best_val = float(\"inf\")\n","            best_sd = None\n","            best_epoch = -1\n","\n","            # 학습 모드로 설정\n","            model.train()\n","\n","            # epochs 만큼 훈련\n","            for epoch in range(1, epochs + 1):\n","                model.train(True)\n","                perm = torch.randperm(len(x_train), device = device)\n","                epoch_train_loss = 0.0\n","                total_train_count = 0\n","\n","                # idx : 랜덤하게 섞인 index들\n","                for i in range(0, len(x_train), batch_size):\n","                    batch_idx = perm[i : i+batch_size] # 배치 개수만큼 끊어서\n","                    x_batch, y_batch = x_train[batch_idx], y_train[batch_idx] # 배치 데이터 할당\n","\n","                    weight_mat = horizon_w.unsqueeze(0).repeat(y_batch.size(0), 1)\n","\n","                    output = model(x_batch) # 모델 태워서\n","                    loss = comb_loss(output, y_batch, w = weight_mat) # 평가하고\n","\n","                    optimizer.zero_grad() # 역전파를 위한 초기화\n","                    loss.backward() # 역전파\n","                    optimizer.step() # 최적화\n","\n","                    epoch_train_loss += loss.item() * y_batch.size(0)\n","                    total_train_count += y_batch.size(0)\n","\n","                epoch_train_loss /= max(1, total_train_count)\n","\n","                ### Validation\n","                with torch.no_grad():\n","                    model.eval()\n","                    pred_val = model(x_val)\n","                    weight_val = horizon_w.unsqueeze(0).repeat(y_val.size(0), 1)\n","                    val_loss = comb_loss(pred_val, y_val, w = weight_val).item()\n","                    val_smape = self.compute_smape(pred_val, y_val)\n","\n","                    if epoch % 50 == 0:\n","                        print(f\"\\n[{store_menu}] Epoch {epoch} ==============================\\n \"\n","                            f\"Train Loss {epoch_train_loss:.5f} | Val Loss {val_loss:.5f} | SMAPE {val_smape:.5f}\")\n","\n","                    if val_loss < best_val - 1e-6:\n","                        best_val = val_loss\n","                        best_sd = {k : v.detach().cpu().clone() for k, v in model.state_dict().items()}\n","                        best_epoch = epoch\n","\n","                model.train(True)\n","\n","\n","            if best_sd is not None:\n","                model.load_state_dict(best_sd)\n","\n","            # 모델 저장\n","            trained_models[store_menu] = {\n","                'model': model.state_dict(),\n","                'encoders' : encoders,\n","                'features_scaler' : features_scaler,\n","                'target_scaler': target_scaler,\n","                'meta' : {\n","                    'input_dim': len(cols),\n","                    'hidden_dim': self.hidden_dim,\n","                    'num_layers': self.num_layers,\n","                    'output_dim': self.predict,\n","                    'dropout' : self.dropout\n","                }\n","                }\n","\n","        return trained_models\n","\n","    def save_lstm_model_gpu(self, models, model_path):\n","        joblib.dump(models, model_path)\n","        print(\"GPU 버전 모델 저장 완료!\")\n","\n","    def save_lstm_model_cpu(self, models, model_path):\n","        cpu_models = {}\n","        for k, bundle in models.items():\n","            cpu_models[k] = {\n","            'model': {kk: vv.cpu() for kk, vv in bundle['model'].items()},  # 모델만 CPU로\n","            'encoders': bundle['encoders'],\n","            'features_scaler': bundle['features_scaler'],\n","            'target_scaler': bundle['target_scaler'],\n","            'meta' : bundle['meta']\n","        }\n","        joblib.dump(cpu_models, model_path)\n","        print(\"CPU 버전 모델 저장 완료!\")\n","\n","    def load_saved_model(self, model_path):\n","        models = joblib.load(model_path)\n","        return models"]},{"cell_type":"markdown","source":["##### Train"],"metadata":{"id":"uup-wSWOBYEA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20ZWwzy0UpQP","collapsed":true,"outputId":"c03b29a5-2539-4129-9856-30c5fde6a37c","executionInfo":{"status":"ok","timestamp":1755284773097,"user_tz":-540,"elapsed":5908764,"user":{"displayName":"박준희","userId":"01167826914931997240"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   0%|          | 0/193 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 50 ==============================\n"," Train Loss 0.19378 | Val Loss 0.35608 | SMAPE 0.69510\n","\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 100 ==============================\n"," Train Loss 0.11939 | Val Loss 0.38836 | SMAPE 0.76970\n","\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 150 ==============================\n"," Train Loss 0.06899 | Val Loss 0.36547 | SMAPE 0.71617\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   1%|          | 1/193 [00:30<1:37:30, 30.47s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_1인 수저세트',)] Epoch 200 ==============================\n"," Train Loss 0.05668 | Val Loss 0.37487 | SMAPE 0.73919\n","\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 50 ==============================\n"," Train Loss 0.16931 | Val Loss 0.25688 | SMAPE 0.50057\n","\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 100 ==============================\n"," Train Loss 0.08782 | Val Loss 0.30959 | SMAPE 0.60090\n","\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 150 ==============================\n"," Train Loss 0.05500 | Val Loss 0.30546 | SMAPE 0.57905\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   1%|          | 2/193 [01:01<1:37:53, 30.75s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_BBQ55(단체)',)] Epoch 200 ==============================\n"," Train Loss 0.04625 | Val Loss 0.30656 | SMAPE 0.57732\n","\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 50 ==============================\n"," Train Loss 0.14000 | Val Loss 0.29658 | SMAPE 0.55576\n","\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 100 ==============================\n"," Train Loss 0.08839 | Val Loss 0.28078 | SMAPE 0.52691\n","\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 150 ==============================\n"," Train Loss 0.05698 | Val Loss 0.30597 | SMAPE 0.58033\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   2%|▏         | 3/193 [01:32<1:37:11, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_대여료 30,000원',)] Epoch 200 ==============================\n"," Train Loss 0.04354 | Val Loss 0.29056 | SMAPE 0.55212\n","\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 50 ==============================\n"," Train Loss 0.15817 | Val Loss 0.31351 | SMAPE 0.59343\n","\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 100 ==============================\n"," Train Loss 0.10085 | Val Loss 0.31129 | SMAPE 0.59664\n","\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 150 ==============================\n"," Train Loss 0.06275 | Val Loss 0.29352 | SMAPE 0.55970\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   2%|▏         | 4/193 [02:02<1:36:36, 30.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_대여료 60,000원',)] Epoch 200 ==============================\n"," Train Loss 0.04496 | Val Loss 0.29233 | SMAPE 0.56067\n","\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 50 ==============================\n"," Train Loss 0.08894 | Val Loss 0.19096 | SMAPE 0.34406\n","\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 100 ==============================\n"," Train Loss 0.04964 | Val Loss 0.19422 | SMAPE 0.35276\n","\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 150 ==============================\n"," Train Loss 0.02463 | Val Loss 0.20582 | SMAPE 0.37758\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   3%|▎         | 5/193 [02:33<1:36:00, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_대여료 90,000원',)] Epoch 200 ==============================\n"," Train Loss 0.02062 | Val Loss 0.19215 | SMAPE 0.35747\n","\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 50 ==============================\n"," Train Loss 0.09368 | Val Loss 0.34108 | SMAPE 0.66439\n","\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 100 ==============================\n"," Train Loss 0.07527 | Val Loss 0.35432 | SMAPE 0.69352\n","\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 150 ==============================\n"," Train Loss 0.05042 | Val Loss 0.33653 | SMAPE 0.66435\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   3%|▎         | 6/193 [03:03<1:35:28, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_본삼겹 (단품,실내)',)] Epoch 200 ==============================\n"," Train Loss 0.03978 | Val Loss 0.33654 | SMAPE 0.66708\n","\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 50 ==============================\n"," Train Loss 0.21939 | Val Loss 0.38415 | SMAPE 0.74878\n","\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 100 ==============================\n"," Train Loss 0.18515 | Val Loss 0.40693 | SMAPE 0.80812\n","\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 150 ==============================\n"," Train Loss 0.11133 | Val Loss 0.38122 | SMAPE 0.75515\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   4%|▎         | 7/193 [03:34<1:34:51, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_스프라이트 (단체)',)] Epoch 200 ==============================\n"," Train Loss 0.08846 | Val Loss 0.36133 | SMAPE 0.71935\n","\n","[('느티나무 셀프BBQ_신라면',)] Epoch 50 ==============================\n"," Train Loss 0.20334 | Val Loss 0.38367 | SMAPE 0.74391\n","\n","[('느티나무 셀프BBQ_신라면',)] Epoch 100 ==============================\n"," Train Loss 0.16483 | Val Loss 0.39288 | SMAPE 0.76428\n","\n","[('느티나무 셀프BBQ_신라면',)] Epoch 150 ==============================\n"," Train Loss 0.10249 | Val Loss 0.40794 | SMAPE 0.78991\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   4%|▍         | 8/193 [04:04<1:34:17, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_신라면',)] Epoch 200 ==============================\n"," Train Loss 0.07038 | Val Loss 0.40072 | SMAPE 0.78767\n","\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 50 ==============================\n"," Train Loss 0.17880 | Val Loss 0.40192 | SMAPE 0.74611\n","\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 100 ==============================\n"," Train Loss 0.08769 | Val Loss 0.39148 | SMAPE 0.72826\n","\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 150 ==============================\n"," Train Loss 0.05497 | Val Loss 0.39252 | SMAPE 0.72839\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   5%|▍         | 9/193 [04:35<1:33:53, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_쌈야채세트',)] Epoch 200 ==============================\n"," Train Loss 0.04296 | Val Loss 0.38984 | SMAPE 0.72685\n","\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 50 ==============================\n"," Train Loss 0.09109 | Val Loss 0.19380 | SMAPE 0.36554\n","\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 100 ==============================\n"," Train Loss 0.05859 | Val Loss 0.23296 | SMAPE 0.42720\n","\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 150 ==============================\n"," Train Loss 0.04768 | Val Loss 0.26294 | SMAPE 0.50071\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   5%|▌         | 10/193 [05:06<1:33:28, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_쌈장',)] Epoch 200 ==============================\n"," Train Loss 0.02808 | Val Loss 0.29632 | SMAPE 0.55007\n","\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 50 ==============================\n"," Train Loss 0.17621 | Val Loss 0.35656 | SMAPE 0.71410\n","\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 100 ==============================\n"," Train Loss 0.09984 | Val Loss 0.35060 | SMAPE 0.70941\n","\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 150 ==============================\n"," Train Loss 0.05887 | Val Loss 0.34554 | SMAPE 0.68190\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   6%|▌         | 11/193 [05:37<1:33:06, 30.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_육개장 사발면',)] Epoch 200 ==============================\n"," Train Loss 0.04727 | Val Loss 0.36289 | SMAPE 0.71580\n","\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 50 ==============================\n"," Train Loss 0.10733 | Val Loss 0.17982 | SMAPE 0.33697\n","\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 100 ==============================\n"," Train Loss 0.05753 | Val Loss 0.19108 | SMAPE 0.36050\n","\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 150 ==============================\n"," Train Loss 0.03093 | Val Loss 0.17242 | SMAPE 0.32261\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   6%|▌         | 12/193 [06:07<1:32:26, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_일회용 소주컵',)] Epoch 200 ==============================\n"," Train Loss 0.02227 | Val Loss 0.18092 | SMAPE 0.34775\n","\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 50 ==============================\n"," Train Loss 0.13630 | Val Loss 0.23708 | SMAPE 0.44128\n","\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 100 ==============================\n"," Train Loss 0.05419 | Val Loss 0.27489 | SMAPE 0.51564\n","\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 150 ==============================\n"," Train Loss 0.03259 | Val Loss 0.25214 | SMAPE 0.48057\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   7%|▋         | 13/193 [06:38<1:31:54, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_일회용 종이컵',)] Epoch 200 ==============================\n"," Train Loss 0.02504 | Val Loss 0.27224 | SMAPE 0.52108\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 50 ==============================\n"," Train Loss 0.20719 | Val Loss 0.25083 | SMAPE 0.50697\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 100 ==============================\n"," Train Loss 0.13748 | Val Loss 0.24244 | SMAPE 0.47635\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 150 ==============================\n"," Train Loss 0.07708 | Val Loss 0.24562 | SMAPE 0.49602\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   7%|▋         | 14/193 [07:08<1:31:17, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (12인석)',)] Epoch 200 ==============================\n"," Train Loss 0.05833 | Val Loss 0.23672 | SMAPE 0.46913\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 50 ==============================\n"," Train Loss 0.18229 | Val Loss 0.30502 | SMAPE 0.59055\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 100 ==============================\n"," Train Loss 0.15161 | Val Loss 0.29520 | SMAPE 0.58045\n","\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 150 ==============================\n"," Train Loss 0.10584 | Val Loss 0.29679 | SMAPE 0.58178\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   8%|▊         | 15/193 [07:39<1:30:46, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_잔디그늘집 대여료 (6인석)',)] Epoch 200 ==============================\n"," Train Loss 0.07406 | Val Loss 0.29606 | SMAPE 0.57168\n","\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 50 ==============================\n"," Train Loss 0.15073 | Val Loss 0.30411 | SMAPE 0.60369\n","\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 100 ==============================\n"," Train Loss 0.11406 | Val Loss 0.31823 | SMAPE 0.61786\n","\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 150 ==============================\n"," Train Loss 0.06935 | Val Loss 0.30688 | SMAPE 0.59493\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   8%|▊         | 16/193 [08:09<1:30:09, 30.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_잔디그늘집 의자 추가',)] Epoch 200 ==============================\n"," Train Loss 0.05040 | Val Loss 0.33591 | SMAPE 0.65682\n","\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 50 ==============================\n"," Train Loss 0.31039 | Val Loss 0.36239 | SMAPE 0.73066\n","\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 100 ==============================\n"," Train Loss 0.22434 | Val Loss 0.37897 | SMAPE 0.76015\n","\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 150 ==============================\n"," Train Loss 0.16283 | Val Loss 0.37563 | SMAPE 0.74460\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   9%|▉         | 17/193 [08:40<1:29:40, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_참이슬 (단체)',)] Epoch 200 ==============================\n"," Train Loss 0.11831 | Val Loss 0.38560 | SMAPE 0.76377\n","\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 50 ==============================\n"," Train Loss 0.09920 | Val Loss 0.22145 | SMAPE 0.42035\n","\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 100 ==============================\n"," Train Loss 0.06110 | Val Loss 0.22009 | SMAPE 0.42557\n","\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 150 ==============================\n"," Train Loss 0.03776 | Val Loss 0.21375 | SMAPE 0.41923\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:   9%|▉         | 18/193 [09:11<1:29:11, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_친환경 접시 14cm',)] Epoch 200 ==============================\n"," Train Loss 0.02727 | Val Loss 0.22189 | SMAPE 0.43050\n","\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 50 ==============================\n"," Train Loss 0.13162 | Val Loss 0.23176 | SMAPE 0.44657\n","\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 100 ==============================\n"," Train Loss 0.08792 | Val Loss 0.23069 | SMAPE 0.44690\n","\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 150 ==============================\n"," Train Loss 0.04821 | Val Loss 0.23530 | SMAPE 0.45857\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  10%|▉         | 19/193 [09:41<1:28:40, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_친환경 접시 23cm',)] Epoch 200 ==============================\n"," Train Loss 0.03897 | Val Loss 0.23587 | SMAPE 0.46367\n","\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 50 ==============================\n"," Train Loss 0.22678 | Val Loss 0.37219 | SMAPE 0.74185\n","\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 100 ==============================\n"," Train Loss 0.15293 | Val Loss 0.35881 | SMAPE 0.71003\n","\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 150 ==============================\n"," Train Loss 0.09998 | Val Loss 0.33128 | SMAPE 0.65409\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  10%|█         | 20/193 [10:12<1:28:19, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_카스 병(단체)',)] Epoch 200 ==============================\n"," Train Loss 0.08016 | Val Loss 0.32859 | SMAPE 0.64825\n","\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 50 ==============================\n"," Train Loss 0.21598 | Val Loss 0.40427 | SMAPE 0.79705\n","\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 100 ==============================\n"," Train Loss 0.13811 | Val Loss 0.41181 | SMAPE 0.81817\n","\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 150 ==============================\n"," Train Loss 0.09384 | Val Loss 0.43894 | SMAPE 0.87082\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  11%|█         | 21/193 [10:42<1:27:36, 30.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_콜라 (단체)',)] Epoch 200 ==============================\n"," Train Loss 0.08950 | Val Loss 0.42721 | SMAPE 0.84087\n","\n","[('느티나무 셀프BBQ_햇반',)] Epoch 50 ==============================\n"," Train Loss 0.19797 | Val Loss 0.25636 | SMAPE 0.50012\n","\n","[('느티나무 셀프BBQ_햇반',)] Epoch 100 ==============================\n"," Train Loss 0.14326 | Val Loss 0.29646 | SMAPE 0.57440\n","\n","[('느티나무 셀프BBQ_햇반',)] Epoch 150 ==============================\n"," Train Loss 0.07575 | Val Loss 0.29122 | SMAPE 0.56192\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  11%|█▏        | 22/193 [11:13<1:26:59, 30.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_햇반',)] Epoch 200 ==============================\n"," Train Loss 0.05341 | Val Loss 0.28562 | SMAPE 0.54864\n","\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 50 ==============================\n"," Train Loss 0.10042 | Val Loss 0.20142 | SMAPE 0.38651\n","\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 100 ==============================\n"," Train Loss 0.04875 | Val Loss 0.20114 | SMAPE 0.37479\n","\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 150 ==============================\n"," Train Loss 0.03211 | Val Loss 0.22059 | SMAPE 0.40982\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  12%|█▏        | 23/193 [11:43<1:26:33, 30.55s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('느티나무 셀프BBQ_허브솔트',)] Epoch 200 ==============================\n"," Train Loss 0.02424 | Val Loss 0.18982 | SMAPE 0.35511\n","\n","[('담하_(단체) 공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.18613 | Val Loss 0.29672 | SMAPE 0.57962\n","\n","[('담하_(단체) 공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.14095 | Val Loss 0.30364 | SMAPE 0.57054\n","\n","[('담하_(단체) 공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.10010 | Val Loss 0.30711 | SMAPE 0.61636\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  12%|█▏        | 24/193 [12:14<1:26:10, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.09084 | Val Loss 0.32556 | SMAPE 0.65008\n","\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 50 ==============================\n"," Train Loss 0.07967 | Val Loss 0.41700 | SMAPE 0.80820\n","\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 100 ==============================\n"," Train Loss 0.06107 | Val Loss 0.35179 | SMAPE 0.66269\n","\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 150 ==============================\n"," Train Loss 0.06033 | Val Loss 0.44391 | SMAPE 0.84744\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  13%|█▎        | 25/193 [12:45<1:25:38, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 생목살 김치전골 2.0',)] Epoch 200 ==============================\n"," Train Loss 0.04099 | Val Loss 0.33806 | SMAPE 0.63431\n","\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 50 ==============================\n"," Train Loss 0.16791 | Val Loss 0.47808 | SMAPE 0.96176\n","\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 100 ==============================\n"," Train Loss 0.11961 | Val Loss 0.41010 | SMAPE 0.77935\n","\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 150 ==============================\n"," Train Loss 0.09179 | Val Loss 0.41865 | SMAPE 0.82625\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  13%|█▎        | 26/193 [13:15<1:25:08, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 은이버섯 갈비탕',)] Epoch 200 ==============================\n"," Train Loss 0.06520 | Val Loss 0.69908 | SMAPE 1.38524\n","\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 50 ==============================\n"," Train Loss 0.24287 | Val Loss 0.32277 | SMAPE 0.61477\n","\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 100 ==============================\n"," Train Loss 0.20161 | Val Loss 0.36368 | SMAPE 0.70994\n","\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 150 ==============================\n"," Train Loss 0.15431 | Val Loss 0.39231 | SMAPE 0.76662\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  14%|█▍        | 27/193 [13:46<1:24:32, 30.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 한우 우거지 국밥',)] Epoch 200 ==============================\n"," Train Loss 0.12058 | Val Loss 0.40427 | SMAPE 0.79370\n","\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 50 ==============================\n"," Train Loss 0.17914 | Val Loss 0.33492 | SMAPE 0.62935\n","\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 100 ==============================\n"," Train Loss 0.08165 | Val Loss 0.36297 | SMAPE 0.69539\n","\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 150 ==============================\n"," Train Loss 0.06338 | Val Loss 0.33938 | SMAPE 0.65828\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  15%|█▍        | 28/193 [14:16<1:24:03, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(단체) 황태해장국 3/27까지',)] Epoch 200 ==============================\n"," Train Loss 0.04765 | Val Loss 0.35482 | SMAPE 0.68571\n","\n","[('담하_(정식) 된장찌개',)] Epoch 50 ==============================\n"," Train Loss 0.19029 | Val Loss 0.38802 | SMAPE 0.76642\n","\n","[('담하_(정식) 된장찌개',)] Epoch 100 ==============================\n"," Train Loss 0.14483 | Val Loss 0.40998 | SMAPE 0.80797\n","\n","[('담하_(정식) 된장찌개',)] Epoch 150 ==============================\n"," Train Loss 0.09677 | Val Loss 0.38642 | SMAPE 0.76061\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  15%|█▌        | 29/193 [14:47<1:23:39, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(정식) 된장찌개',)] Epoch 200 ==============================\n"," Train Loss 0.06756 | Val Loss 0.54166 | SMAPE 1.07872\n","\n","[('담하_(정식) 물냉면 ',)] Epoch 50 ==============================\n"," Train Loss 0.19097 | Val Loss 0.47015 | SMAPE 0.88181\n","\n","[('담하_(정식) 물냉면 ',)] Epoch 100 ==============================\n"," Train Loss 0.11949 | Val Loss 0.40669 | SMAPE 0.78528\n","\n","[('담하_(정식) 물냉면 ',)] Epoch 150 ==============================\n"," Train Loss 0.06846 | Val Loss 0.63918 | SMAPE 1.26055\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  16%|█▌        | 30/193 [15:17<1:23:00, 30.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(정식) 물냉면 ',)] Epoch 200 ==============================\n"," Train Loss 0.04714 | Val Loss 0.57725 | SMAPE 1.14382\n","\n","[('담하_(정식) 비빔냉면',)] Epoch 50 ==============================\n"," Train Loss 0.20865 | Val Loss 0.36731 | SMAPE 0.71456\n","\n","[('담하_(정식) 비빔냉면',)] Epoch 100 ==============================\n"," Train Loss 0.15510 | Val Loss 0.39790 | SMAPE 0.77598\n","\n","[('담하_(정식) 비빔냉면',)] Epoch 150 ==============================\n"," Train Loss 0.08151 | Val Loss 0.35608 | SMAPE 0.68827\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  16%|█▌        | 31/193 [15:48<1:22:36, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(정식) 비빔냉면',)] Epoch 200 ==============================\n"," Train Loss 0.05224 | Val Loss 0.40489 | SMAPE 0.77749\n","\n","[('담하_(후식) 된장찌개',)] Epoch 50 ==============================\n"," Train Loss 0.16137 | Val Loss 0.33926 | SMAPE 0.64584\n","\n","[('담하_(후식) 된장찌개',)] Epoch 100 ==============================\n"," Train Loss 0.10258 | Val Loss 0.37304 | SMAPE 0.71840\n","\n","[('담하_(후식) 된장찌개',)] Epoch 150 ==============================\n"," Train Loss 0.05788 | Val Loss 0.32849 | SMAPE 0.62827\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  17%|█▋        | 32/193 [16:19<1:22:03, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(후식) 된장찌개',)] Epoch 200 ==============================\n"," Train Loss 0.04303 | Val Loss 0.32622 | SMAPE 0.62567\n","\n","[('담하_(후식) 물냉면',)] Epoch 50 ==============================\n"," Train Loss 0.20138 | Val Loss 0.36496 | SMAPE 0.64724\n","\n","[('담하_(후식) 물냉면',)] Epoch 100 ==============================\n"," Train Loss 0.12727 | Val Loss 0.48078 | SMAPE 0.89928\n","\n","[('담하_(후식) 물냉면',)] Epoch 150 ==============================\n"," Train Loss 0.06800 | Val Loss 0.69446 | SMAPE 1.32736\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  17%|█▋        | 33/193 [16:49<1:21:35, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(후식) 물냉면',)] Epoch 200 ==============================\n"," Train Loss 0.04363 | Val Loss 0.60939 | SMAPE 1.17062\n","\n","[('담하_(후식) 비빔냉면',)] Epoch 50 ==============================\n"," Train Loss 0.16467 | Val Loss 0.54617 | SMAPE 1.00005\n","\n","[('담하_(후식) 비빔냉면',)] Epoch 100 ==============================\n"," Train Loss 0.09655 | Val Loss 0.51188 | SMAPE 0.99524\n","\n","[('담하_(후식) 비빔냉면',)] Epoch 150 ==============================\n"," Train Loss 0.04877 | Val Loss 0.51525 | SMAPE 0.95688\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  18%|█▊        | 34/193 [17:20<1:21:10, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_(후식) 비빔냉면',)] Epoch 200 ==============================\n"," Train Loss 0.03616 | Val Loss 0.65280 | SMAPE 1.27457\n","\n","[('담하_갑오징어 비빔밥',)] Epoch 50 ==============================\n"," Train Loss 0.19464 | Val Loss 0.54463 | SMAPE 1.07548\n","\n","[('담하_갑오징어 비빔밥',)] Epoch 100 ==============================\n"," Train Loss 0.17272 | Val Loss 0.53025 | SMAPE 1.04130\n","\n","[('담하_갑오징어 비빔밥',)] Epoch 150 ==============================\n"," Train Loss 0.13542 | Val Loss 0.56542 | SMAPE 1.11931\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  18%|█▊        | 35/193 [17:51<1:20:36, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_갑오징어 비빔밥',)] Epoch 200 ==============================\n"," Train Loss 0.07559 | Val Loss 0.60675 | SMAPE 1.20262\n","\n","[('담하_갱시기',)] Epoch 50 ==============================\n"," Train Loss 0.13761 | Val Loss 0.62609 | SMAPE 1.14508\n","\n","[('담하_갱시기',)] Epoch 100 ==============================\n"," Train Loss 0.10385 | Val Loss 0.62283 | SMAPE 1.17183\n","\n","[('담하_갱시기',)] Epoch 150 ==============================\n"," Train Loss 0.06179 | Val Loss 0.60874 | SMAPE 1.14192\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  19%|█▊        | 36/193 [18:21<1:20:05, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_갱시기',)] Epoch 200 ==============================\n"," Train Loss 0.05539 | Val Loss 0.58223 | SMAPE 1.09071\n","\n","[('담하_공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.15645 | Val Loss 0.27786 | SMAPE 0.55260\n","\n","[('담하_공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.11366 | Val Loss 0.26937 | SMAPE 0.54214\n","\n","[('담하_공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.08833 | Val Loss 0.27725 | SMAPE 0.54497\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  19%|█▉        | 37/193 [18:52<1:19:36, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.06671 | Val Loss 0.27891 | SMAPE 0.54602\n","\n","[('담하_꼬막 비빔밥',)] Epoch 50 ==============================\n"," Train Loss 0.16991 | Val Loss 0.21757 | SMAPE 0.43617\n","\n","[('담하_꼬막 비빔밥',)] Epoch 100 ==============================\n"," Train Loss 0.13886 | Val Loss 0.92504 | SMAPE 1.86703\n","\n","[('담하_꼬막 비빔밥',)] Epoch 150 ==============================\n"," Train Loss 0.09678 | Val Loss 0.34255 | SMAPE 0.66208\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  20%|█▉        | 38/193 [19:22<1:18:58, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_꼬막 비빔밥',)] Epoch 200 ==============================\n"," Train Loss 0.05654 | Val Loss 0.29924 | SMAPE 0.59978\n","\n","[('담하_느린마을 막걸리',)] Epoch 50 ==============================\n"," Train Loss 0.12432 | Val Loss 0.33288 | SMAPE 0.64005\n","\n","[('담하_느린마을 막걸리',)] Epoch 100 ==============================\n"," Train Loss 0.06966 | Val Loss 0.33220 | SMAPE 0.63978\n","\n","[('담하_느린마을 막걸리',)] Epoch 150 ==============================\n"," Train Loss 0.04405 | Val Loss 0.32685 | SMAPE 0.62696\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  20%|██        | 39/193 [19:53<1:18:31, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_느린마을 막걸리',)] Epoch 200 ==============================\n"," Train Loss 0.03107 | Val Loss 0.30777 | SMAPE 0.59444\n","\n","[('담하_담하 한우 불고기',)] Epoch 50 ==============================\n"," Train Loss 0.17570 | Val Loss 0.29518 | SMAPE 0.56958\n","\n","[('담하_담하 한우 불고기',)] Epoch 100 ==============================\n"," Train Loss 0.12415 | Val Loss 0.29805 | SMAPE 0.57418\n","\n","[('담하_담하 한우 불고기',)] Epoch 150 ==============================\n"," Train Loss 0.08600 | Val Loss 0.31773 | SMAPE 0.61943\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  21%|██        | 40/193 [20:24<1:18:01, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_담하 한우 불고기',)] Epoch 200 ==============================\n"," Train Loss 0.06494 | Val Loss 0.32135 | SMAPE 0.62036\n","\n","[('담하_담하 한우 불고기 정식',)] Epoch 50 ==============================\n"," Train Loss 0.33052 | Val Loss 0.37979 | SMAPE 0.74490\n","\n","[('담하_담하 한우 불고기 정식',)] Epoch 100 ==============================\n"," Train Loss 0.29487 | Val Loss 0.42859 | SMAPE 0.83669\n","\n","[('담하_담하 한우 불고기 정식',)] Epoch 150 ==============================\n"," Train Loss 0.25310 | Val Loss 0.40560 | SMAPE 0.79561\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  21%|██        | 41/193 [20:54<1:17:29, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_담하 한우 불고기 정식',)] Epoch 200 ==============================\n"," Train Loss 0.22994 | Val Loss 0.39944 | SMAPE 0.75973\n","\n","[('담하_더덕 한우 지짐',)] Epoch 50 ==============================\n"," Train Loss 0.17477 | Val Loss 0.78368 | SMAPE 1.57004\n","\n","[('담하_더덕 한우 지짐',)] Epoch 100 ==============================\n"," Train Loss 0.10916 | Val Loss 0.61878 | SMAPE 1.25673\n","\n","[('담하_더덕 한우 지짐',)] Epoch 150 ==============================\n"," Train Loss 0.06638 | Val Loss 0.78487 | SMAPE 1.56428\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  22%|██▏       | 42/193 [21:25<1:16:59, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_더덕 한우 지짐',)] Epoch 200 ==============================\n"," Train Loss 0.04803 | Val Loss 0.93085 | SMAPE 1.80624\n","\n","[('담하_들깨 양지탕',)] Epoch 50 ==============================\n"," Train Loss 0.19425 | Val Loss 0.30246 | SMAPE 0.58937\n","\n","[('담하_들깨 양지탕',)] Epoch 100 ==============================\n"," Train Loss 0.14583 | Val Loss 0.31852 | SMAPE 0.61260\n","\n","[('담하_들깨 양지탕',)] Epoch 150 ==============================\n"," Train Loss 0.06228 | Val Loss 0.27226 | SMAPE 0.52624\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  22%|██▏       | 43/193 [21:55<1:16:36, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_들깨 양지탕',)] Epoch 200 ==============================\n"," Train Loss 0.04968 | Val Loss 0.26762 | SMAPE 0.51405\n","\n","[('담하_라면사리',)] Epoch 50 ==============================\n"," Train Loss 0.18909 | Val Loss 0.34198 | SMAPE 0.66538\n","\n","[('담하_라면사리',)] Epoch 100 ==============================\n"," Train Loss 0.12050 | Val Loss 0.35124 | SMAPE 0.69283\n","\n","[('담하_라면사리',)] Epoch 150 ==============================\n"," Train Loss 0.09865 | Val Loss 0.34300 | SMAPE 0.67158\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  23%|██▎       | 44/193 [22:26<1:15:58, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_라면사리',)] Epoch 200 ==============================\n"," Train Loss 0.06411 | Val Loss 0.36173 | SMAPE 0.71164\n","\n","[('담하_룸 이용료',)] Epoch 50 ==============================\n"," Train Loss 0.12241 | Val Loss 0.22369 | SMAPE 0.43247\n","\n","[('담하_룸 이용료',)] Epoch 100 ==============================\n"," Train Loss 0.06616 | Val Loss 0.19781 | SMAPE 0.37965\n","\n","[('담하_룸 이용료',)] Epoch 150 ==============================\n"," Train Loss 0.04266 | Val Loss 0.18496 | SMAPE 0.35912\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  23%|██▎       | 45/193 [22:57<1:15:28, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_룸 이용료',)] Epoch 200 ==============================\n"," Train Loss 0.03203 | Val Loss 0.16579 | SMAPE 0.33136\n","\n","[('담하_메밀면 사리',)] Epoch 50 ==============================\n"," Train Loss 0.16449 | Val Loss 0.41155 | SMAPE 0.79028\n","\n","[('담하_메밀면 사리',)] Epoch 100 ==============================\n"," Train Loss 0.09419 | Val Loss 0.39494 | SMAPE 0.77683\n","\n","[('담하_메밀면 사리',)] Epoch 150 ==============================\n"," Train Loss 0.05853 | Val Loss 0.39391 | SMAPE 0.77400\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  24%|██▍       | 46/193 [23:27<1:14:58, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_메밀면 사리',)] Epoch 200 ==============================\n"," Train Loss 0.04602 | Val Loss 0.39128 | SMAPE 0.76213\n","\n","[('담하_명인안동소주',)] Epoch 50 ==============================\n"," Train Loss 0.12261 | Val Loss 0.09010 | SMAPE 0.15299\n","\n","[('담하_명인안동소주',)] Epoch 100 ==============================\n"," Train Loss 0.12136 | Val Loss 0.08974 | SMAPE 0.15281\n","\n","[('담하_명인안동소주',)] Epoch 150 ==============================\n"," Train Loss 0.12100 | Val Loss 0.09196 | SMAPE 0.15341\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  24%|██▍       | 47/193 [23:58<1:14:29, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_명인안동소주',)] Epoch 200 ==============================\n"," Train Loss 0.12171 | Val Loss 0.09171 | SMAPE 0.15416\n","\n","[('담하_명태회 비빔냉면',)] Epoch 50 ==============================\n"," Train Loss 0.20822 | Val Loss 0.44004 | SMAPE 0.83759\n","\n","[('담하_명태회 비빔냉면',)] Epoch 100 ==============================\n"," Train Loss 0.14581 | Val Loss 0.35611 | SMAPE 0.68371\n","\n","[('담하_명태회 비빔냉면',)] Epoch 150 ==============================\n"," Train Loss 0.07183 | Val Loss 0.45315 | SMAPE 0.89937\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  25%|██▍       | 48/193 [24:28<1:13:52, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_명태회 비빔냉면',)] Epoch 200 ==============================\n"," Train Loss 0.04964 | Val Loss 0.51194 | SMAPE 1.02376\n","\n","[('담하_문막 복분자 칵테일',)] Epoch 50 ==============================\n"," Train Loss 0.11381 | Val Loss 0.20753 | SMAPE 0.40917\n","\n","[('담하_문막 복분자 칵테일',)] Epoch 100 ==============================\n"," Train Loss 0.08897 | Val Loss 0.62132 | SMAPE 1.16489\n","\n","[('담하_문막 복분자 칵테일',)] Epoch 150 ==============================\n"," Train Loss 0.04943 | Val Loss 0.59494 | SMAPE 1.08906\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  25%|██▌       | 49/193 [24:59<1:13:14, 30.52s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_문막 복분자 칵테일',)] Epoch 200 ==============================\n"," Train Loss 0.03348 | Val Loss 0.78855 | SMAPE 1.52335\n","\n","[('담하_봉평메밀 물냉면',)] Epoch 50 ==============================\n"," Train Loss 0.19805 | Val Loss 0.36183 | SMAPE 0.70849\n","\n","[('담하_봉평메밀 물냉면',)] Epoch 100 ==============================\n"," Train Loss 0.13080 | Val Loss 0.35575 | SMAPE 0.70983\n","\n","[('담하_봉평메밀 물냉면',)] Epoch 150 ==============================\n"," Train Loss 0.08333 | Val Loss 0.36610 | SMAPE 0.71962\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  26%|██▌       | 50/193 [25:29<1:12:41, 30.50s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_봉평메밀 물냉면',)] Epoch 200 ==============================\n"," Train Loss 0.06361 | Val Loss 0.37699 | SMAPE 0.75037\n","\n","[('담하_생목살 김치찌개',)] Epoch 50 ==============================\n"," Train Loss 0.15345 | Val Loss 0.30445 | SMAPE 0.59908\n","\n","[('담하_생목살 김치찌개',)] Epoch 100 ==============================\n"," Train Loss 0.09419 | Val Loss 0.31187 | SMAPE 0.61156\n","\n","[('담하_생목살 김치찌개',)] Epoch 150 ==============================\n"," Train Loss 0.05283 | Val Loss 0.30938 | SMAPE 0.60386\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  26%|██▋       | 51/193 [26:00<1:12:13, 30.51s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_생목살 김치찌개',)] Epoch 200 ==============================\n"," Train Loss 0.04433 | Val Loss 0.30754 | SMAPE 0.59712\n","\n","[('담하_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.14583 | Val Loss 0.19195 | SMAPE 0.39022\n","\n","[('담하_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.09454 | Val Loss 0.17993 | SMAPE 0.35755\n","\n","[('담하_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.06602 | Val Loss 0.18730 | SMAPE 0.37040\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  27%|██▋       | 52/193 [26:30<1:11:39, 30.49s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.06289 | Val Loss 0.18676 | SMAPE 0.37530\n","\n","[('담하_은이버섯 갈비탕',)] Epoch 50 ==============================\n"," Train Loss 0.21530 | Val Loss 0.40036 | SMAPE 0.77093\n","\n","[('담하_은이버섯 갈비탕',)] Epoch 100 ==============================\n"," Train Loss 0.13196 | Val Loss 0.39424 | SMAPE 0.75915\n","\n","[('담하_은이버섯 갈비탕',)] Epoch 150 ==============================\n"," Train Loss 0.06568 | Val Loss 0.40368 | SMAPE 0.77884\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  27%|██▋       | 53/193 [27:01<1:11:04, 30.46s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_은이버섯 갈비탕',)] Epoch 200 ==============================\n"," Train Loss 0.05199 | Val Loss 0.40592 | SMAPE 0.79011\n","\n","[('담하_제로콜라',)] Epoch 50 ==============================\n"," Train Loss 0.13981 | Val Loss 0.18740 | SMAPE 0.35662\n","\n","[('담하_제로콜라',)] Epoch 100 ==============================\n"," Train Loss 0.09066 | Val Loss 0.20731 | SMAPE 0.39462\n","\n","[('담하_제로콜라',)] Epoch 150 ==============================\n"," Train Loss 0.05013 | Val Loss 0.21679 | SMAPE 0.41009\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  28%|██▊       | 54/193 [27:31<1:10:36, 30.48s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_제로콜라',)] Epoch 200 ==============================\n"," Train Loss 0.03345 | Val Loss 0.20411 | SMAPE 0.38178\n","\n","[('담하_참이슬',)] Epoch 50 ==============================\n"," Train Loss 0.18062 | Val Loss 0.31060 | SMAPE 0.61260\n","\n","[('담하_참이슬',)] Epoch 100 ==============================\n"," Train Loss 0.10898 | Val Loss 0.32489 | SMAPE 0.63548\n","\n","[('담하_참이슬',)] Epoch 150 ==============================\n"," Train Loss 0.06282 | Val Loss 0.35548 | SMAPE 0.68829\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  28%|██▊       | 55/193 [28:01<1:10:03, 30.46s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_참이슬',)] Epoch 200 ==============================\n"," Train Loss 0.04810 | Val Loss 0.34429 | SMAPE 0.67406\n","\n","[('담하_처음처럼',)] Epoch 50 ==============================\n"," Train Loss 0.13268 | Val Loss 0.25606 | SMAPE 0.49789\n","\n","[('담하_처음처럼',)] Epoch 100 ==============================\n"," Train Loss 0.07337 | Val Loss 0.24598 | SMAPE 0.47765\n","\n","[('담하_처음처럼',)] Epoch 150 ==============================\n"," Train Loss 0.04521 | Val Loss 0.24107 | SMAPE 0.47876\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  29%|██▉       | 56/193 [28:32<1:09:40, 30.51s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_처음처럼',)] Epoch 200 ==============================\n"," Train Loss 0.03404 | Val Loss 0.24606 | SMAPE 0.48321\n","\n","[('담하_카스',)] Epoch 50 ==============================\n"," Train Loss 0.15337 | Val Loss 0.28545 | SMAPE 0.56869\n","\n","[('담하_카스',)] Epoch 100 ==============================\n"," Train Loss 0.08646 | Val Loss 0.30853 | SMAPE 0.61402\n","\n","[('담하_카스',)] Epoch 150 ==============================\n"," Train Loss 0.05079 | Val Loss 0.30292 | SMAPE 0.60658\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  30%|██▉       | 57/193 [29:03<1:09:12, 30.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_카스',)] Epoch 200 ==============================\n"," Train Loss 0.03779 | Val Loss 0.31557 | SMAPE 0.63086\n","\n","[('담하_콜라',)] Epoch 50 ==============================\n"," Train Loss 0.17082 | Val Loss 0.21823 | SMAPE 0.43148\n","\n","[('담하_콜라',)] Epoch 100 ==============================\n"," Train Loss 0.08060 | Val Loss 0.22291 | SMAPE 0.43874\n","\n","[('담하_콜라',)] Epoch 150 ==============================\n"," Train Loss 0.05391 | Val Loss 0.21645 | SMAPE 0.43509\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  30%|███       | 58/193 [29:33<1:08:38, 30.51s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_콜라',)] Epoch 200 ==============================\n"," Train Loss 0.05883 | Val Loss 0.24055 | SMAPE 0.47889\n","\n","[('담하_테라',)] Epoch 50 ==============================\n"," Train Loss 0.17541 | Val Loss 0.31358 | SMAPE 0.60738\n","\n","[('담하_테라',)] Epoch 100 ==============================\n"," Train Loss 0.08809 | Val Loss 0.27361 | SMAPE 0.53172\n","\n","[('담하_테라',)] Epoch 150 ==============================\n"," Train Loss 0.05283 | Val Loss 0.28055 | SMAPE 0.54165\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  31%|███       | 59/193 [30:04<1:08:12, 30.54s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_테라',)] Epoch 200 ==============================\n"," Train Loss 0.03686 | Val Loss 0.29047 | SMAPE 0.56432\n","\n","[('담하_하동 매실 칵테일',)] Epoch 50 ==============================\n"," Train Loss 0.12167 | Val Loss 0.30692 | SMAPE 0.60004\n","\n","[('담하_하동 매실 칵테일',)] Epoch 100 ==============================\n"," Train Loss 0.07797 | Val Loss 0.31870 | SMAPE 0.61602\n","\n","[('담하_하동 매실 칵테일',)] Epoch 150 ==============================\n"," Train Loss 0.03914 | Val Loss 0.28296 | SMAPE 0.56103\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  31%|███       | 60/193 [30:34<1:07:46, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_하동 매실 칵테일',)] Epoch 200 ==============================\n"," Train Loss 0.02923 | Val Loss 0.30090 | SMAPE 0.58969\n","\n","[('담하_한우 떡갈비 정식',)] Epoch 50 ==============================\n"," Train Loss 0.17548 | Val Loss 0.34715 | SMAPE 0.67789\n","\n","[('담하_한우 떡갈비 정식',)] Epoch 100 ==============================\n"," Train Loss 0.12938 | Val Loss 0.33536 | SMAPE 0.65567\n","\n","[('담하_한우 떡갈비 정식',)] Epoch 150 ==============================\n"," Train Loss 0.09572 | Val Loss 0.33764 | SMAPE 0.65784\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  32%|███▏      | 61/193 [31:05<1:07:22, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 떡갈비 정식',)] Epoch 200 ==============================\n"," Train Loss 0.06916 | Val Loss 0.34255 | SMAPE 0.67560\n","\n","[('담하_한우 미역국 정식',)] Epoch 50 ==============================\n"," Train Loss 0.20683 | Val Loss 0.37183 | SMAPE 0.74282\n","\n","[('담하_한우 미역국 정식',)] Epoch 100 ==============================\n"," Train Loss 0.14075 | Val Loss 0.40469 | SMAPE 0.78839\n","\n","[('담하_한우 미역국 정식',)] Epoch 150 ==============================\n"," Train Loss 0.09255 | Val Loss 0.40871 | SMAPE 0.79216\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  32%|███▏      | 62/193 [31:36<1:06:44, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 미역국 정식',)] Epoch 200 ==============================\n"," Train Loss 0.06741 | Val Loss 0.38979 | SMAPE 0.76650\n","\n","[('담하_한우 우거지 국밥',)] Epoch 50 ==============================\n"," Train Loss 0.21527 | Val Loss 0.33676 | SMAPE 0.66949\n","\n","[('담하_한우 우거지 국밥',)] Epoch 100 ==============================\n"," Train Loss 0.16381 | Val Loss 0.31315 | SMAPE 0.61605\n","\n","[('담하_한우 우거지 국밥',)] Epoch 150 ==============================\n"," Train Loss 0.13176 | Val Loss 0.33117 | SMAPE 0.65018\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  33%|███▎      | 63/193 [32:06<1:06:13, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 우거지 국밥',)] Epoch 200 ==============================\n"," Train Loss 0.09931 | Val Loss 0.34196 | SMAPE 0.67609\n","\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 50 ==============================\n"," Train Loss 0.15419 | Val Loss 0.28799 | SMAPE 0.57194\n","\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 100 ==============================\n"," Train Loss 0.09143 | Val Loss 0.28006 | SMAPE 0.55200\n","\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 150 ==============================\n"," Train Loss 0.09700 | Val Loss 0.29607 | SMAPE 0.58945\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  33%|███▎      | 64/193 [32:37<1:05:44, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_한우 차돌박이 된장찌개',)] Epoch 200 ==============================\n"," Train Loss 0.04190 | Val Loss 0.31095 | SMAPE 0.61381\n","\n","[('담하_황태해장국',)] Epoch 50 ==============================\n"," Train Loss 0.20386 | Val Loss 0.40843 | SMAPE 0.78181\n","\n","[('담하_황태해장국',)] Epoch 100 ==============================\n"," Train Loss 0.12188 | Val Loss 0.40917 | SMAPE 0.79664\n","\n","[('담하_황태해장국',)] Epoch 150 ==============================\n"," Train Loss 0.07875 | Val Loss 0.41362 | SMAPE 0.79676\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  34%|███▎      | 65/193 [33:07<1:05:15, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('담하_황태해장국',)] Epoch 200 ==============================\n"," Train Loss 0.05759 | Val Loss 0.40584 | SMAPE 0.78256\n","\n","[('라그로타_AUS (200g)',)] Epoch 50 ==============================\n"," Train Loss 0.15440 | Val Loss 0.39823 | SMAPE 0.73767\n","\n","[('라그로타_AUS (200g)',)] Epoch 100 ==============================\n"," Train Loss 0.13893 | Val Loss 0.44644 | SMAPE 0.83006\n","\n","[('라그로타_AUS (200g)',)] Epoch 150 ==============================\n"," Train Loss 0.09164 | Val Loss 0.56752 | SMAPE 1.07605\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  34%|███▍      | 66/193 [33:38<1:04:40, 30.55s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_AUS (200g)',)] Epoch 200 ==============================\n"," Train Loss 0.10729 | Val Loss 0.61366 | SMAPE 1.18783\n","\n","[('라그로타_G-Charge(3)',)] Epoch 50 ==============================\n"," Train Loss 0.12299 | Val Loss 0.30103 | SMAPE 0.60033\n","\n","[('라그로타_G-Charge(3)',)] Epoch 100 ==============================\n"," Train Loss 0.08195 | Val Loss 0.29905 | SMAPE 0.58687\n","\n","[('라그로타_G-Charge(3)',)] Epoch 150 ==============================\n"," Train Loss 0.06326 | Val Loss 0.31849 | SMAPE 0.63574\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  35%|███▍      | 67/193 [34:08<1:04:11, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_G-Charge(3)',)] Epoch 200 ==============================\n"," Train Loss 0.03881 | Val Loss 0.33321 | SMAPE 0.67006\n","\n","[('라그로타_Gls.Sileni',)] Epoch 50 ==============================\n"," Train Loss 0.16161 | Val Loss 0.23563 | SMAPE 0.45420\n","\n","[('라그로타_Gls.Sileni',)] Epoch 100 ==============================\n"," Train Loss 0.08278 | Val Loss 0.26811 | SMAPE 0.51409\n","\n","[('라그로타_Gls.Sileni',)] Epoch 150 ==============================\n"," Train Loss 0.04076 | Val Loss 0.27175 | SMAPE 0.53444\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  35%|███▌      | 68/193 [34:39<1:03:38, 30.54s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_Gls.Sileni',)] Epoch 200 ==============================\n"," Train Loss 0.03269 | Val Loss 0.25901 | SMAPE 0.50413\n","\n","[('라그로타_Gls.미션 서드',)] Epoch 50 ==============================\n"," Train Loss 0.15432 | Val Loss 0.30950 | SMAPE 0.59673\n","\n","[('라그로타_Gls.미션 서드',)] Epoch 100 ==============================\n"," Train Loss 0.07663 | Val Loss 0.31538 | SMAPE 0.61278\n","\n","[('라그로타_Gls.미션 서드',)] Epoch 150 ==============================\n"," Train Loss 0.04811 | Val Loss 0.31634 | SMAPE 0.61358\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  36%|███▌      | 69/193 [35:09<1:03:05, 30.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_Gls.미션 서드',)] Epoch 200 ==============================\n"," Train Loss 0.03953 | Val Loss 0.32017 | SMAPE 0.61850\n","\n","[('라그로타_Open Food',)] Epoch 50 ==============================\n"," Train Loss 0.14975 | Val Loss 0.19382 | SMAPE 0.36618\n","\n","[('라그로타_Open Food',)] Epoch 100 ==============================\n"," Train Loss 0.11454 | Val Loss 0.19219 | SMAPE 0.36534\n","\n","[('라그로타_Open Food',)] Epoch 150 ==============================\n"," Train Loss 0.07158 | Val Loss 0.19780 | SMAPE 0.37054\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  36%|███▋      | 70/193 [35:40<1:02:35, 30.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_Open Food',)] Epoch 200 ==============================\n"," Train Loss 0.06355 | Val Loss 0.16535 | SMAPE 0.32528\n","\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 50 ==============================\n"," Train Loss 0.15644 | Val Loss 0.98111 | SMAPE 1.93877\n","\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 100 ==============================\n"," Train Loss 0.12229 | Val Loss 0.93923 | SMAPE 1.80033\n","\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 150 ==============================\n"," Train Loss 0.06604 | Val Loss 0.97390 | SMAPE 1.91378\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  37%|███▋      | 71/193 [36:11<1:02:08, 30.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_그릴드 비프 샐러드',)] Epoch 200 ==============================\n"," Train Loss 0.04903 | Val Loss 0.93949 | SMAPE 1.84134\n","\n","[('라그로타_까르보나라',)] Epoch 50 ==============================\n"," Train Loss 0.11882 | Val Loss 1.00046 | SMAPE 1.97678\n","\n","[('라그로타_까르보나라',)] Epoch 100 ==============================\n"," Train Loss 0.12014 | Val Loss 0.83992 | SMAPE 1.62010\n","\n","[('라그로타_까르보나라',)] Epoch 150 ==============================\n"," Train Loss 0.11416 | Val Loss 0.84304 | SMAPE 1.66827\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  37%|███▋      | 72/193 [36:41<1:01:36, 30.55s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_까르보나라',)] Epoch 200 ==============================\n"," Train Loss 0.08231 | Val Loss 0.94456 | SMAPE 1.87972\n","\n","[('라그로타_모둠 해산물 플래터',)] Epoch 50 ==============================\n"," Train Loss 0.15542 | Val Loss 0.22241 | SMAPE 0.40677\n","\n","[('라그로타_모둠 해산물 플래터',)] Epoch 100 ==============================\n"," Train Loss 0.14908 | Val Loss 0.22373 | SMAPE 0.40918\n","\n","[('라그로타_모둠 해산물 플래터',)] Epoch 150 ==============================\n"," Train Loss 0.13107 | Val Loss 0.22158 | SMAPE 0.40472\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  38%|███▊      | 73/193 [37:11<1:01:00, 30.51s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_모둠 해산물 플래터',)] Epoch 200 ==============================\n"," Train Loss 0.13178 | Val Loss 0.22278 | SMAPE 0.40619\n","\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 50 ==============================\n"," Train Loss 0.13778 | Val Loss 0.25075 | SMAPE 0.50366\n","\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 100 ==============================\n"," Train Loss 0.08900 | Val Loss 0.23262 | SMAPE 0.46828\n","\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 150 ==============================\n"," Train Loss 0.04799 | Val Loss 0.24110 | SMAPE 0.48318\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  38%|███▊      | 74/193 [37:42<1:00:33, 30.54s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_미션 서드 카베르네 쉬라',)] Epoch 200 ==============================\n"," Train Loss 0.03213 | Val Loss 0.24608 | SMAPE 0.48687\n","\n","[('라그로타_버섯 크림 리조또',)] Epoch 50 ==============================\n"," Train Loss 0.12450 | Val Loss 0.59325 | SMAPE 1.09296\n","\n","[('라그로타_버섯 크림 리조또',)] Epoch 100 ==============================\n"," Train Loss 0.09844 | Val Loss 0.45347 | SMAPE 0.81630\n","\n","[('라그로타_버섯 크림 리조또',)] Epoch 150 ==============================\n"," Train Loss 0.05933 | Val Loss 0.50574 | SMAPE 0.92828\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  39%|███▉      | 75/193 [38:13<1:00:06, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_버섯 크림 리조또',)] Epoch 200 ==============================\n"," Train Loss 0.04940 | Val Loss 0.83715 | SMAPE 1.62791\n","\n","[('라그로타_빵 추가 (1인)',)] Epoch 50 ==============================\n"," Train Loss 0.17106 | Val Loss 0.43919 | SMAPE 0.86200\n","\n","[('라그로타_빵 추가 (1인)',)] Epoch 100 ==============================\n"," Train Loss 0.09148 | Val Loss 0.43432 | SMAPE 0.83926\n","\n","[('라그로타_빵 추가 (1인)',)] Epoch 150 ==============================\n"," Train Loss 0.05522 | Val Loss 0.44322 | SMAPE 0.86016\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  39%|███▉      | 76/193 [38:43<59:37, 30.58s/it]  "]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_빵 추가 (1인)',)] Epoch 200 ==============================\n"," Train Loss 0.04798 | Val Loss 0.44182 | SMAPE 0.86089\n","\n","[('라그로타_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.09606 | Val Loss 0.18020 | SMAPE 0.35962\n","\n","[('라그로타_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.05808 | Val Loss 0.18273 | SMAPE 0.36232\n","\n","[('라그로타_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.03732 | Val Loss 0.20933 | SMAPE 0.41887\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  40%|███▉      | 77/193 [39:14<59:05, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.02854 | Val Loss 0.19331 | SMAPE 0.38632\n","\n","[('라그로타_시저 샐러드 ',)] Epoch 50 ==============================\n"," Train Loss 0.18016 | Val Loss 0.60465 | SMAPE 1.11858\n","\n","[('라그로타_시저 샐러드 ',)] Epoch 100 ==============================\n"," Train Loss 0.11148 | Val Loss 0.35040 | SMAPE 0.68350\n","\n","[('라그로타_시저 샐러드 ',)] Epoch 150 ==============================\n"," Train Loss 0.07025 | Val Loss 0.32793 | SMAPE 0.63429\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  40%|████      | 78/193 [39:44<58:33, 30.55s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_시저 샐러드 ',)] Epoch 200 ==============================\n"," Train Loss 0.04635 | Val Loss 0.33264 | SMAPE 0.65220\n","\n","[('라그로타_아메리카노',)] Epoch 50 ==============================\n"," Train Loss 0.14376 | Val Loss 0.28091 | SMAPE 0.55398\n","\n","[('라그로타_아메리카노',)] Epoch 100 ==============================\n"," Train Loss 0.10019 | Val Loss 0.29598 | SMAPE 0.58410\n","\n","[('라그로타_아메리카노',)] Epoch 150 ==============================\n"," Train Loss 0.06276 | Val Loss 0.29692 | SMAPE 0.59262\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  41%|████      | 79/193 [40:15<58:07, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_아메리카노',)] Epoch 200 ==============================\n"," Train Loss 0.05172 | Val Loss 0.29990 | SMAPE 0.59691\n","\n","[('라그로타_알리오 에 올리오 ',)] Epoch 50 ==============================\n"," Train Loss 0.16915 | Val Loss 0.34010 | SMAPE 0.65354\n","\n","[('라그로타_알리오 에 올리오 ',)] Epoch 100 ==============================\n"," Train Loss 0.11168 | Val Loss 0.39757 | SMAPE 0.77601\n","\n","[('라그로타_알리오 에 올리오 ',)] Epoch 150 ==============================\n"," Train Loss 0.06072 | Val Loss 0.40466 | SMAPE 0.79390\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  41%|████▏     | 80/193 [40:46<57:35, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_알리오 에 올리오 ',)] Epoch 200 ==============================\n"," Train Loss 0.04416 | Val Loss 0.42830 | SMAPE 0.84343\n","\n","[('라그로타_양갈비 (4ps)',)] Epoch 50 ==============================\n"," Train Loss 0.10014 | Val Loss 0.43961 | SMAPE 0.80948\n","\n","[('라그로타_양갈비 (4ps)',)] Epoch 100 ==============================\n"," Train Loss 0.09818 | Val Loss 0.71707 | SMAPE 1.35823\n","\n","[('라그로타_양갈비 (4ps)',)] Epoch 150 ==============================\n"," Train Loss 0.06546 | Val Loss 0.70808 | SMAPE 1.34705\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  42%|████▏     | 81/193 [41:16<57:09, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_양갈비 (4ps)',)] Epoch 200 ==============================\n"," Train Loss 0.05422 | Val Loss 0.39718 | SMAPE 0.71378\n","\n","[('라그로타_자몽리치에이드',)] Epoch 50 ==============================\n"," Train Loss 0.10648 | Val Loss 0.24320 | SMAPE 0.47364\n","\n","[('라그로타_자몽리치에이드',)] Epoch 100 ==============================\n"," Train Loss 0.06373 | Val Loss 0.27795 | SMAPE 0.54678\n","\n","[('라그로타_자몽리치에이드',)] Epoch 150 ==============================\n"," Train Loss 0.03664 | Val Loss 0.28419 | SMAPE 0.55294\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  42%|████▏     | 82/193 [41:47<56:33, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_자몽리치에이드',)] Epoch 200 ==============================\n"," Train Loss 0.03844 | Val Loss 0.29914 | SMAPE 0.56932\n","\n","[('라그로타_제로콜라',)] Epoch 50 ==============================\n"," Train Loss 0.10159 | Val Loss 0.24277 | SMAPE 0.47647\n","\n","[('라그로타_제로콜라',)] Epoch 100 ==============================\n"," Train Loss 0.05955 | Val Loss 0.23951 | SMAPE 0.45767\n","\n","[('라그로타_제로콜라',)] Epoch 150 ==============================\n"," Train Loss 0.03823 | Val Loss 0.23346 | SMAPE 0.45201\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  43%|████▎     | 83/193 [42:17<55:59, 30.54s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_제로콜라',)] Epoch 200 ==============================\n"," Train Loss 0.02919 | Val Loss 0.22201 | SMAPE 0.43439\n","\n","[('라그로타_카스',)] Epoch 50 ==============================\n"," Train Loss 0.14842 | Val Loss 0.30612 | SMAPE 0.60474\n","\n","[('라그로타_카스',)] Epoch 100 ==============================\n"," Train Loss 0.07239 | Val Loss 0.28511 | SMAPE 0.55979\n","\n","[('라그로타_카스',)] Epoch 150 ==============================\n"," Train Loss 0.04923 | Val Loss 0.28765 | SMAPE 0.55312\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  44%|████▎     | 84/193 [42:48<55:27, 30.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_카스',)] Epoch 200 ==============================\n"," Train Loss 0.03638 | Val Loss 0.27808 | SMAPE 0.54980\n","\n","[('라그로타_콜라',)] Epoch 50 ==============================\n"," Train Loss 0.14946 | Val Loss 0.25580 | SMAPE 0.50820\n","\n","[('라그로타_콜라',)] Epoch 100 ==============================\n"," Train Loss 0.09876 | Val Loss 0.25322 | SMAPE 0.49878\n","\n","[('라그로타_콜라',)] Epoch 150 ==============================\n"," Train Loss 0.05384 | Val Loss 0.25576 | SMAPE 0.50344\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  44%|████▍     | 85/193 [43:18<55:02, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_콜라',)] Epoch 200 ==============================\n"," Train Loss 0.04101 | Val Loss 0.25879 | SMAPE 0.51391\n","\n","[('라그로타_하이네켄(생)',)] Epoch 50 ==============================\n"," Train Loss 0.17339 | Val Loss 0.35793 | SMAPE 0.69194\n","\n","[('라그로타_하이네켄(생)',)] Epoch 100 ==============================\n"," Train Loss 0.10792 | Val Loss 0.36272 | SMAPE 0.70381\n","\n","[('라그로타_하이네켄(생)',)] Epoch 150 ==============================\n"," Train Loss 0.05472 | Val Loss 0.36666 | SMAPE 0.71390\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  45%|████▍     | 86/193 [43:49<54:29, 30.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_하이네켄(생)',)] Epoch 200 ==============================\n"," Train Loss 0.04043 | Val Loss 0.37447 | SMAPE 0.72984\n","\n","[('라그로타_한우 (200g)',)] Epoch 50 ==============================\n"," Train Loss 0.09754 | Val Loss 0.46528 | SMAPE 0.72828\n","\n","[('라그로타_한우 (200g)',)] Epoch 100 ==============================\n"," Train Loss 0.08055 | Val Loss 0.60415 | SMAPE 0.82604\n","\n","[('라그로타_한우 (200g)',)] Epoch 150 ==============================\n"," Train Loss 0.05007 | Val Loss 0.48809 | SMAPE 0.90599\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  45%|████▌     | 87/193 [44:20<54:02, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_한우 (200g)',)] Epoch 200 ==============================\n"," Train Loss 0.03516 | Val Loss 0.47461 | SMAPE 0.74845\n","\n","[('라그로타_해산물 토마토 리조또',)] Epoch 50 ==============================\n"," Train Loss 0.14258 | Val Loss 0.24746 | SMAPE 0.45675\n","\n","[('라그로타_해산물 토마토 리조또',)] Epoch 100 ==============================\n"," Train Loss 0.07174 | Val Loss 0.31878 | SMAPE 0.59591\n","\n","[('라그로타_해산물 토마토 리조또',)] Epoch 150 ==============================\n"," Train Loss 0.04411 | Val Loss 0.29984 | SMAPE 0.58498\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  46%|████▌     | 88/193 [44:50<53:31, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_해산물 토마토 리조또',)] Epoch 200 ==============================\n"," Train Loss 0.03499 | Val Loss 0.31582 | SMAPE 0.62019\n","\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 50 ==============================\n"," Train Loss 0.16427 | Val Loss 0.83589 | SMAPE 1.58992\n","\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 100 ==============================\n"," Train Loss 0.20108 | Val Loss 0.29049 | SMAPE 0.51018\n","\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 150 ==============================\n"," Train Loss 0.04489 | Val Loss 0.46512 | SMAPE 0.85361\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  46%|████▌     | 89/193 [45:21<53:00, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_해산물 토마토 스튜 파스타',)] Epoch 200 ==============================\n"," Train Loss 0.04261 | Val Loss 0.55742 | SMAPE 1.02352\n","\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 50 ==============================\n"," Train Loss 0.16034 | Val Loss 0.33887 | SMAPE 0.61986\n","\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 100 ==============================\n"," Train Loss 0.08123 | Val Loss 0.35556 | SMAPE 0.65956\n","\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 150 ==============================\n"," Train Loss 0.04737 | Val Loss 0.35058 | SMAPE 0.66104\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  47%|████▋     | 90/193 [45:51<52:28, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('라그로타_해산물 토마토 스파게티',)] Epoch 200 ==============================\n"," Train Loss 0.04007 | Val Loss 0.34776 | SMAPE 0.64849\n","\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 50 ==============================\n"," Train Loss 0.32366 | Val Loss 0.36288 | SMAPE 0.69619\n","\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 100 ==============================\n"," Train Loss 0.26531 | Val Loss 0.40578 | SMAPE 0.76925\n","\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 150 ==============================\n"," Train Loss 0.25416 | Val Loss 0.39569 | SMAPE 0.76178\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  47%|████▋     | 91/193 [46:22<52:00, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_(단체)브런치주중 36,000',)] Epoch 200 ==============================\n"," Train Loss 0.16013 | Val Loss 0.40508 | SMAPE 0.78611\n","\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 50 ==============================\n"," Train Loss 0.16963 | Val Loss 0.21235 | SMAPE 0.41499\n","\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 100 ==============================\n"," Train Loss 0.13418 | Val Loss 0.95683 | SMAPE 1.93542\n","\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 150 ==============================\n"," Train Loss 0.08048 | Val Loss 0.96201 | SMAPE 1.85367\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  48%|████▊     | 92/193 [46:53<51:31, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_(오븐) 하와이안 쉬림프 피자',)] Epoch 200 ==============================\n"," Train Loss 0.05004 | Val Loss 0.98585 | SMAPE 1.95551\n","\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 50 ==============================\n"," Train Loss 0.15473 | Val Loss 0.26045 | SMAPE 0.50843\n","\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 100 ==============================\n"," Train Loss 0.07350 | Val Loss 0.25799 | SMAPE 0.49556\n","\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 150 ==============================\n"," Train Loss 0.04759 | Val Loss 0.26045 | SMAPE 0.50702\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  48%|████▊     | 93/193 [47:23<51:01, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_(화덕) 불고기 페퍼로니 반반피자',)] Epoch 200 ==============================\n"," Train Loss 0.03970 | Val Loss 0.27685 | SMAPE 0.53520\n","\n","[('미라시아_BBQ Platter',)] Epoch 50 ==============================\n"," Train Loss 0.15562 | Val Loss 0.31757 | SMAPE 0.63342\n","\n","[('미라시아_BBQ Platter',)] Epoch 100 ==============================\n"," Train Loss 0.10631 | Val Loss 0.30574 | SMAPE 0.59669\n","\n","[('미라시아_BBQ Platter',)] Epoch 150 ==============================\n"," Train Loss 0.07261 | Val Loss 0.28648 | SMAPE 0.55863\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  49%|████▊     | 94/193 [47:54<50:28, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_BBQ Platter',)] Epoch 200 ==============================\n"," Train Loss 0.05267 | Val Loss 0.27861 | SMAPE 0.54462\n","\n","[('미라시아_BBQ 고기추가',)] Epoch 50 ==============================\n"," Train Loss 0.14954 | Val Loss 0.22816 | SMAPE 0.44960\n","\n","[('미라시아_BBQ 고기추가',)] Epoch 100 ==============================\n"," Train Loss 0.10336 | Val Loss 0.22379 | SMAPE 0.45096\n","\n","[('미라시아_BBQ 고기추가',)] Epoch 150 ==============================\n"," Train Loss 0.06190 | Val Loss 0.24176 | SMAPE 0.48582\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  49%|████▉     | 95/193 [48:24<49:54, 30.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_BBQ 고기추가',)] Epoch 200 ==============================\n"," Train Loss 0.04538 | Val Loss 0.23311 | SMAPE 0.47285\n","\n","[('미라시아_공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.21641 | Val Loss 0.67144 | SMAPE 1.39895\n","\n","[('미라시아_공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.18297 | Val Loss 0.83353 | SMAPE 1.70635\n","\n","[('미라시아_공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.13201 | Val Loss 0.91819 | SMAPE 1.81784\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  50%|████▉     | 96/193 [48:55<49:25, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.09903 | Val Loss 0.86857 | SMAPE 1.57571\n","\n","[('미라시아_글라스와인 (레드)',)] Epoch 50 ==============================\n"," Train Loss 0.10669 | Val Loss 0.25778 | SMAPE 0.51142\n","\n","[('미라시아_글라스와인 (레드)',)] Epoch 100 ==============================\n"," Train Loss 0.06739 | Val Loss 0.25295 | SMAPE 0.49797\n","\n","[('미라시아_글라스와인 (레드)',)] Epoch 150 ==============================\n"," Train Loss 0.04575 | Val Loss 0.24758 | SMAPE 0.48634\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  50%|█████     | 97/193 [49:25<48:54, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_글라스와인 (레드)',)] Epoch 200 ==============================\n"," Train Loss 0.03407 | Val Loss 0.24605 | SMAPE 0.48533\n","\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 50 ==============================\n"," Train Loss 0.09601 | Val Loss 0.17927 | SMAPE 0.31689\n","\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 100 ==============================\n"," Train Loss 0.04187 | Val Loss 0.16403 | SMAPE 0.27835\n","\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 150 ==============================\n"," Train Loss 0.02615 | Val Loss 0.15413 | SMAPE 0.27370\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  51%|█████     | 98/193 [49:56<48:25, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_레인보우칵테일(알코올)',)] Epoch 200 ==============================\n"," Train Loss 0.04309 | Val Loss 0.14776 | SMAPE 0.25675\n","\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 50 ==============================\n"," Train Loss 0.21442 | Val Loss 0.32273 | SMAPE 0.63046\n","\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 100 ==============================\n"," Train Loss 0.13388 | Val Loss 0.32814 | SMAPE 0.64144\n","\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 150 ==============================\n"," Train Loss 0.08350 | Val Loss 0.29818 | SMAPE 0.59016\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  51%|█████▏    | 99/193 [50:27<47:56, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_미라시아 브런치 (패키지)',)] Epoch 200 ==============================\n"," Train Loss 0.06186 | Val Loss 0.30924 | SMAPE 0.60827\n","\n","[('미라시아_버드와이저(무제한)',)] Epoch 50 ==============================\n"," Train Loss 0.17246 | Val Loss 0.32556 | SMAPE 0.64653\n","\n","[('미라시아_버드와이저(무제한)',)] Epoch 100 ==============================\n"," Train Loss 0.11401 | Val Loss 0.32491 | SMAPE 0.64257\n","\n","[('미라시아_버드와이저(무제한)',)] Epoch 150 ==============================\n"," Train Loss 0.07430 | Val Loss 0.32110 | SMAPE 0.64035\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  52%|█████▏    | 100/193 [50:57<47:23, 30.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_버드와이저(무제한)',)] Epoch 200 ==============================\n"," Train Loss 0.05828 | Val Loss 0.32420 | SMAPE 0.64093\n","\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 50 ==============================\n"," Train Loss 0.16533 | Val Loss 0.22903 | SMAPE 0.43105\n","\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 100 ==============================\n"," Train Loss 0.11355 | Val Loss 0.31779 | SMAPE 0.61873\n","\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 150 ==============================\n"," Train Loss 0.04602 | Val Loss 0.24049 | SMAPE 0.45412\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  52%|█████▏    | 101/193 [51:28<46:56, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_보일링 랍스타 플래터',)] Epoch 200 ==============================\n"," Train Loss 0.02962 | Val Loss 0.23062 | SMAPE 0.43748\n","\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 50 ==============================\n"," Train Loss 0.09870 | Val Loss 0.20764 | SMAPE 0.41049\n","\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 100 ==============================\n"," Train Loss 0.07043 | Val Loss 0.19095 | SMAPE 0.37344\n","\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 150 ==============================\n"," Train Loss 0.04728 | Val Loss 0.30221 | SMAPE 0.59065\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  53%|█████▎    | 102/193 [51:59<46:32, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_보일링 랍스타 플래터(덜매운맛)',)] Epoch 200 ==============================\n"," Train Loss 0.04118 | Val Loss 0.20280 | SMAPE 0.39394\n","\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 50 ==============================\n"," Train Loss 0.24903 | Val Loss 0.30543 | SMAPE 0.62544\n","\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 100 ==============================\n"," Train Loss 0.23373 | Val Loss 0.29185 | SMAPE 0.58416\n","\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 150 ==============================\n"," Train Loss 0.14301 | Val Loss 0.31781 | SMAPE 0.63387\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  53%|█████▎    | 103/193 [52:29<46:02, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치 2인 패키지 ',)] Epoch 200 ==============================\n"," Train Loss 0.08969 | Val Loss 0.35003 | SMAPE 0.69776\n","\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 50 ==============================\n"," Train Loss 0.10913 | Val Loss 0.10345 | SMAPE 0.17220\n","\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 100 ==============================\n"," Train Loss 0.05571 | Val Loss 0.13679 | SMAPE 0.24493\n","\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 150 ==============================\n"," Train Loss 0.03999 | Val Loss 0.13230 | SMAPE 0.22978\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  54%|█████▍    | 104/193 [53:00<45:28, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치 4인 패키지 ',)] Epoch 200 ==============================\n"," Train Loss 0.03109 | Val Loss 0.16436 | SMAPE 0.28538\n","\n","[('미라시아_브런치(대인) 주말',)] Epoch 50 ==============================\n"," Train Loss 0.22573 | Val Loss 0.52357 | SMAPE 1.02095\n","\n","[('미라시아_브런치(대인) 주말',)] Epoch 100 ==============================\n"," Train Loss 0.24167 | Val Loss 0.46017 | SMAPE 0.85727\n","\n","[('미라시아_브런치(대인) 주말',)] Epoch 150 ==============================\n"," Train Loss 0.23960 | Val Loss 0.38131 | SMAPE 0.69165\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  54%|█████▍    | 105/193 [53:31<44:53, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치(대인) 주말',)] Epoch 200 ==============================\n"," Train Loss 0.37152 | Val Loss 0.51783 | SMAPE 1.01178\n","\n","[('미라시아_브런치(대인) 주중',)] Epoch 50 ==============================\n"," Train Loss 0.22089 | Val Loss 0.54420 | SMAPE 1.07436\n","\n","[('미라시아_브런치(대인) 주중',)] Epoch 100 ==============================\n"," Train Loss 0.18145 | Val Loss 0.44717 | SMAPE 0.85198\n","\n","[('미라시아_브런치(대인) 주중',)] Epoch 150 ==============================\n"," Train Loss 0.15512 | Val Loss 0.45662 | SMAPE 0.88203\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  55%|█████▍    | 106/193 [54:01<44:23, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치(대인) 주중',)] Epoch 200 ==============================\n"," Train Loss 0.12345 | Val Loss 0.48579 | SMAPE 0.92366\n","\n","[('미라시아_브런치(어린이)',)] Epoch 50 ==============================\n"," Train Loss 0.17055 | Val Loss 0.45878 | SMAPE 0.88605\n","\n","[('미라시아_브런치(어린이)',)] Epoch 100 ==============================\n"," Train Loss 0.11207 | Val Loss 0.45167 | SMAPE 0.86706\n","\n","[('미라시아_브런치(어린이)',)] Epoch 150 ==============================\n"," Train Loss 0.08135 | Val Loss 0.42717 | SMAPE 0.83337\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  55%|█████▌    | 107/193 [54:32<43:52, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_브런치(어린이)',)] Epoch 200 ==============================\n"," Train Loss 0.06128 | Val Loss 0.43622 | SMAPE 0.84224\n","\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 50 ==============================\n"," Train Loss 0.19117 | Val Loss 0.68144 | SMAPE 1.39823\n","\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 100 ==============================\n"," Train Loss 0.12179 | Val Loss 0.80557 | SMAPE 1.61206\n","\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 150 ==============================\n"," Train Loss 0.06490 | Val Loss 0.65753 | SMAPE 1.29511\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  56%|█████▌    | 108/193 [55:02<43:21, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_쉬림프 투움바 파스타',)] Epoch 200 ==============================\n"," Train Loss 0.04470 | Val Loss 0.63521 | SMAPE 1.23768\n","\n","[('미라시아_스텔라(무제한)',)] Epoch 50 ==============================\n"," Train Loss 0.19808 | Val Loss 0.29428 | SMAPE 0.57657\n","\n","[('미라시아_스텔라(무제한)',)] Epoch 100 ==============================\n"," Train Loss 0.12391 | Val Loss 0.30618 | SMAPE 0.60793\n","\n","[('미라시아_스텔라(무제한)',)] Epoch 150 ==============================\n"," Train Loss 0.06037 | Val Loss 0.29531 | SMAPE 0.57688\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  56%|█████▋    | 109/193 [55:33<42:50, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_스텔라(무제한)',)] Epoch 200 ==============================\n"," Train Loss 0.04889 | Val Loss 0.30186 | SMAPE 0.59535\n","\n","[('미라시아_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.14048 | Val Loss 0.32709 | SMAPE 0.61896\n","\n","[('미라시아_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.09529 | Val Loss 0.31604 | SMAPE 0.59361\n","\n","[('미라시아_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.05111 | Val Loss 0.33486 | SMAPE 0.63345\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  57%|█████▋    | 110/193 [56:04<42:21, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.03565 | Val Loss 0.46291 | SMAPE 0.87860\n","\n","[('미라시아_애플망고 에이드',)] Epoch 50 ==============================\n"," Train Loss 0.16973 | Val Loss 0.39398 | SMAPE 0.77236\n","\n","[('미라시아_애플망고 에이드',)] Epoch 100 ==============================\n"," Train Loss 0.09220 | Val Loss 0.35089 | SMAPE 0.69075\n","\n","[('미라시아_애플망고 에이드',)] Epoch 150 ==============================\n"," Train Loss 0.05323 | Val Loss 0.34445 | SMAPE 0.67100\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  58%|█████▊    | 111/193 [56:34<41:52, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_애플망고 에이드',)] Epoch 200 ==============================\n"," Train Loss 0.03863 | Val Loss 0.34317 | SMAPE 0.66379\n","\n","[('미라시아_얼그레이 하이볼',)] Epoch 50 ==============================\n"," Train Loss 0.14522 | Val Loss 0.28093 | SMAPE 0.54276\n","\n","[('미라시아_얼그레이 하이볼',)] Epoch 100 ==============================\n"," Train Loss 0.09704 | Val Loss 0.28344 | SMAPE 0.54774\n","\n","[('미라시아_얼그레이 하이볼',)] Epoch 150 ==============================\n"," Train Loss 0.06368 | Val Loss 0.25901 | SMAPE 0.50577\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  58%|█████▊    | 112/193 [57:05<41:21, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_얼그레이 하이볼',)] Epoch 200 ==============================\n"," Train Loss 0.04453 | Val Loss 0.26447 | SMAPE 0.51512\n","\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 50 ==============================\n"," Train Loss 0.13736 | Val Loss 0.28348 | SMAPE 0.55896\n","\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 100 ==============================\n"," Train Loss 0.08477 | Val Loss 0.21797 | SMAPE 0.42336\n","\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 150 ==============================\n"," Train Loss 0.04869 | Val Loss 0.23374 | SMAPE 0.46073\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  59%|█████▊    | 113/193 [57:36<40:51, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_오븐구이 윙과 킬바사소세지',)] Epoch 200 ==============================\n"," Train Loss 0.03441 | Val Loss 0.22237 | SMAPE 0.43677\n","\n","[('미라시아_유자 하이볼',)] Epoch 50 ==============================\n"," Train Loss 0.15023 | Val Loss 0.28775 | SMAPE 0.55000\n","\n","[('미라시아_유자 하이볼',)] Epoch 100 ==============================\n"," Train Loss 0.09659 | Val Loss 0.31576 | SMAPE 0.60157\n","\n","[('미라시아_유자 하이볼',)] Epoch 150 ==============================\n"," Train Loss 0.05653 | Val Loss 0.28122 | SMAPE 0.54515\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  59%|█████▉    | 114/193 [58:06<40:17, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_유자 하이볼',)] Epoch 200 ==============================\n"," Train Loss 0.04542 | Val Loss 0.28480 | SMAPE 0.55513\n","\n","[('미라시아_잭 애플 토닉',)] Epoch 50 ==============================\n"," Train Loss 0.14664 | Val Loss 0.67869 | SMAPE 1.39069\n","\n","[('미라시아_잭 애플 토닉',)] Epoch 100 ==============================\n"," Train Loss 0.08663 | Val Loss 0.72398 | SMAPE 1.45860\n","\n","[('미라시아_잭 애플 토닉',)] Epoch 150 ==============================\n"," Train Loss 0.08031 | Val Loss 0.21064 | SMAPE 0.42433\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  60%|█████▉    | 115/193 [58:37<39:50, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_잭 애플 토닉',)] Epoch 200 ==============================\n"," Train Loss 0.05039 | Val Loss 0.40918 | SMAPE 0.84019\n","\n","[('미라시아_칠리 치즈 프라이',)] Epoch 50 ==============================\n"," Train Loss 0.12546 | Val Loss 0.20851 | SMAPE 0.40424\n","\n","[('미라시아_칠리 치즈 프라이',)] Epoch 100 ==============================\n"," Train Loss 0.08655 | Val Loss 0.19043 | SMAPE 0.36365\n","\n","[('미라시아_칠리 치즈 프라이',)] Epoch 150 ==============================\n"," Train Loss 0.04436 | Val Loss 0.38320 | SMAPE 0.75267\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  60%|██████    | 116/193 [59:07<39:18, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_칠리 치즈 프라이',)] Epoch 200 ==============================\n"," Train Loss 0.02965 | Val Loss 0.51295 | SMAPE 0.97166\n","\n","[('미라시아_코카콜라',)] Epoch 50 ==============================\n"," Train Loss 0.17465 | Val Loss 0.46315 | SMAPE 0.91727\n","\n","[('미라시아_코카콜라',)] Epoch 100 ==============================\n"," Train Loss 0.12484 | Val Loss 0.24894 | SMAPE 0.49539\n","\n","[('미라시아_코카콜라',)] Epoch 150 ==============================\n"," Train Loss 0.06168 | Val Loss 0.45917 | SMAPE 0.88783\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  61%|██████    | 117/193 [59:38<38:47, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_코카콜라',)] Epoch 200 ==============================\n"," Train Loss 0.04583 | Val Loss 0.27218 | SMAPE 0.54745\n","\n","[('미라시아_코카콜라(제로)',)] Epoch 50 ==============================\n"," Train Loss 0.15319 | Val Loss 0.22527 | SMAPE 0.43876\n","\n","[('미라시아_코카콜라(제로)',)] Epoch 100 ==============================\n"," Train Loss 0.08806 | Val Loss 0.23775 | SMAPE 0.46757\n","\n","[('미라시아_코카콜라(제로)',)] Epoch 150 ==============================\n"," Train Loss 0.06974 | Val Loss 0.22793 | SMAPE 0.44952\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  61%|██████    | 118/193 [1:00:09<38:16, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_코카콜라(제로)',)] Epoch 200 ==============================\n"," Train Loss 0.05291 | Val Loss 0.22273 | SMAPE 0.43881\n","\n","[('미라시아_콥 샐러드',)] Epoch 50 ==============================\n"," Train Loss 0.13089 | Val Loss 0.35289 | SMAPE 0.62501\n","\n","[('미라시아_콥 샐러드',)] Epoch 100 ==============================\n"," Train Loss 0.17983 | Val Loss 0.30459 | SMAPE 0.57896\n","\n","[('미라시아_콥 샐러드',)] Epoch 150 ==============================\n"," Train Loss 0.11059 | Val Loss 0.32425 | SMAPE 0.58902\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  62%|██████▏   | 119/193 [1:00:39<37:49, 30.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_콥 샐러드',)] Epoch 200 ==============================\n"," Train Loss 0.07556 | Val Loss 0.32045 | SMAPE 0.58725\n","\n","[('미라시아_파스타면 추가(150g)',)] Epoch 50 ==============================\n"," Train Loss 0.15563 | Val Loss 0.18421 | SMAPE 0.36344\n","\n","[('미라시아_파스타면 추가(150g)',)] Epoch 100 ==============================\n"," Train Loss 0.08761 | Val Loss 0.17499 | SMAPE 0.34347\n","\n","[('미라시아_파스타면 추가(150g)',)] Epoch 150 ==============================\n"," Train Loss 0.05472 | Val Loss 0.17803 | SMAPE 0.34771\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  62%|██████▏   | 120/193 [1:01:10<37:18, 30.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_파스타면 추가(150g)',)] Epoch 200 ==============================\n"," Train Loss 0.04095 | Val Loss 0.18477 | SMAPE 0.36522\n","\n","[('미라시아_핑크레몬에이드',)] Epoch 50 ==============================\n"," Train Loss 0.15563 | Val Loss 0.22673 | SMAPE 0.44638\n","\n","[('미라시아_핑크레몬에이드',)] Epoch 100 ==============================\n"," Train Loss 0.10323 | Val Loss 0.20164 | SMAPE 0.39757\n","\n","[('미라시아_핑크레몬에이드',)] Epoch 150 ==============================\n"," Train Loss 0.05545 | Val Loss 0.22245 | SMAPE 0.44184\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  63%|██████▎   | 121/193 [1:01:41<36:49, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('미라시아_핑크레몬에이드',)] Epoch 200 ==============================\n"," Train Loss 0.03787 | Val Loss 0.22815 | SMAPE 0.45840\n","\n","[('연회장_Cass Beer',)] Epoch 50 ==============================\n"," Train Loss 0.21751 | Val Loss 0.39151 | SMAPE 0.73935\n","\n","[('연회장_Cass Beer',)] Epoch 100 ==============================\n"," Train Loss 0.12626 | Val Loss 0.44424 | SMAPE 0.83385\n","\n","[('연회장_Cass Beer',)] Epoch 150 ==============================\n"," Train Loss 0.09528 | Val Loss 0.36091 | SMAPE 0.69771\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  63%|██████▎   | 122/193 [1:02:12<36:19, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Cass Beer',)] Epoch 200 ==============================\n"," Train Loss 0.07370 | Val Loss 0.41012 | SMAPE 0.79451\n","\n","[('연회장_Conference L1',)] Epoch 50 ==============================\n"," Train Loss 0.05997 | Val Loss 0.06872 | SMAPE 0.04012\n","\n","[('연회장_Conference L1',)] Epoch 100 ==============================\n"," Train Loss 0.05975 | Val Loss 0.06773 | SMAPE 0.03677\n","\n","[('연회장_Conference L1',)] Epoch 150 ==============================\n"," Train Loss 0.05456 | Val Loss 0.06671 | SMAPE 0.03675\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  64%|██████▎   | 123/193 [1:02:42<35:48, 30.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference L1',)] Epoch 200 ==============================\n"," Train Loss 0.05298 | Val Loss 0.06571 | SMAPE 0.03726\n","\n","[('연회장_Conference L2',)] Epoch 50 ==============================\n"," Train Loss 0.05496 | Val Loss 0.04146 | SMAPE 0.04104\n","\n","[('연회장_Conference L2',)] Epoch 100 ==============================\n"," Train Loss 0.04832 | Val Loss 0.04271 | SMAPE 0.04345\n","\n","[('연회장_Conference L2',)] Epoch 150 ==============================\n"," Train Loss 0.04573 | Val Loss 0.03991 | SMAPE 0.03674\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  64%|██████▍   | 124/193 [1:03:13<35:18, 30.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference L2',)] Epoch 200 ==============================\n"," Train Loss 0.04080 | Val Loss 0.04043 | SMAPE 0.03854\n","\n","[('연회장_Conference L3',)] Epoch 50 ==============================\n"," Train Loss 0.05247 | Val Loss 0.05160 | SMAPE 0.00994\n","\n","[('연회장_Conference L3',)] Epoch 100 ==============================\n"," Train Loss 0.05056 | Val Loss 0.05317 | SMAPE 0.01761\n","\n","[('연회장_Conference L3',)] Epoch 150 ==============================\n"," Train Loss 0.03895 | Val Loss 0.07744 | SMAPE 0.07219\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  65%|██████▍   | 125/193 [1:03:44<34:45, 30.68s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference L3',)] Epoch 200 ==============================\n"," Train Loss 0.03119 | Val Loss 0.14447 | SMAPE 0.21843\n","\n","[('연회장_Conference M1',)] Epoch 50 ==============================\n"," Train Loss 0.05578 | Val Loss 0.04638 | SMAPE 0.00597\n","\n","[('연회장_Conference M1',)] Epoch 100 ==============================\n"," Train Loss 0.05425 | Val Loss 0.05214 | SMAPE 0.01746\n","\n","[('연회장_Conference M1',)] Epoch 150 ==============================\n"," Train Loss 0.05235 | Val Loss 0.06300 | SMAPE 0.04456\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  65%|██████▌   | 126/193 [1:04:14<34:14, 30.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference M1',)] Epoch 200 ==============================\n"," Train Loss 0.04853 | Val Loss 0.16036 | SMAPE 0.20374\n","\n","[('연회장_Conference M8',)] Epoch 50 ==============================\n"," Train Loss 0.06044 | Val Loss 0.05182 | SMAPE 0.00788\n","\n","[('연회장_Conference M8',)] Epoch 100 ==============================\n"," Train Loss 0.06107 | Val Loss 0.05410 | SMAPE 0.01048\n","\n","[('연회장_Conference M8',)] Epoch 150 ==============================\n"," Train Loss 0.06039 | Val Loss 0.05342 | SMAPE 0.00729\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  66%|██████▌   | 127/193 [1:04:45<33:41, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference M8',)] Epoch 200 ==============================\n"," Train Loss 0.05933 | Val Loss 0.05065 | SMAPE 0.00449\n","\n","[('연회장_Conference M9',)] Epoch 50 ==============================\n"," Train Loss 0.05766 | Val Loss 0.04969 | SMAPE 0.01198\n","\n","[('연회장_Conference M9',)] Epoch 100 ==============================\n"," Train Loss 0.05611 | Val Loss 0.05110 | SMAPE 0.01020\n","\n","[('연회장_Conference M9',)] Epoch 150 ==============================\n"," Train Loss 0.04666 | Val Loss 0.06570 | SMAPE 0.03967\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  66%|██████▋   | 128/193 [1:05:15<33:07, 30.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Conference M9',)] Epoch 200 ==============================\n"," Train Loss 0.04347 | Val Loss 0.04754 | SMAPE 0.01480\n","\n","[('연회장_Convention Hall',)] Epoch 50 ==============================\n"," Train Loss 0.05129 | Val Loss 0.02213 | SMAPE 0.01395\n","\n","[('연회장_Convention Hall',)] Epoch 100 ==============================\n"," Train Loss 0.04683 | Val Loss 0.01820 | SMAPE 0.00577\n","\n","[('연회장_Convention Hall',)] Epoch 150 ==============================\n"," Train Loss 0.04795 | Val Loss 0.01949 | SMAPE 0.00910\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  67%|██████▋   | 129/193 [1:05:46<32:39, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Convention Hall',)] Epoch 200 ==============================\n"," Train Loss 0.04592 | Val Loss 0.01873 | SMAPE 0.00610\n","\n","[('연회장_Cookie Platter',)] Epoch 50 ==============================\n"," Train Loss 0.18840 | Val Loss 0.35457 | SMAPE 0.70260\n","\n","[('연회장_Cookie Platter',)] Epoch 100 ==============================\n"," Train Loss 0.13689 | Val Loss 0.36321 | SMAPE 0.71104\n","\n","[('연회장_Cookie Platter',)] Epoch 150 ==============================\n"," Train Loss 0.08594 | Val Loss 0.35709 | SMAPE 0.70016\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  67%|██████▋   | 130/193 [1:06:17<32:11, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Cookie Platter',)] Epoch 200 ==============================\n"," Train Loss 0.05576 | Val Loss 0.35752 | SMAPE 0.69648\n","\n","[('연회장_Grand Ballroom',)] Epoch 50 ==============================\n"," Train Loss 0.08183 | Val Loss 0.07659 | SMAPE 0.05869\n","\n","[('연회장_Grand Ballroom',)] Epoch 100 ==============================\n"," Train Loss 0.07104 | Val Loss 0.07979 | SMAPE 0.06485\n","\n","[('연회장_Grand Ballroom',)] Epoch 150 ==============================\n"," Train Loss 0.08031 | Val Loss 0.07444 | SMAPE 0.05500\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  68%|██████▊   | 131/193 [1:06:47<31:41, 30.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Grand Ballroom',)] Epoch 200 ==============================\n"," Train Loss 0.08159 | Val Loss 0.07588 | SMAPE 0.05694\n","\n","[('연회장_OPUS 2',)] Epoch 50 ==============================\n"," Train Loss 0.07584 | Val Loss 0.05975 | SMAPE 0.02218\n","\n","[('연회장_OPUS 2',)] Epoch 100 ==============================\n"," Train Loss 0.07090 | Val Loss 0.05176 | SMAPE 0.00782\n","\n","[('연회장_OPUS 2',)] Epoch 150 ==============================\n"," Train Loss 0.06903 | Val Loss 0.07367 | SMAPE 0.06710\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  68%|██████▊   | 132/193 [1:07:18<31:12, 30.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_OPUS 2',)] Epoch 200 ==============================\n"," Train Loss 0.06322 | Val Loss 0.04867 | SMAPE 0.01417\n","\n","[('연회장_Regular Coffee',)] Epoch 50 ==============================\n"," Train Loss 0.19867 | Val Loss 0.34772 | SMAPE 0.68840\n","\n","[('연회장_Regular Coffee',)] Epoch 100 ==============================\n"," Train Loss 0.13969 | Val Loss 0.35955 | SMAPE 0.70953\n","\n","[('연회장_Regular Coffee',)] Epoch 150 ==============================\n"," Train Loss 0.11437 | Val Loss 0.38664 | SMAPE 0.77894\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  69%|██████▉   | 133/193 [1:07:49<30:38, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_Regular Coffee',)] Epoch 200 ==============================\n"," Train Loss 0.10341 | Val Loss 0.36757 | SMAPE 0.72197\n","\n","[('연회장_골뱅이무침',)] Epoch 50 ==============================\n"," Train Loss 0.11175 | Val Loss 0.26249 | SMAPE 0.49414\n","\n","[('연회장_골뱅이무침',)] Epoch 100 ==============================\n"," Train Loss 0.06701 | Val Loss 0.26623 | SMAPE 0.50439\n","\n","[('연회장_골뱅이무침',)] Epoch 150 ==============================\n"," Train Loss 0.04496 | Val Loss 0.28375 | SMAPE 0.54280\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  69%|██████▉   | 134/193 [1:08:19<30:06, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_골뱅이무침',)] Epoch 200 ==============================\n"," Train Loss 0.03876 | Val Loss 0.27336 | SMAPE 0.52925\n","\n","[('연회장_공깃밥',)] Epoch 50 ==============================\n"," Train Loss 0.19548 | Val Loss 0.52355 | SMAPE 1.02264\n","\n","[('연회장_공깃밥',)] Epoch 100 ==============================\n"," Train Loss 0.11843 | Val Loss 0.48581 | SMAPE 0.96119\n","\n","[('연회장_공깃밥',)] Epoch 150 ==============================\n"," Train Loss 0.07196 | Val Loss 0.70449 | SMAPE 1.40480\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  70%|██████▉   | 135/193 [1:08:50<29:37, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_공깃밥',)] Epoch 200 ==============================\n"," Train Loss 0.04939 | Val Loss 0.84082 | SMAPE 1.66204\n","\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 50 ==============================\n"," Train Loss 0.15459 | Val Loss 0.28279 | SMAPE 0.54152\n","\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 100 ==============================\n"," Train Loss 0.09698 | Val Loss 0.31684 | SMAPE 0.60887\n","\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 150 ==============================\n"," Train Loss 0.05708 | Val Loss 0.28752 | SMAPE 0.57817\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  70%|███████   | 136/193 [1:09:21<29:06, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_돈목살 김치찌개 (밥포함)',)] Epoch 200 ==============================\n"," Train Loss 0.03907 | Val Loss 0.27537 | SMAPE 0.52740\n","\n","[('연회장_로제 치즈떡볶이',)] Epoch 50 ==============================\n"," Train Loss 0.14400 | Val Loss 0.21055 | SMAPE 0.41404\n","\n","[('연회장_로제 치즈떡볶이',)] Epoch 100 ==============================\n"," Train Loss 0.08670 | Val Loss 0.23750 | SMAPE 0.45593\n","\n","[('연회장_로제 치즈떡볶이',)] Epoch 150 ==============================\n"," Train Loss 0.05657 | Val Loss 0.23190 | SMAPE 0.45758\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  71%|███████   | 137/193 [1:09:51<28:33, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_로제 치즈떡볶이',)] Epoch 200 ==============================\n"," Train Loss 0.04884 | Val Loss 0.21339 | SMAPE 0.40938\n","\n","[('연회장_마라샹궈',)] Epoch 50 ==============================\n"," Train Loss 0.14471 | Val Loss 0.87703 | SMAPE 1.77239\n","\n","[('연회장_마라샹궈',)] Epoch 100 ==============================\n"," Train Loss 0.08951 | Val Loss 0.89585 | SMAPE 1.82076\n","\n","[('연회장_마라샹궈',)] Epoch 150 ==============================\n"," Train Loss 0.08418 | Val Loss 0.85639 | SMAPE 1.75497\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  72%|███████▏  | 138/193 [1:10:22<28:02, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_마라샹궈',)] Epoch 200 ==============================\n"," Train Loss 0.04884 | Val Loss 0.79307 | SMAPE 1.58783\n","\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 50 ==============================\n"," Train Loss 0.13121 | Val Loss 0.28148 | SMAPE 0.53809\n","\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 100 ==============================\n"," Train Loss 0.06296 | Val Loss 0.27211 | SMAPE 0.52887\n","\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 150 ==============================\n"," Train Loss 0.04103 | Val Loss 0.26531 | SMAPE 0.51234\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  72%|███████▏  | 139/193 [1:10:52<27:32, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_매콤 무뼈닭발&계란찜',)] Epoch 200 ==============================\n"," Train Loss 0.03676 | Val Loss 0.27448 | SMAPE 0.53441\n","\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 50 ==============================\n"," Train Loss 0.13125 | Val Loss 0.21215 | SMAPE 0.39334\n","\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 100 ==============================\n"," Train Loss 0.08781 | Val Loss 0.22729 | SMAPE 0.43171\n","\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 150 ==============================\n"," Train Loss 0.06026 | Val Loss 0.23171 | SMAPE 0.43733\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  73%|███████▎  | 140/193 [1:11:23<27:02, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_모둠 돈육구이(3인)',)] Epoch 200 ==============================\n"," Train Loss 0.04052 | Val Loss 0.20743 | SMAPE 0.39089\n","\n","[('연회장_삼겹살추가 (200g)',)] Epoch 50 ==============================\n"," Train Loss 0.15148 | Val Loss 0.51232 | SMAPE 0.95733\n","\n","[('연회장_삼겹살추가 (200g)',)] Epoch 100 ==============================\n"," Train Loss 0.09963 | Val Loss 0.73920 | SMAPE 1.49145\n","\n","[('연회장_삼겹살추가 (200g)',)] Epoch 150 ==============================\n"," Train Loss 0.08364 | Val Loss 0.50344 | SMAPE 0.99575\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  73%|███████▎  | 141/193 [1:11:54<26:32, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_삼겹살추가 (200g)',)] Epoch 200 ==============================\n"," Train Loss 0.05002 | Val Loss 0.77147 | SMAPE 1.52346\n","\n","[('연회장_야채추가',)] Epoch 50 ==============================\n"," Train Loss 0.08535 | Val Loss 0.20422 | SMAPE 0.39274\n","\n","[('연회장_야채추가',)] Epoch 100 ==============================\n"," Train Loss 0.04762 | Val Loss 0.21623 | SMAPE 0.41743\n","\n","[('연회장_야채추가',)] Epoch 150 ==============================\n"," Train Loss 0.03961 | Val Loss 0.22607 | SMAPE 0.43242\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  74%|███████▎  | 142/193 [1:12:24<26:05, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_야채추가',)] Epoch 200 ==============================\n"," Train Loss 0.02278 | Val Loss 0.22070 | SMAPE 0.44167\n","\n","[('연회장_왕갈비치킨',)] Epoch 50 ==============================\n"," Train Loss 0.17297 | Val Loss 0.27670 | SMAPE 0.51882\n","\n","[('연회장_왕갈비치킨',)] Epoch 100 ==============================\n"," Train Loss 0.10218 | Val Loss 0.91519 | SMAPE 1.79062\n","\n","[('연회장_왕갈비치킨',)] Epoch 150 ==============================\n"," Train Loss 0.07213 | Val Loss 0.97718 | SMAPE 1.91732\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  74%|███████▍  | 143/193 [1:12:55<25:36, 30.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_왕갈비치킨',)] Epoch 200 ==============================\n"," Train Loss 0.04603 | Val Loss 1.00709 | SMAPE 1.97466\n","\n","[('연회장_주먹밥 (2ea)',)] Epoch 50 ==============================\n"," Train Loss 0.14177 | Val Loss 0.22488 | SMAPE 0.43024\n","\n","[('연회장_주먹밥 (2ea)',)] Epoch 100 ==============================\n"," Train Loss 0.07950 | Val Loss 0.19314 | SMAPE 0.36998\n","\n","[('연회장_주먹밥 (2ea)',)] Epoch 150 ==============================\n"," Train Loss 0.05635 | Val Loss 0.20943 | SMAPE 0.40011\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  75%|███████▍  | 144/193 [1:13:26<25:04, 30.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('연회장_주먹밥 (2ea)',)] Epoch 200 ==============================\n"," Train Loss 0.03811 | Val Loss 0.22015 | SMAPE 0.42762\n","\n","[('카페테리아_공깃밥(추가)',)] Epoch 50 ==============================\n"," Train Loss 0.20798 | Val Loss 0.38067 | SMAPE 0.75202\n","\n","[('카페테리아_공깃밥(추가)',)] Epoch 100 ==============================\n"," Train Loss 0.15967 | Val Loss 0.34745 | SMAPE 0.69353\n","\n","[('카페테리아_공깃밥(추가)',)] Epoch 150 ==============================\n"," Train Loss 0.12578 | Val Loss 0.35428 | SMAPE 0.70211\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  75%|███████▌  | 145/193 [1:13:57<24:35, 30.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_공깃밥(추가)',)] Epoch 200 ==============================\n"," Train Loss 0.07948 | Val Loss 0.36145 | SMAPE 0.71787\n","\n","[('카페테리아_구슬아이스크림',)] Epoch 50 ==============================\n"," Train Loss 0.45793 | Val Loss 0.63480 | SMAPE 1.20458\n","\n","[('카페테리아_구슬아이스크림',)] Epoch 100 ==============================\n"," Train Loss 0.40379 | Val Loss 0.64830 | SMAPE 1.22499\n","\n","[('카페테리아_구슬아이스크림',)] Epoch 150 ==============================\n"," Train Loss 0.40375 | Val Loss 0.63161 | SMAPE 1.19822\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  76%|███████▌  | 146/193 [1:14:27<24:03, 30.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_구슬아이스크림',)] Epoch 200 ==============================\n"," Train Loss 0.22841 | Val Loss 0.59534 | SMAPE 1.18957\n","\n","[('카페테리아_단체식 13000(신)',)] Epoch 50 ==============================\n"," Train Loss 0.18958 | Val Loss 0.38747 | SMAPE 0.75410\n","\n","[('카페테리아_단체식 13000(신)',)] Epoch 100 ==============================\n"," Train Loss 0.13808 | Val Loss 0.40538 | SMAPE 0.81913\n","\n","[('카페테리아_단체식 13000(신)',)] Epoch 150 ==============================\n"," Train Loss 0.08393 | Val Loss 0.41414 | SMAPE 0.81083\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  76%|███████▌  | 147/193 [1:14:58<23:32, 30.71s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_단체식 13000(신)',)] Epoch 200 ==============================\n"," Train Loss 0.06193 | Val Loss 0.39177 | SMAPE 0.76935\n","\n","[('카페테리아_단체식 18000(신)',)] Epoch 50 ==============================\n"," Train Loss 0.15975 | Val Loss 0.45635 | SMAPE 0.88048\n","\n","[('카페테리아_단체식 18000(신)',)] Epoch 100 ==============================\n"," Train Loss 0.11918 | Val Loss 0.44954 | SMAPE 0.86535\n","\n","[('카페테리아_단체식 18000(신)',)] Epoch 150 ==============================\n"," Train Loss 0.07304 | Val Loss 0.45525 | SMAPE 0.88301\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  77%|███████▋  | 148/193 [1:15:29<23:02, 30.72s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_단체식 18000(신)',)] Epoch 200 ==============================\n"," Train Loss 0.05361 | Val Loss 0.42867 | SMAPE 0.82149\n","\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 50 ==============================\n"," Train Loss 0.18317 | Val Loss 0.32251 | SMAPE 0.63884\n","\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 100 ==============================\n"," Train Loss 0.13191 | Val Loss 0.35603 | SMAPE 0.70174\n","\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 150 ==============================\n"," Train Loss 0.11392 | Val Loss 0.33088 | SMAPE 0.65914\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  77%|███████▋  | 149/193 [1:15:59<22:30, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_돼지고기 김치찌개',)] Epoch 200 ==============================\n"," Train Loss 0.08267 | Val Loss 0.34565 | SMAPE 0.69412\n","\n","[('카페테리아_복숭아 아이스티',)] Epoch 50 ==============================\n"," Train Loss 0.24284 | Val Loss 0.71533 | SMAPE 1.42194\n","\n","[('카페테리아_복숭아 아이스티',)] Epoch 100 ==============================\n"," Train Loss 0.30696 | Val Loss 0.59904 | SMAPE 1.17760\n","\n","[('카페테리아_복숭아 아이스티',)] Epoch 150 ==============================\n"," Train Loss 0.20143 | Val Loss 0.68944 | SMAPE 1.37304\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  78%|███████▊  | 150/193 [1:16:30<21:59, 30.68s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_복숭아 아이스티',)] Epoch 200 ==============================\n"," Train Loss 0.16076 | Val Loss 0.75787 | SMAPE 1.50634\n","\n","[('카페테리아_새우 볶음밥',)] Epoch 50 ==============================\n"," Train Loss 0.18986 | Val Loss 0.35457 | SMAPE 0.71187\n","\n","[('카페테리아_새우 볶음밥',)] Epoch 100 ==============================\n"," Train Loss 0.13805 | Val Loss 0.34963 | SMAPE 0.69279\n","\n","[('카페테리아_새우 볶음밥',)] Epoch 150 ==============================\n"," Train Loss 0.08752 | Val Loss 0.37765 | SMAPE 0.76147\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  78%|███████▊  | 151/193 [1:17:01<21:27, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_새우 볶음밥',)] Epoch 200 ==============================\n"," Train Loss 0.06467 | Val Loss 0.37330 | SMAPE 0.74697\n","\n","[('카페테리아_새우튀김 우동',)] Epoch 50 ==============================\n"," Train Loss 0.22344 | Val Loss 0.64559 | SMAPE 1.26741\n","\n","[('카페테리아_새우튀김 우동',)] Epoch 100 ==============================\n"," Train Loss 0.20784 | Val Loss 0.62386 | SMAPE 1.23937\n","\n","[('카페테리아_새우튀김 우동',)] Epoch 150 ==============================\n"," Train Loss 0.17921 | Val Loss 0.68674 | SMAPE 1.36625\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  79%|███████▉  | 152/193 [1:17:31<20:54, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_새우튀김 우동',)] Epoch 200 ==============================\n"," Train Loss 0.13370 | Val Loss 0.74373 | SMAPE 1.48006\n","\n","[('카페테리아_샷 추가',)] Epoch 50 ==============================\n"," Train Loss 0.26261 | Val Loss 0.00313 | SMAPE 0.00000\n","\n","[('카페테리아_샷 추가',)] Epoch 100 ==============================\n"," Train Loss 0.30727 | Val Loss 0.00698 | SMAPE 0.00000\n","\n","[('카페테리아_샷 추가',)] Epoch 150 ==============================\n"," Train Loss 0.29550 | Val Loss 0.01301 | SMAPE 0.00000\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  79%|███████▉  | 153/193 [1:18:02<20:23, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_샷 추가',)] Epoch 200 ==============================\n"," Train Loss 0.28764 | Val Loss 0.02571 | SMAPE 0.00000\n","\n","[('카페테리아_수제 등심 돈까스',)] Epoch 50 ==============================\n"," Train Loss 0.19899 | Val Loss 0.34530 | SMAPE 0.69337\n","\n","[('카페테리아_수제 등심 돈까스',)] Epoch 100 ==============================\n"," Train Loss 0.15341 | Val Loss 0.33740 | SMAPE 0.67712\n","\n","[('카페테리아_수제 등심 돈까스',)] Epoch 150 ==============================\n"," Train Loss 0.11312 | Val Loss 0.33403 | SMAPE 0.67193\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  80%|███████▉  | 154/193 [1:18:32<19:53, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_수제 등심 돈까스',)] Epoch 200 ==============================\n"," Train Loss 0.07703 | Val Loss 0.34608 | SMAPE 0.68286\n","\n","[('카페테리아_아메리카노(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.34531 | Val Loss 0.65960 | SMAPE 1.31421\n","\n","[('카페테리아_아메리카노(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.15454 | Val Loss 0.24103 | SMAPE 0.48060\n","\n","[('카페테리아_아메리카노(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.11482 | Val Loss 0.81174 | SMAPE 1.62002\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  80%|████████  | 155/193 [1:19:03<19:23, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_아메리카노(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.10187 | Val Loss 0.82595 | SMAPE 1.64739\n","\n","[('카페테리아_아메리카노(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.15721 | Val Loss 0.85665 | SMAPE 1.70254\n","\n","[('카페테리아_아메리카노(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.08650 | Val Loss 0.85017 | SMAPE 1.69449\n","\n","[('카페테리아_아메리카노(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.06848 | Val Loss 0.84308 | SMAPE 1.67923\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  81%|████████  | 156/193 [1:19:34<18:53, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_아메리카노(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.06874 | Val Loss 0.83968 | SMAPE 1.67259\n","\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 50 ==============================\n"," Train Loss 0.18053 | Val Loss 0.33598 | SMAPE 0.66383\n","\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 100 ==============================\n"," Train Loss 0.14155 | Val Loss 0.36015 | SMAPE 0.72951\n","\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 150 ==============================\n"," Train Loss 0.09044 | Val Loss 0.36456 | SMAPE 0.73228\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  81%|████████▏ | 157/193 [1:20:04<18:23, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_약 고추장 돌솥비빔밥',)] Epoch 200 ==============================\n"," Train Loss 0.06502 | Val Loss 0.36912 | SMAPE 0.72305\n","\n","[('카페테리아_어린이 돈까스',)] Epoch 50 ==============================\n"," Train Loss 0.16933 | Val Loss 0.31375 | SMAPE 0.62915\n","\n","[('카페테리아_어린이 돈까스',)] Epoch 100 ==============================\n"," Train Loss 0.13608 | Val Loss 0.29224 | SMAPE 0.60716\n","\n","[('카페테리아_어린이 돈까스',)] Epoch 150 ==============================\n"," Train Loss 0.08569 | Val Loss 0.30951 | SMAPE 0.61135\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  82%|████████▏ | 158/193 [1:20:35<17:52, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_어린이 돈까스',)] Epoch 200 ==============================\n"," Train Loss 0.06307 | Val Loss 0.29887 | SMAPE 0.59628\n","\n","[('카페테리아_오픈푸드',)] Epoch 50 ==============================\n"," Train Loss 0.90832 | Val Loss 0.79815 | SMAPE 1.64399\n","\n","[('카페테리아_오픈푸드',)] Epoch 100 ==============================\n"," Train Loss 0.67087 | Val Loss 0.40650 | SMAPE 0.71513\n","\n","[('카페테리아_오픈푸드',)] Epoch 150 ==============================\n"," Train Loss 0.66180 | Val Loss 0.40718 | SMAPE 0.71536\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  82%|████████▏ | 159/193 [1:21:06<17:22, 30.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_오픈푸드',)] Epoch 200 ==============================\n"," Train Loss 0.67284 | Val Loss 0.40844 | SMAPE 0.71560\n","\n","[('카페테리아_진사골 설렁탕',)] Epoch 50 ==============================\n"," Train Loss 0.15138 | Val Loss 0.82865 | SMAPE 1.58148\n","\n","[('카페테리아_진사골 설렁탕',)] Epoch 100 ==============================\n"," Train Loss 0.13851 | Val Loss 0.70264 | SMAPE 1.39771\n","\n","[('카페테리아_진사골 설렁탕',)] Epoch 150 ==============================\n"," Train Loss 0.10612 | Val Loss 0.82544 | SMAPE 1.60775\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  83%|████████▎ | 160/193 [1:21:36<16:51, 30.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_진사골 설렁탕',)] Epoch 200 ==============================\n"," Train Loss 0.14042 | Val Loss 0.83420 | SMAPE 1.60022\n","\n","[('카페테리아_짜장면',)] Epoch 50 ==============================\n"," Train Loss 0.21693 | Val Loss 0.32055 | SMAPE 0.64619\n","\n","[('카페테리아_짜장면',)] Epoch 100 ==============================\n"," Train Loss 0.15043 | Val Loss 0.32348 | SMAPE 0.64360\n","\n","[('카페테리아_짜장면',)] Epoch 150 ==============================\n"," Train Loss 0.12365 | Val Loss 0.31971 | SMAPE 0.65115\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  83%|████████▎ | 161/193 [1:22:07<16:20, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짜장면',)] Epoch 200 ==============================\n"," Train Loss 0.09367 | Val Loss 0.32745 | SMAPE 0.64532\n","\n","[('카페테리아_짜장밥',)] Epoch 50 ==============================\n"," Train Loss 0.15707 | Val Loss 0.24802 | SMAPE 0.49264\n","\n","[('카페테리아_짜장밥',)] Epoch 100 ==============================\n"," Train Loss 0.09252 | Val Loss 0.23741 | SMAPE 0.47433\n","\n","[('카페테리아_짜장밥',)] Epoch 150 ==============================\n"," Train Loss 0.04916 | Val Loss 0.23652 | SMAPE 0.46644\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  84%|████████▍ | 162/193 [1:22:38<15:50, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짜장밥',)] Epoch 200 ==============================\n"," Train Loss 0.03864 | Val Loss 0.23868 | SMAPE 0.47274\n","\n","[('카페테리아_짬뽕',)] Epoch 50 ==============================\n"," Train Loss 0.19696 | Val Loss 0.29785 | SMAPE 0.59849\n","\n","[('카페테리아_짬뽕',)] Epoch 100 ==============================\n"," Train Loss 0.13003 | Val Loss 0.37340 | SMAPE 0.73183\n","\n","[('카페테리아_짬뽕',)] Epoch 150 ==============================\n"," Train Loss 0.09681 | Val Loss 0.33458 | SMAPE 0.65168\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  84%|████████▍ | 163/193 [1:23:08<15:19, 30.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짬뽕',)] Epoch 200 ==============================\n"," Train Loss 0.06583 | Val Loss 0.34433 | SMAPE 0.68162\n","\n","[('카페테리아_짬뽕밥',)] Epoch 50 ==============================\n"," Train Loss 0.17400 | Val Loss 0.30015 | SMAPE 0.59256\n","\n","[('카페테리아_짬뽕밥',)] Epoch 100 ==============================\n"," Train Loss 0.12987 | Val Loss 0.32881 | SMAPE 0.66049\n","\n","[('카페테리아_짬뽕밥',)] Epoch 150 ==============================\n"," Train Loss 0.07352 | Val Loss 0.32344 | SMAPE 0.64483\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  85%|████████▍ | 164/193 [1:23:39<14:49, 30.68s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_짬뽕밥',)] Epoch 200 ==============================\n"," Train Loss 0.05310 | Val Loss 0.33118 | SMAPE 0.65667\n","\n","[('카페테리아_치즈돈까스',)] Epoch 50 ==============================\n"," Train Loss 0.20371 | Val Loss 0.34003 | SMAPE 0.68162\n","\n","[('카페테리아_치즈돈까스',)] Epoch 100 ==============================\n"," Train Loss 0.16306 | Val Loss 0.34395 | SMAPE 0.69272\n","\n","[('카페테리아_치즈돈까스',)] Epoch 150 ==============================\n"," Train Loss 0.13266 | Val Loss 0.37211 | SMAPE 0.75715\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  85%|████████▌ | 165/193 [1:24:10<14:19, 30.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_치즈돈까스',)] Epoch 200 ==============================\n"," Train Loss 0.08044 | Val Loss 0.35818 | SMAPE 0.72691\n","\n","[('카페테리아_카페라떼(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.21817 | Val Loss 0.62370 | SMAPE 1.24345\n","\n","[('카페테리아_카페라떼(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.15222 | Val Loss 0.68063 | SMAPE 1.35923\n","\n","[('카페테리아_카페라떼(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.11930 | Val Loss 0.54470 | SMAPE 1.08817\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  86%|████████▌ | 166/193 [1:24:40<13:47, 30.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_카페라떼(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.07949 | Val Loss 0.60655 | SMAPE 1.21208\n","\n","[('카페테리아_카페라떼(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.24470 | Val Loss 0.76116 | SMAPE 1.51369\n","\n","[('카페테리아_카페라떼(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.19985 | Val Loss 0.82598 | SMAPE 1.64626\n","\n","[('카페테리아_카페라떼(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.11504 | Val Loss 0.87661 | SMAPE 1.74892\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  87%|████████▋ | 167/193 [1:25:11<13:16, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_카페라떼(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.11653 | Val Loss 0.89792 | SMAPE 1.79135\n","\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 50 ==============================\n"," Train Loss 0.16482 | Val Loss 0.36488 | SMAPE 0.72153\n","\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 100 ==============================\n"," Train Loss 0.10382 | Val Loss 0.34615 | SMAPE 0.66357\n","\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 150 ==============================\n"," Train Loss 0.06676 | Val Loss 0.34742 | SMAPE 0.66970\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  87%|████████▋ | 168/193 [1:25:41<12:45, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('카페테리아_한상 삼겹구이 정식(2인) 소요시간 약 15~20분',)] Epoch 200 ==============================\n"," Train Loss 0.05034 | Val Loss 0.35668 | SMAPE 0.69417\n","\n","[('포레스트릿_꼬치어묵',)] Epoch 50 ==============================\n"," Train Loss 0.63711 | Val Loss 0.96174 | SMAPE 1.89377\n","\n","[('포레스트릿_꼬치어묵',)] Epoch 100 ==============================\n"," Train Loss 0.52773 | Val Loss 0.96153 | SMAPE 1.89254\n","\n","[('포레스트릿_꼬치어묵',)] Epoch 150 ==============================\n"," Train Loss 0.53380 | Val Loss 0.95838 | SMAPE 1.88764\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  88%|████████▊ | 169/193 [1:26:12<12:15, 30.66s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_꼬치어묵',)] Epoch 200 ==============================\n"," Train Loss 0.33506 | Val Loss 0.35837 | SMAPE 0.71597\n","\n","[('포레스트릿_떡볶이',)] Epoch 50 ==============================\n"," Train Loss 0.82349 | Val Loss 0.81346 | SMAPE 1.65544\n","\n","[('포레스트릿_떡볶이',)] Epoch 100 ==============================\n"," Train Loss 0.78767 | Val Loss 0.66202 | SMAPE 1.38305\n","\n","[('포레스트릿_떡볶이',)] Epoch 150 ==============================\n"," Train Loss 0.81182 | Val Loss 0.71164 | SMAPE 1.40215\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  88%|████████▊ | 170/193 [1:26:43<11:45, 30.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_떡볶이',)] Epoch 200 ==============================\n"," Train Loss 0.78786 | Val Loss 0.68694 | SMAPE 1.45850\n","\n","[('포레스트릿_복숭아 아이스티',)] Epoch 50 ==============================\n"," Train Loss 0.30150 | Val Loss 0.87604 | SMAPE 1.74575\n","\n","[('포레스트릿_복숭아 아이스티',)] Epoch 100 ==============================\n"," Train Loss 0.24693 | Val Loss 0.90022 | SMAPE 1.79219\n","\n","[('포레스트릿_복숭아 아이스티',)] Epoch 150 ==============================\n"," Train Loss 0.21395 | Val Loss 0.92296 | SMAPE 1.82596\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  89%|████████▊ | 171/193 [1:27:13<11:13, 30.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_복숭아 아이스티',)] Epoch 200 ==============================\n"," Train Loss 0.17458 | Val Loss 0.91448 | SMAPE 1.80793\n","\n","[('포레스트릿_생수',)] Epoch 50 ==============================\n"," Train Loss 0.34390 | Val Loss 0.38995 | SMAPE 0.77515\n","\n","[('포레스트릿_생수',)] Epoch 100 ==============================\n"," Train Loss 0.30591 | Val Loss 0.44428 | SMAPE 0.88417\n","\n","[('포레스트릿_생수',)] Epoch 150 ==============================\n"," Train Loss 0.23741 | Val Loss 0.44981 | SMAPE 0.90470\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  89%|████████▉ | 172/193 [1:27:44<10:42, 30.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_생수',)] Epoch 200 ==============================\n"," Train Loss 0.21360 | Val Loss 0.44371 | SMAPE 0.88748\n","\n","[('포레스트릿_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.28226 | Val Loss 0.36621 | SMAPE 0.72870\n","\n","[('포레스트릿_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.22981 | Val Loss 0.34111 | SMAPE 0.68781\n","\n","[('포레스트릿_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.19420 | Val Loss 0.37398 | SMAPE 0.76421\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  90%|████████▉ | 173/193 [1:28:15<10:12, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.12911 | Val Loss 0.37040 | SMAPE 0.76536\n","\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.25250 | Val Loss 0.35225 | SMAPE 0.70529\n","\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.22356 | Val Loss 0.34764 | SMAPE 0.69050\n","\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.15693 | Val Loss 0.37751 | SMAPE 0.74249\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  90%|█████████ | 174/193 [1:28:45<09:42, 30.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_아메리카노(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.13316 | Val Loss 0.37853 | SMAPE 0.74343\n","\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.25269 | Val Loss 0.36161 | SMAPE 0.72202\n","\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.19147 | Val Loss 0.39184 | SMAPE 0.77936\n","\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.14248 | Val Loss 0.41160 | SMAPE 0.81836\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  91%|█████████ | 175/193 [1:29:16<09:12, 30.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_아메리카노(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.11973 | Val Loss 0.42461 | SMAPE 0.83615\n","\n","[('포레스트릿_치즈 핫도그',)] Epoch 50 ==============================\n"," Train Loss 0.30970 | Val Loss 0.37040 | SMAPE 0.74652\n","\n","[('포레스트릿_치즈 핫도그',)] Epoch 100 ==============================\n"," Train Loss 0.23199 | Val Loss 0.39269 | SMAPE 0.79379\n","\n","[('포레스트릿_치즈 핫도그',)] Epoch 150 ==============================\n"," Train Loss 0.19417 | Val Loss 0.39622 | SMAPE 0.78216\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  91%|█████████ | 176/193 [1:29:47<08:41, 30.67s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_치즈 핫도그',)] Epoch 200 ==============================\n"," Train Loss 0.16851 | Val Loss 0.34256 | SMAPE 0.68092\n","\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 50 ==============================\n"," Train Loss 0.17693 | Val Loss 0.34194 | SMAPE 0.67409\n","\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 100 ==============================\n"," Train Loss 0.12767 | Val Loss 0.33553 | SMAPE 0.67922\n","\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 150 ==============================\n"," Train Loss 0.10163 | Val Loss 0.34291 | SMAPE 0.69152\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  92%|█████████▏| 177/193 [1:30:18<08:11, 30.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_카페라떼(HOT)',)] Epoch 200 ==============================\n"," Train Loss 0.07251 | Val Loss 0.35526 | SMAPE 0.70605\n","\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 50 ==============================\n"," Train Loss 0.19365 | Val Loss 0.35287 | SMAPE 0.68597\n","\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 100 ==============================\n"," Train Loss 0.13793 | Val Loss 0.33978 | SMAPE 0.67217\n","\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 150 ==============================\n"," Train Loss 0.09233 | Val Loss 0.31796 | SMAPE 0.63969\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  92%|█████████▏| 178/193 [1:30:49<07:41, 30.76s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_카페라떼(ICE)',)] Epoch 200 ==============================\n"," Train Loss 0.07228 | Val Loss 0.32037 | SMAPE 0.63486\n","\n","[('포레스트릿_코카콜라',)] Epoch 50 ==============================\n"," Train Loss 0.31871 | Val Loss 0.33079 | SMAPE 0.67977\n","\n","[('포레스트릿_코카콜라',)] Epoch 100 ==============================\n"," Train Loss 0.29854 | Val Loss 0.35692 | SMAPE 0.73120\n","\n","[('포레스트릿_코카콜라',)] Epoch 150 ==============================\n"," Train Loss 0.19822 | Val Loss 0.33562 | SMAPE 0.68872\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  93%|█████████▎| 179/193 [1:31:19<07:11, 30.81s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_코카콜라',)] Epoch 200 ==============================\n"," Train Loss 0.18104 | Val Loss 0.34206 | SMAPE 0.70128\n","\n","[('포레스트릿_페스츄리 소시지',)] Epoch 50 ==============================\n"," Train Loss 0.62757 | Val Loss 0.41807 | SMAPE 0.77421\n","\n","[('포레스트릿_페스츄리 소시지',)] Epoch 100 ==============================\n"," Train Loss 0.53591 | Val Loss 0.25129 | SMAPE 0.49922\n","\n","[('포레스트릿_페스츄리 소시지',)] Epoch 150 ==============================\n"," Train Loss 0.54484 | Val Loss 0.26720 | SMAPE 0.53023\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  93%|█████████▎| 180/193 [1:31:50<06:40, 30.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('포레스트릿_페스츄리 소시지',)] Epoch 200 ==============================\n"," Train Loss 0.54268 | Val Loss 0.26223 | SMAPE 0.52451\n","\n","[('화담숲주막_느린마을 막걸리',)] Epoch 50 ==============================\n"," Train Loss 0.16574 | Val Loss 0.23019 | SMAPE 0.44373\n","\n","[('화담숲주막_느린마을 막걸리',)] Epoch 100 ==============================\n"," Train Loss 0.11918 | Val Loss 0.23177 | SMAPE 0.45302\n","\n","[('화담숲주막_느린마을 막걸리',)] Epoch 150 ==============================\n"," Train Loss 0.09133 | Val Loss 0.25732 | SMAPE 0.50389\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  94%|█████████▍| 181/193 [1:32:21<06:09, 30.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_느린마을 막걸리',)] Epoch 200 ==============================\n"," Train Loss 0.06678 | Val Loss 0.26090 | SMAPE 0.50545\n","\n","[('화담숲주막_단호박 식혜 ',)] Epoch 50 ==============================\n"," Train Loss 0.18102 | Val Loss 0.24010 | SMAPE 0.46927\n","\n","[('화담숲주막_단호박 식혜 ',)] Epoch 100 ==============================\n"," Train Loss 0.15011 | Val Loss 0.22497 | SMAPE 0.43635\n","\n","[('화담숲주막_단호박 식혜 ',)] Epoch 150 ==============================\n"," Train Loss 0.11227 | Val Loss 0.25109 | SMAPE 0.48340\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  94%|█████████▍| 182/193 [1:32:52<05:38, 30.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_단호박 식혜 ',)] Epoch 200 ==============================\n"," Train Loss 0.08418 | Val Loss 0.26898 | SMAPE 0.51853\n","\n","[('화담숲주막_병천순대',)] Epoch 50 ==============================\n"," Train Loss 0.14037 | Val Loss 0.20068 | SMAPE 0.37268\n","\n","[('화담숲주막_병천순대',)] Epoch 100 ==============================\n"," Train Loss 0.10387 | Val Loss 0.19753 | SMAPE 0.37964\n","\n","[('화담숲주막_병천순대',)] Epoch 150 ==============================\n"," Train Loss 0.08003 | Val Loss 0.20023 | SMAPE 0.37812\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  95%|█████████▍| 183/193 [1:33:22<05:06, 30.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_병천순대',)] Epoch 200 ==============================\n"," Train Loss 0.06619 | Val Loss 0.20591 | SMAPE 0.38983\n","\n","[('화담숲주막_스프라이트',)] Epoch 50 ==============================\n"," Train Loss 0.19949 | Val Loss 0.30684 | SMAPE 0.59802\n","\n","[('화담숲주막_스프라이트',)] Epoch 100 ==============================\n"," Train Loss 0.15095 | Val Loss 0.30599 | SMAPE 0.59454\n","\n","[('화담숲주막_스프라이트',)] Epoch 150 ==============================\n"," Train Loss 0.11390 | Val Loss 0.30695 | SMAPE 0.60296\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  95%|█████████▌| 184/193 [1:33:53<04:35, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_스프라이트',)] Epoch 200 ==============================\n"," Train Loss 0.08623 | Val Loss 0.31413 | SMAPE 0.61770\n","\n","[('화담숲주막_참살이 막걸리',)] Epoch 50 ==============================\n"," Train Loss 0.17516 | Val Loss 0.27555 | SMAPE 0.52596\n","\n","[('화담숲주막_참살이 막걸리',)] Epoch 100 ==============================\n"," Train Loss 0.13399 | Val Loss 0.27226 | SMAPE 0.49438\n","\n","[('화담숲주막_참살이 막걸리',)] Epoch 150 ==============================\n"," Train Loss 0.10858 | Val Loss 0.28720 | SMAPE 0.54753\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  96%|█████████▌| 185/193 [1:34:23<04:05, 30.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_참살이 막걸리',)] Epoch 200 ==============================\n"," Train Loss 0.07963 | Val Loss 0.30286 | SMAPE 0.57609\n","\n","[('화담숲주막_찹쌀식혜',)] Epoch 50 ==============================\n"," Train Loss 0.18829 | Val Loss 0.28146 | SMAPE 0.55909\n","\n","[('화담숲주막_찹쌀식혜',)] Epoch 100 ==============================\n"," Train Loss 0.14477 | Val Loss 0.27940 | SMAPE 0.54643\n","\n","[('화담숲주막_찹쌀식혜',)] Epoch 150 ==============================\n"," Train Loss 0.11705 | Val Loss 0.29040 | SMAPE 0.57542\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  96%|█████████▋| 186/193 [1:34:54<03:34, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_찹쌀식혜',)] Epoch 200 ==============================\n"," Train Loss 0.08651 | Val Loss 0.30938 | SMAPE 0.59018\n","\n","[('화담숲주막_콜라',)] Epoch 50 ==============================\n"," Train Loss 0.20299 | Val Loss 0.30730 | SMAPE 0.59888\n","\n","[('화담숲주막_콜라',)] Epoch 100 ==============================\n"," Train Loss 0.17671 | Val Loss 0.29339 | SMAPE 0.57479\n","\n","[('화담숲주막_콜라',)] Epoch 150 ==============================\n"," Train Loss 0.13306 | Val Loss 0.30330 | SMAPE 0.60165\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  97%|█████████▋| 187/193 [1:35:25<03:03, 30.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_콜라',)] Epoch 200 ==============================\n"," Train Loss 0.10325 | Val Loss 0.30263 | SMAPE 0.59178\n","\n","[('화담숲주막_해물파전',)] Epoch 50 ==============================\n"," Train Loss 0.12076 | Val Loss 0.18601 | SMAPE 0.35288\n","\n","[('화담숲주막_해물파전',)] Epoch 100 ==============================\n"," Train Loss 0.08666 | Val Loss 0.19366 | SMAPE 0.36339\n","\n","[('화담숲주막_해물파전',)] Epoch 150 ==============================\n"," Train Loss 0.06876 | Val Loss 0.21068 | SMAPE 0.39549\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  97%|█████████▋| 188/193 [1:35:55<02:33, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲주막_해물파전',)] Epoch 200 ==============================\n"," Train Loss 0.05360 | Val Loss 0.20477 | SMAPE 0.39117\n","\n","[('화담숲카페_메밀미숫가루',)] Epoch 50 ==============================\n"," Train Loss 0.20545 | Val Loss 0.28990 | SMAPE 0.54073\n","\n","[('화담숲카페_메밀미숫가루',)] Epoch 100 ==============================\n"," Train Loss 0.16970 | Val Loss 0.32698 | SMAPE 0.63266\n","\n","[('화담숲카페_메밀미숫가루',)] Epoch 150 ==============================\n"," Train Loss 0.13276 | Val Loss 0.33263 | SMAPE 0.65490\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  98%|█████████▊| 189/193 [1:36:26<02:02, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_메밀미숫가루',)] Epoch 200 ==============================\n"," Train Loss 0.09869 | Val Loss 0.38241 | SMAPE 0.73679\n","\n","[('화담숲카페_아메리카노 HOT',)] Epoch 50 ==============================\n"," Train Loss 0.17622 | Val Loss 0.26169 | SMAPE 0.49821\n","\n","[('화담숲카페_아메리카노 HOT',)] Epoch 100 ==============================\n"," Train Loss 0.13425 | Val Loss 0.27782 | SMAPE 0.52208\n","\n","[('화담숲카페_아메리카노 HOT',)] Epoch 150 ==============================\n"," Train Loss 0.09046 | Val Loss 0.28974 | SMAPE 0.54952\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  98%|█████████▊| 190/193 [1:36:56<01:31, 30.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_아메리카노 HOT',)] Epoch 200 ==============================\n"," Train Loss 0.06933 | Val Loss 0.28690 | SMAPE 0.54425\n","\n","[('화담숲카페_아메리카노 ICE',)] Epoch 50 ==============================\n"," Train Loss 0.21392 | Val Loss 0.35895 | SMAPE 0.69870\n","\n","[('화담숲카페_아메리카노 ICE',)] Epoch 100 ==============================\n"," Train Loss 0.17891 | Val Loss 0.38201 | SMAPE 0.72845\n","\n","[('화담숲카페_아메리카노 ICE',)] Epoch 150 ==============================\n"," Train Loss 0.15191 | Val Loss 0.40057 | SMAPE 0.75954\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  99%|█████████▉| 191/193 [1:37:27<01:01, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_아메리카노 ICE',)] Epoch 200 ==============================\n"," Train Loss 0.11196 | Val Loss 0.43326 | SMAPE 0.82414\n","\n","[('화담숲카페_카페라떼 ICE',)] Epoch 50 ==============================\n"," Train Loss 0.21116 | Val Loss 0.30821 | SMAPE 0.56953\n","\n","[('화담숲카페_카페라떼 ICE',)] Epoch 100 ==============================\n"," Train Loss 0.15286 | Val Loss 0.35072 | SMAPE 0.64308\n","\n","[('화담숲카페_카페라떼 ICE',)] Epoch 150 ==============================\n"," Train Loss 0.10483 | Val Loss 0.35534 | SMAPE 0.65074\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining LSTM:  99%|█████████▉| 192/193 [1:37:58<00:30, 30.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_카페라떼 ICE',)] Epoch 200 ==============================\n"," Train Loss 0.06501 | Val Loss 0.36554 | SMAPE 0.68005\n","\n","[('화담숲카페_현미뻥스크림',)] Epoch 50 ==============================\n"," Train Loss 0.20693 | Val Loss 0.36448 | SMAPE 0.70820\n","\n","[('화담숲카페_현미뻥스크림',)] Epoch 100 ==============================\n"," Train Loss 0.16410 | Val Loss 0.36835 | SMAPE 0.70345\n","\n","[('화담숲카페_현미뻥스크림',)] Epoch 150 ==============================\n"," Train Loss 0.11104 | Val Loss 0.41156 | SMAPE 0.79342\n"]},{"output_type":"stream","name":"stderr","text":["Training LSTM: 100%|██████████| 193/193 [1:38:28<00:00, 30.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","[('화담숲카페_현미뻥스크림',)] Epoch 200 ==============================\n"," Train Loss 0.08389 | Val Loss 0.40751 | SMAPE 0.78084\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# 데이터 준비\n","features = cols + [\"매출수량\", \"영업일자\", \"영업장명_메뉴명\"]\n","dataset_lstm = data[features]\n","\n","losses = [WeightedSMAPELoss(eps = 1e-8), WeightedHuberLoss(delta = 1.0, zeros = False, eps = 1e-8)]\n","loss_weights = [0.5, 0.5]\n","lstm = LSTMModel(lookback = 28, hidden_dim = 256, num_layers = 4, predict = 7, dropout = 0.3)\n","\n","lookback, predict, batch_size, epochs = 28, 7, 16, 200\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","trained_lstm = lstm.train_lstm(train_df = dataset_lstm, cols = cols, enc_cols = enc_cols, num_cols = num_cols,\n","                               device = device, epochs = epochs, batch_size = batch_size, lr = 1e-3, dropout = 0.4,\n","                               losses = losses, loss_weights = loss_weights, n_splits = 3, print_every = 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTfohyADnb1P"},"outputs":[],"source":["model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 7/lstm_models_gpu.pkl'\n","lstm.save_lstm_model_gpu(trained_lstm, model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUZFsOC5p1sp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755284778576,"user_tz":-540,"elapsed":5364,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"546eaa22-f281-48e5-fc09-5b5662acc48c"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU 버전 모델 저장 완료!\n"]}],"source":["model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 7/lstm_models_cpu.pkl'\n","lstm.save_lstm_model_cpu(trained_lstm, model_path)"]},{"cell_type":"markdown","metadata":{"id":"Qqtu8A59P6Kg"},"source":["#### 예측하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJpzrc5WYXsZ"},"outputs":[],"source":["# 저장된 모델 로드 - CPU\n","lookback, predict, batch_size, epochs = 28, 7, 16, 200\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 6/lstm_models_cpu.pkl'\n","lstm = LSTMModel(lookback = 28, predict = 7)\n","trained_lstm = lstm.load_saved_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzm7n6SEP7lB"},"outputs":[],"source":["class PredictionFunctions():\n","    def __init__(self, test_df = None, trained_models = None, test_prefix = None, cols = None, enc_cols = None, lookback = 28, predict = 7):\n","        self.test_df = test_df\n","        self.trained_models = trained_models\n","        self.test_prefix = test_prefix\n","        self.cols = cols\n","        self.enc_cols = enc_cols\n","        self.lookback = lookback\n","        self.predict = predict\n","\n","    def predict_class(self, test_df, trained_models, test_prefix : str, cols : list, enc_cols : list, lookback = 28, predict = 7):\n","        \"\"\"\n","        Input : test_df - test data, trained_models - list(menu : {model, encoder}), cols - x 변수들\n","        Output : [영업일자, 영업장명_메뉴명, 매출여부] DataFrame\n","        \"\"\"\n","        results = []\n","\n","        for store_menu_tup, store_test in test_df.groupby(['영업장명_메뉴명']):\n","            store_menu = store_menu_tup[0]\n","            # 훈련된 모델에 메뉴가 있는 경우만 진행\n","            if store_menu not in trained_models:\n","                continue\n","\n","            # 모델 불러오기\n","            model = trained_models[store_menu][\"model\"]\n","            encoder = trained_models[store_menu][\"encoder\"]\n","            threshold = trained_models[store_menu].get(\"threshold\", 0.5)\n","\n","            # 변수 추가하기\n","            mv = Make_Variables()\n","            store_test['영업일자'] = pd.to_datetime(store_test['영업일자'])\n","            store_test_sorted = store_test.sort_values('영업일자')\n","            last_date = store_test_sorted['영업일자'].iloc[-1]\n","\n","            future_df = mv.make_variables_test(date = last_date, test_df = store_test, predict = 7)\n","            encoded = encoder.transform(future_df[enc_cols])\n","            encoded_df = pd.DataFrame(encoded, columns = enc_cols, index = future_df.index)\n","            future_df[enc_cols] = encoded_df\n","            x = future_df[cols]\n","\n","            if hasattr(model, \"classes_\"):\n","                pos_idx = int(np.where(model.classes_ == 1)[0][0])\n","            else:\n","                pos_idx = 1\n","\n","            proba = model.predict_proba(x)[:, pos_idx]\n","            y_hat = (proba >= threshold).astype(int)\n","\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, y_hat):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출여부': val\n","                })\n","\n","        return pd.DataFrame(results)\n","\n","    def predict_reg(self, test_df, trained_models, test_prefix : str, cols : list, enc_cols : list, lookback = 28, predict = 7):\n","        \"\"\"\n","        Input : test_df - test data, trained_models - list(menu : {model, encoder}), cols - x 변수들\n","        Output : [영업일자, 영업장명_메뉴명, 매출수량] DataFrame\n","        \"\"\"\n","        results = []\n","\n","        for store_menu_tup, store_test in test_df.groupby(['영업장명_메뉴명']):\n","            store_menu = store_menu_tup[0]\n","            # 훈련된 모델에 메뉴가 있는 경우만 진행\n","            if store_menu not in trained_models:\n","                continue\n","\n","            # 모델 불러오기\n","            model = trained_models[store_menu][\"model\"]\n","            encoder = trained_models[store_menu][\"encoder\"]\n","\n","            # 변수 추가하기\n","            mv = Make_Variables()\n","            store_test['영업일자'] = pd.to_datetime(store_test['영업일자'])\n","            store_test_sorted = store_test.sort_values('영업일자')\n","            last_date = store_test_sorted['영업일자'].iloc[-1]\n","\n","            future_df = mv.make_variables_test(date = last_date, test_df = store_test, predict = 7)\n","            encoded = encoder.transform(future_df[enc_cols])\n","            encoded_df = pd.DataFrame(encoded, columns = enc_cols, index = future_df.index)\n","            future_df[enc_cols] = encoded_df\n","            future_df = future_df[cols]\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, model.predict(future_df)):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출수량': val\n","                })\n","\n","        return pd.DataFrame(results)\n","\n","    def predict_lstm(self, test_df, trained_models, test_prefix : str, cols : list, enc_cols : list, num_cols : list, lookback = 28, predict = 7, device = None):\n","        \"\"\"\n","        Input : test_df - test data, trained_models - list(menu : { model}), cols - x 변수들\n","        Output : [영업일자, 영업장명_메뉴명, 매출수량] DataFrame\n","        \"\"\"\n","\n","        if device is None:\n","            device = getattr(self, \"device\", \"cpu\")\n","        device = torch.device(device)\n","\n","        results = []\n","\n","        # 매장, 메뉴별로 그룹화해서 예측\n","        for store_menu, store_test in test_df.groupby(['영업장명_메뉴명']):\n","            # 훈련된 모델에 메뉴가 있는 경우만 진행\n","            if store_menu not in trained_models:\n","                continue\n","\n","            # 모델, scaler 불러오기\n","            state = trained_models[store_menu]['model']\n","            meta = trained_models[store_menu]['meta']\n","            encoders = trained_models[store_menu]['encoders']\n","            features_scaler = trained_models[store_menu]['features_scaler']\n","            target_scaler = trained_models[store_menu]['target_scaler']\n","\n","            # LSTM 모델 생성\n","            model = MultiOutputLSTM(\n","                input_dim=meta['input_dim'],\n","                hidden_dim=meta['hidden_dim'],\n","                num_layers=meta['num_layers'],\n","                output_dim=meta['output_dim']\n","            )\n","\n","            model.load_state_dict(state)\n","            model = model.to(device).eval()\n","\n","            # LSTM 입력으로 활용할 최근 lookback 만큼의 데이터 가져오기\n","            mv = Make_Variables()\n","            store_test = store_test.sort_values('영업일자')\n","            store_test = mv.make_variables_train(data = store_test)\n","            store_test_sorted = store_test.sort_values('영업일자')\n","\n","            features = cols + [\"매출수량\"]\n","            if len(store_test_sorted) < lookback:\n","                continue\n","\n","            recent_df = store_test_sorted[features].iloc[-lookback:].copy()\n","            if len(recent_df) < lookback:\n","                continue # lookback 만큼의 데이터가 없으면 예측 안 하고 넘어가기\n","\n","            ##### 요기서 변수 추가\n","            last_date = store_test_sorted['영업일자'].iloc[-1]\n","            recent_df_for_mv = store_test_sorted[features + ['영업장명_메뉴명', '영업일자']].iloc[-lookback:].copy()\n","            future_df = mv.make_variables_test(date = last_date, test_df = recent_df_for_mv, predict = 7)\n","            future_df['매출수량'] = 0.0\n","            full_df = pd.concat([recent_df, future_df[features]], axis = 0)\n","\n","            # enc_cols 정규화\n","            for col in enc_cols:\n","                if col not in full_df.columns:\n","                    continue\n","                if col in encoders:\n","                    le = encoders[col]\n","                    full_df[col] = le.transform(full_df[col].astype(str)) ##### str로 바꿔봄...\n","                else:\n","                    full_df[col] = full_df[col].astype(int)\n","\n","            # num_cols 스케일링\n","            full_df[num_cols] = features_scaler.transform(full_df[num_cols])\n","\n","            x_input_vals = full_df[cols].values\n","            x_input = x_input_vals[:lookback]\n","            x_input = torch.tensor([x_input]).float().to(device)\n","\n","            # 예측 수행\n","            with torch.no_grad():\n","                pred_scaled = model(x_input).squeeze().cpu().numpy()\n","\n","            # 역정규화\n","            restored = []\n","            for i in range(predict):\n","                dummy = np.zeros((1, len(features)))\n","                dummy[0, features.index(\"매출수량\")] = pred_scaled[i]\n","                restored_val = target_scaler.inverse_transform(dummy)[0, features.index(\"매출수량\")]\n","                restored.append(max(restored_val, 0)) # 음수 나오면 0으로 처리\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, restored):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출수량(lstm)': val\n","                })\n","\n","        return pd.DataFrame(results)"]},{"cell_type":"code","source":["    def predict_reg_model(self, test_df, trained_model, test_prefix : str, cols : list, enc_cols : list, data, lookback = 28, predict = 7):\n","        \"\"\"\n","        Input : test_df - test data, trained_model - {~~}, original_data : train할 때 사용한 데이터 (data)\n","        Output : [영업일자, 영업장명_메뉴명, 매출수량] DataFrame\n","        \"\"\"\n","        results = []\n","\n","        # 모델 불러오기\n","        model = trained_model[\"model\"]\n","        encoder = trained_model[\"encoder\"]\n","\n","        # 변수 추가하기\n","        mv = Make_Variables()\n","\n","        for store_menu, store_df in test_df.groupby(['영업장명_메뉴명']):\n","\n","            store_df['영업일자'] = pd.to_datetime(store_df['영업일자'])\n","            store_df_sorted = store_df.sort_values('영업일자')\n","            last_date = store_df_sorted['영업일자'].iloc[-1]\n","\n","            future_df = mv.make_variables_test(date = last_date, test_df = store_df, original_data = data, predict = 7)\n","            if enc_cols:\n","                future_df[enc_cols] = encoder.transform(future_df[enc_cols])\n","\n","            # 사용할 변수만\n","            future_df = future_df[cols]\n","\n","            # 로그 변환 처리\n","            predicted = model.predict(future_df)\n","\n","            # 예측일자: TEST_00+1일 ~ TEST_00+7일\n","            pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(predict)]\n","\n","            for d, val in zip(pred_dates, predicted):\n","                results.append({\n","                    '영업일자': d,\n","                    '영업장명_메뉴명': store_menu,\n","                    '매출수량': val\n","                })\n","\n","        return pd.DataFrame(results)"],"metadata":{"id":"pvTKEKEB0Aca"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PnTZIj8uXAdw"},"source":["#### 예측값 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"eP7il3f1stSF","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1755319070068,"user_tz":-540,"elapsed":985,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"2122e872-32ad-403a-ee56-7edb07f1f055"},"outputs":[{"output_type":"stream","name":"stdout","text":["==================\n","         영업일자            영업장명_메뉴명  매출수량\n","0  2024-06-16  느티나무 셀프BBQ_1인 수저세트     2\n","1  2024-06-17  느티나무 셀프BBQ_1인 수저세트     0\n","2  2024-06-18  느티나무 셀프BBQ_1인 수저세트     0\n","3  2024-06-19  느티나무 셀프BBQ_1인 수저세트     0\n","4  2024-06-20  느티나무 셀프BBQ_1인 수저세트     4\n","==================\n","==================\n","          영업일자              영업장명_메뉴명  매출수량\n","28  2024-06-16  느티나무 셀프BBQ_BBQ55(단체)     0\n","29  2024-06-17  느티나무 셀프BBQ_BBQ55(단체)     0\n","30  2024-06-18  느티나무 셀프BBQ_BBQ55(단체)     0\n","31  2024-06-19  느티나무 셀프BBQ_BBQ55(단체)    67\n","32  2024-06-20  느티나무 셀프BBQ_BBQ55(단체)   124\n","==================\n","==================\n","          영업일자                영업장명_메뉴명  매출수량\n","56  2024-06-16  느티나무 셀프BBQ_대여료 30,000원     5\n","57  2024-06-17  느티나무 셀프BBQ_대여료 30,000원     0\n","58  2024-06-18  느티나무 셀프BBQ_대여료 30,000원     2\n","59  2024-06-19  느티나무 셀프BBQ_대여료 30,000원     1\n","60  2024-06-20  느티나무 셀프BBQ_대여료 30,000원     0\n","==================\n","==================\n","          영업일자                영업장명_메뉴명  매출수량\n","84  2024-06-16  느티나무 셀프BBQ_대여료 60,000원     3\n","85  2024-06-17  느티나무 셀프BBQ_대여료 60,000원     0\n","86  2024-06-18  느티나무 셀프BBQ_대여료 60,000원     0\n","87  2024-06-19  느티나무 셀프BBQ_대여료 60,000원     0\n","88  2024-06-20  느티나무 셀프BBQ_대여료 60,000원     0\n","==================\n","==================\n","           영업일자                영업장명_메뉴명  매출수량\n","112  2024-06-16  느티나무 셀프BBQ_대여료 90,000원     0\n","113  2024-06-17  느티나무 셀프BBQ_대여료 90,000원     0\n","114  2024-06-18  느티나무 셀프BBQ_대여료 90,000원     0\n","115  2024-06-19  느티나무 셀프BBQ_대여료 90,000원     0\n","116  2024-06-20  느티나무 셀프BBQ_대여료 90,000원     0\n","==================\n","==================\n","           영업일자                영업장명_메뉴명  매출수량\n","140  2024-06-16  느티나무 셀프BBQ_본삼겹 (단품,실내)     0\n","141  2024-06-17  느티나무 셀프BBQ_본삼겹 (단품,실내)     0\n","142  2024-06-18  느티나무 셀프BBQ_본삼겹 (단품,실내)     0\n","143  2024-06-19  느티나무 셀프BBQ_본삼겹 (단품,실내)     2\n","144  2024-06-20  느티나무 셀프BBQ_본삼겹 (단품,실내)     0\n","==================\n","==================\n","           영업일자               영업장명_메뉴명  매출수량\n","168  2024-06-16  느티나무 셀프BBQ_스프라이트 (단체)     0\n","169  2024-06-17  느티나무 셀프BBQ_스프라이트 (단체)     0\n","170  2024-06-18  느티나무 셀프BBQ_스프라이트 (단체)     2\n","171  2024-06-19  느티나무 셀프BBQ_스프라이트 (단체)    33\n","172  2024-06-20  느티나무 셀프BBQ_스프라이트 (단체)    48\n","==================\n","==================\n","           영업일자        영업장명_메뉴명  매출수량\n","196  2024-06-16  느티나무 셀프BBQ_신라면     1\n","197  2024-06-17  느티나무 셀프BBQ_신라면     0\n","198  2024-06-18  느티나무 셀프BBQ_신라면     0\n","199  2024-06-19  느티나무 셀프BBQ_신라면     0\n","200  2024-06-20  느티나무 셀프BBQ_신라면     2\n","==================\n","==================\n","           영업일자          영업장명_메뉴명  매출수량\n","224  2024-06-16  느티나무 셀프BBQ_쌈야채세트     1\n","225  2024-06-17  느티나무 셀프BBQ_쌈야채세트     0\n","226  2024-06-18  느티나무 셀프BBQ_쌈야채세트     0\n","227  2024-06-19  느티나무 셀프BBQ_쌈야채세트     1\n","228  2024-06-20  느티나무 셀프BBQ_쌈야채세트     3\n","==================\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3606758613.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# lstm 넣고\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpred_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mall_preds_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2802518163.py\u001b[0m in \u001b[0;36mpredict_lstm\u001b[0;34m(self, test_df, trained_models, test_prefix, cols, enc_cols, num_cols, lookback, predict, device)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mstore_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_variables_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mstore_test_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'영업일자'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1607822789.py\u001b[0m in \u001b[0;36mmake_variables_train\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'영업일자'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mmenu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'영업장명_메뉴명'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prev_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmenu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmenu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhowmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prev_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmenu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmenu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhowmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prev_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmenu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmenu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhowmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1607822789.py\u001b[0m in \u001b[0;36mget_prev_days\u001b[0;34m(self, data, test_df, date, menu, howmany)\u001b[0m\n\u001b[1;32m    120\u001b[0m                         \u001b[0mprev_sd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mweek_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mcurr_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'영업일자'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'영업일자'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mweek_end\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'영업장명_메뉴명'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmenu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                     \u001b[0mcolname_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"prev_avg_{howmany}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0mcolname_sd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"prev_sd_{howmany}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6117\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6119\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import re\n","all_preds_class = []\n","all_preds_reg = []\n","all_preds_lstm = []\n","\n","# 모든 test_*.csv 순회\n","test_files = sorted(glob.glob('DATA/test/TEST_*.csv'))\n","predictions = PredictionFunctions()\n","\n","for path in test_files:\n","    test_df = pd.read_csv(path)\n","\n","    # 파일명에서 접두어 추출 (예: TEST_00)\n","    filename = os.path.basename(path)\n","    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n","\n","    # lstm 넣고\n","    pred_lstm = predictions.predict_lstm(test_df, trained_lstm, test_prefix, cols, enc_cols, num_cols, device = 'cpu')\n","    all_preds_lstm.append(pred_lstm)\n","\n","df_lstm  = pd.concat(all_preds_lstm, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1755177209162,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"VxHGu172_DMW","outputId":"7163ceb2-cb1f-4721-9df9-e60affd02abc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["13510"]},"metadata":{},"execution_count":22}],"source":["len(df_lstm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Au8Nlw1HXCVN","executionInfo":{"status":"ok","timestamp":1755322735022,"user_tz":-540,"elapsed":378029,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"dc57ec3d-4500-42c7-decc-6491b2515c34"},"outputs":[{"output_type":"stream","name":"stdout","text":["예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n","예측 완료 !\n"]}],"source":["import re\n","all_preds_class = []\n","all_preds_reg = []\n","all_preds_lstm = []\n","\n","\n","# 모든 test_*.csv 순회\n","test_files = sorted(glob.glob('DATA/test/TEST_*.csv'))\n","predictions = PredictionFunctions()\n","\n","for path in test_files:\n","    test_df = pd.read_csv(path)\n","\n","    # 파일명에서 접두어 추출 (예: TEST_00)\n","    filename = os.path.basename(path)\n","    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n","\n","    # 일단 분류 모델 넣고\n","    pred_class = predictions.predict_class(test_df, models_class, test_prefix, cols, enc_cols)\n","    all_preds_class.append(pred_class)\n","\n","    # 1 나오면 회귀 모델 넣고\n","    pred_reg = predictions.predict_reg(test_df, models_reg, test_prefix, cols, enc_cols)\n","    all_preds_reg.append(pred_reg)\n","\n","    # lstm 넣고\n","    pred_lstm = predictions.predict_lstm(test_df, trained_lstm, test_prefix, cols, enc_cols, num_cols)\n","    all_preds_lstm.append(pred_lstm)\n","\n","    print(\"예측 완료 !\")\n","\n","    # 합치기 (가중치.. 일단은 1.5 / 8.5 정도....)\n","\n","df_class = pd.concat(all_preds_class, ignore_index = True)\n","df_reg   = pd.concat(all_preds_reg, ignore_index = True)\n","df_lstm  = pd.concat(all_preds_lstm, ignore_index = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":74,"status":"ok","timestamp":1755322740067,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"Qz2PdvvhDu3J","outputId":"0c893796-ba12-400e-dae8-3f85f600d46d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         영업일자                영업장명_메뉴명  매출수량(lstm)  매출여부  매출수량(reg)\n","0  TEST_00+1일      느티나무 셀프BBQ_1인 수저세트    8.494163     1  10.307570\n","1  TEST_00+1일    느티나무 셀프BBQ_BBQ55(단체)   57.814996     0  75.361053\n","2  TEST_00+1일  느티나무 셀프BBQ_대여료 30,000원    7.369763     1  10.134176\n","3  TEST_00+1일  느티나무 셀프BBQ_대여료 60,000원    1.446719     1   1.488075\n","4  TEST_00+1일  느티나무 셀프BBQ_대여료 90,000원    0.937538     1   1.748883"],"text/html":["\n","  <div id=\"df-58f171ca-e40c-47e6-898e-a6e97e8f80c7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>영업일자</th>\n","      <th>영업장명_메뉴명</th>\n","      <th>매출수량(lstm)</th>\n","      <th>매출여부</th>\n","      <th>매출수량(reg)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_1인 수저세트</td>\n","      <td>8.494163</td>\n","      <td>1</td>\n","      <td>10.307570</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_BBQ55(단체)</td>\n","      <td>57.814996</td>\n","      <td>0</td>\n","      <td>75.361053</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 30,000원</td>\n","      <td>7.369763</td>\n","      <td>1</td>\n","      <td>10.134176</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 60,000원</td>\n","      <td>1.446719</td>\n","      <td>1</td>\n","      <td>1.488075</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 90,000원</td>\n","      <td>0.937538</td>\n","      <td>1</td>\n","      <td>1.748883</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58f171ca-e40c-47e6-898e-a6e97e8f80c7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-58f171ca-e40c-47e6-898e-a6e97e8f80c7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-58f171ca-e40c-47e6-898e-a6e97e8f80c7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-cefd319c-2215-4c46-ad0f-974b0fdfa148\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cefd319c-2215-4c46-ad0f-974b0fdfa148')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-cefd319c-2215-4c46-ad0f-974b0fdfa148 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"full_pred_df","summary":"{\n  \"name\": \"full_pred_df\",\n  \"rows\": 13510,\n  \"fields\": [\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc77c\\uc790\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"TEST_03+2\\uc77c\",\n          \"TEST_00+1\\uc77c\",\n          \"TEST_07+1\\uc77c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc7a5\\uba85_\\uba54\\ub274\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"\\ub2f4\\ud558_\\uba54\\ubc00\\uba74 \\uc0ac\\ub9ac\",\n          \"\\uc5f0\\ud68c\\uc7a5_\\ub9c8\\ub77c\\uc0f9\\uad88\",\n          \"\\ub77c\\uadf8\\ub85c\\ud0c0_\\uc2a4\\ud504\\ub77c\\uc774\\ud2b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9(lstm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.805157139838784,\n        \"min\": 0.0,\n        \"max\": 803.3971828222275,\n        \"num_unique_values\": 13426,\n        \"samples\": [\n          3.0374310426414013,\n          1.9062741100788116,\n          48.315315432846546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9(reg)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 13402,\n        \"samples\": [\n          19.20209312438965,\n          4.361409664154053\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":85}],"source":["full_pred_df = pd.merge(df_class, df_reg, on=['영업일자', '영업장명_메뉴명'], how='outer')\n","full_pred_df.rename(columns={'매출수량': '매출수량(reg)'}, inplace=True)\n","\n","df_lstm_plz = df_lstm.copy()\n","df_lstm_plz['영업장명_메뉴명'] = df_lstm['영업장명_메뉴명'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n","\n","full_pred_df = pd.merge(df_lstm_plz, full_pred_df, on=['영업일자', '영업장명_메뉴명'], how='outer')\n","full_pred_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1755322742540,"user":{"displayName":"박준희","userId":"01167826914931997240"},"user_tz":-540},"id":"IZ5UFb0GD6B3","outputId":"7649281e-6a2b-4090-daa1-310e17c2896c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             영업일자                영업장명_메뉴명        매출수량\n","0      TEST_00+1일      느티나무 셀프BBQ_1인 수저세트    9.038186\n","1      TEST_00+1일    느티나무 셀프BBQ_BBQ55(단체)   57.814996\n","2      TEST_00+1일  느티나무 셀프BBQ_대여료 30,000원    8.199087\n","3      TEST_00+1일  느티나무 셀프BBQ_대여료 60,000원    1.459126\n","4      TEST_00+1일  느티나무 셀프BBQ_대여료 90,000원    1.180942\n","...           ...                     ...         ...\n","13505  TEST_09+7일            화담숲카페_메밀미숫가루   52.605764\n","13506  TEST_09+7일         화담숲카페_아메리카노 HOT   33.743139\n","13507  TEST_09+7일         화담숲카페_아메리카노 ICE  101.176566\n","13508  TEST_09+7일          화담숲카페_카페라떼 ICE   22.974551\n","13509  TEST_09+7일            화담숲카페_현미뻥스크림   38.261448\n","\n","[13510 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-ad2a2632-d99f-4139-ac61-725e73b1606f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>영업일자</th>\n","      <th>영업장명_메뉴명</th>\n","      <th>매출수량</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_1인 수저세트</td>\n","      <td>9.038186</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_BBQ55(단체)</td>\n","      <td>57.814996</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 30,000원</td>\n","      <td>8.199087</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 60,000원</td>\n","      <td>1.459126</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 90,000원</td>\n","      <td>1.180942</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13505</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_메밀미숫가루</td>\n","      <td>52.605764</td>\n","    </tr>\n","    <tr>\n","      <th>13506</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_아메리카노 HOT</td>\n","      <td>33.743139</td>\n","    </tr>\n","    <tr>\n","      <th>13507</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_아메리카노 ICE</td>\n","      <td>101.176566</td>\n","    </tr>\n","    <tr>\n","      <th>13508</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_카페라떼 ICE</td>\n","      <td>22.974551</td>\n","    </tr>\n","    <tr>\n","      <th>13509</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_현미뻥스크림</td>\n","      <td>38.261448</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13510 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad2a2632-d99f-4139-ac61-725e73b1606f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ad2a2632-d99f-4139-ac61-725e73b1606f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ad2a2632-d99f-4139-ac61-725e73b1606f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-8abd3920-27b7-45c9-85f9-8e9a6bfa7b4c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8abd3920-27b7-45c9-85f9-8e9a6bfa7b4c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-8abd3920-27b7-45c9-85f9-8e9a6bfa7b4c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_d8ff8815-75d6-47f5-b21c-c620c7aad352\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('full_pred_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_d8ff8815-75d6-47f5-b21c-c620c7aad352 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('full_pred_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"full_pred_df","summary":"{\n  \"name\": \"full_pred_df\",\n  \"rows\": 13510,\n  \"fields\": [\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc77c\\uc790\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"TEST_03+2\\uc77c\",\n          \"TEST_00+1\\uc77c\",\n          \"TEST_07+1\\uc77c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc7a5\\uba85_\\uba54\\ub274\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"\\ub2f4\\ud558_\\uba54\\ubc00\\uba74 \\uc0ac\\ub9ac\",\n          \"\\uc5f0\\ud68c\\uc7a5_\\ub9c8\\ub77c\\uc0f9\\uad88\",\n          \"\\ub77c\\uadf8\\ub85c\\ud0c0_\\uc2a4\\ud504\\ub77c\\uc774\\ud2b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.71599020825849,\n        \"min\": 0.0,\n        \"max\": 731.48886936903,\n        \"num_unique_values\": 13438,\n        \"samples\": [\n          15.515633337199688,\n          15.740871369838715,\n          17.825346095114945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":86}],"source":["full_pred_df['매출수량'] = np.where(\n","    full_pred_df['매출여부'] == 1,\n","    full_pred_df['매출수량(reg)'] * 0.3 + full_pred_df['매출수량(lstm)'] * 0.7,\n","    full_pred_df['매출수량(lstm)']\n",")\n","\n","full_pred_df.drop(columns=['매출여부', '매출수량(reg)', '매출수량(lstm)'], inplace=True)\n","full_pred_df"]},{"cell_type":"code","source":["full_pred_df['매출수량'] = np.where(\n","    full_pred_df['매출여부'] == 1,\n","    full_pred_df['매출수량(reg)'] * 0.4 + full_pred_df['매출수량(lstm)'] * 0.6,\n","    full_pred_df['매출수량(lstm)']\n",")\n","\n","full_pred_df.drop(columns=['매출여부', '매출수량(reg)', '매출수량(lstm)'], inplace=True)\n","full_pred_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"k55pQ1WePFc9","executionInfo":{"status":"ok","timestamp":1755320684271,"user_tz":-540,"elapsed":43,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"1dc3b906-7a53-43fe-f95e-19e1eb2533a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             영업일자                영업장명_메뉴명       매출수량\n","0      TEST_00+1일      느티나무 셀프BBQ_1인 수저세트   7.233946\n","1      TEST_00+1일    느티나무 셀프BBQ_BBQ55(단체)  75.649501\n","2      TEST_00+1일  느티나무 셀프BBQ_대여료 30,000원   8.881719\n","3      TEST_00+1일  느티나무 셀프BBQ_대여료 60,000원   1.487016\n","4      TEST_00+1일  느티나무 셀프BBQ_대여료 90,000원   1.289370\n","...           ...                     ...        ...\n","13505  TEST_09+7일            화담숲카페_메밀미숫가루  49.772997\n","13506  TEST_09+7일         화담숲카페_아메리카노 HOT  27.679980\n","13507  TEST_09+7일         화담숲카페_아메리카노 ICE  92.439979\n","13508  TEST_09+7일          화담숲카페_카페라떼 ICE  25.499672\n","13509  TEST_09+7일            화담숲카페_현미뻥스크림  50.439278\n","\n","[13510 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-00214f97-61c6-42d3-9896-9cc5871f244c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>영업일자</th>\n","      <th>영업장명_메뉴명</th>\n","      <th>매출수량</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_1인 수저세트</td>\n","      <td>7.233946</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_BBQ55(단체)</td>\n","      <td>75.649501</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 30,000원</td>\n","      <td>8.881719</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 60,000원</td>\n","      <td>1.487016</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_00+1일</td>\n","      <td>느티나무 셀프BBQ_대여료 90,000원</td>\n","      <td>1.289370</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13505</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_메밀미숫가루</td>\n","      <td>49.772997</td>\n","    </tr>\n","    <tr>\n","      <th>13506</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_아메리카노 HOT</td>\n","      <td>27.679980</td>\n","    </tr>\n","    <tr>\n","      <th>13507</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_아메리카노 ICE</td>\n","      <td>92.439979</td>\n","    </tr>\n","    <tr>\n","      <th>13508</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_카페라떼 ICE</td>\n","      <td>25.499672</td>\n","    </tr>\n","    <tr>\n","      <th>13509</th>\n","      <td>TEST_09+7일</td>\n","      <td>화담숲카페_현미뻥스크림</td>\n","      <td>50.439278</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13510 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00214f97-61c6-42d3-9896-9cc5871f244c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-00214f97-61c6-42d3-9896-9cc5871f244c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-00214f97-61c6-42d3-9896-9cc5871f244c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-4089b57c-5868-405f-be9f-f3f31df9e3cd\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4089b57c-5868-405f-be9f-f3f31df9e3cd')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-4089b57c-5868-405f-be9f-f3f31df9e3cd button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_fece2d34-3612-4909-bf80-e2308d5353e8\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('full_pred_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_fece2d34-3612-4909-bf80-e2308d5353e8 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('full_pred_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"full_pred_df","summary":"{\n  \"name\": \"full_pred_df\",\n  \"rows\": 13510,\n  \"fields\": [\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc77c\\uc790\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"TEST_03+2\\uc77c\",\n          \"TEST_00+1\\uc77c\",\n          \"TEST_07+1\\uc77c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc7a5\\uba85_\\uba54\\ub274\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"\\ub2f4\\ud558_\\uba54\\ubc00\\uba74 \\uc0ac\\ub9ac\",\n          \"\\uc5f0\\ud68c\\uc7a5_\\ub9c8\\ub77c\\uc0f9\\uad88\",\n          \"\\ub77c\\uadf8\\ub85c\\ud0c0_\\uc2a4\\ud504\\ub77c\\uc774\\ud2b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.37567981242083,\n        \"min\": 0.0,\n        \"max\": 661.0317461490631,\n        \"num_unique_values\": 13404,\n        \"samples\": [\n          12.179772186279298,\n          8.329676866531372,\n          2.8622573390603065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":79}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RuJpr5iCYLt"},"outputs":[],"source":["def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n","    # (영업일자, 메뉴) → 매출수량 딕셔너리로 변환\n","    pred_dict = dict(zip(\n","        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n","        pred_df['매출수량'].astype(float)\n","    ))\n","\n","    final_df = sample_submission.copy()\n","\n","    menu_cols = final_df.columns[1:]\n","    final_df[menu_cols] = final_df[menu_cols].astype(float)\n","\n","    for row_idx in final_df.index:\n","        date = final_df.loc[row_idx, '영업일자']\n","        for col in final_df.columns[1:]:  # 메뉴명들\n","            final_df.loc[row_idx, col] = pred_dict.get((date, col), 0)\n","\n","    return final_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_Hoods1EDeM"},"outputs":[],"source":["full_pred_df_notzero = full_pred_df.copy()\n","full_pred_df_notzero.loc[full_pred_df_notzero['매출수량'].abs() < 1e-9, '매출수량'] = 1\n","\n","sample_submission = pd.read_csv('DATA/sample_submission.csv')\n","final_hybrid = convert_to_submission_format(full_pred_df, sample_submission)\n","final_hybrid.to_csv('baseline_submission_hybrid.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zlrRIwTEFJe"},"outputs":[],"source":["df_lstm_plz = df_lstm.copy()\n","df_lstm_plz['영업장명_메뉴명'] = df_lstm['영업장명_메뉴명'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n","df_lstm_end = df_lstm_plz.rename(columns = {'매출수량(lstm)' : '매출수량'})\n","\n","# 1 변환\n","df_lstm_end.loc[df_lstm_end['매출수량'].abs() < 1e-9, '매출수량'] = 1\n","\n","sample_submission = pd.read_csv('DATA/sample_submission.csv')\n","final_lstm = convert_to_submission_format(df_lstm_end, sample_submission)\n","final_lstm.to_csv('baseline_submission_lstm.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","source":["df_reg_notzero = df_reg.copy()\n","df_reg_notzero.loc[df_reg_notzero['매출수량'].abs() < 1e-9, '매출수량'] = 1\n","\n","sample_submission = pd.read_csv('DATA/sample_submission.csv')\n","final_hybrid = convert_to_submission_format(df_reg, sample_submission)\n","final_hybrid.to_csv('baseline_submission_reg.csv', index=False, encoding='utf-8-sig')"],"metadata":{"id":"vlQbxRFuFtUp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### XAI"],"metadata":{"id":"wdbpgBmNaqDl"}},{"cell_type":"markdown","source":["##### LSTM 모델"],"metadata":{"id":"Hc0VaR5TbB37"}},{"cell_type":"code","source":["# 저장된 모델 로드 - CPU\n","lookback, predict, batch_size, epochs = 28, 7, 16, 200\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model_path = '/content/drive/MyDrive/3. Grad School/LG Aimers/Models/Trial 6/lstm_models_cpu.pkl'\n","lstm = LSTMModel(lookback = 28, predict = 7)\n","trained_lstm = lstm.load_saved_model(model_path)"],"metadata":{"id":"5L3B-dRJaw5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ! pip install captum\n","from captum.attr import IntegratedGradients"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"7ZN2tYo4afFs","executionInfo":{"status":"ok","timestamp":1755323442773,"user_tz":-540,"elapsed":138898,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"c3ba6a5f-e425-4e3a-b0ef-7b966bf48727"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting captum\n","  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.10.0)\n","Collecting numpy<2.0 (from captum)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m514.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum) (25.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10->captum)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10->captum)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10->captum)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10->captum)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10->captum)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10->captum)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10->captum)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10->captum)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10->captum)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.10->captum)\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10->captum)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n","Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, captum\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed captum-0.8.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"9eec9e2598fa4e08b1754976d938f30b"}},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from captum.attr import IntegratedGradients\n","from collections import defaultdict\n","from typing import Dict, List"],"metadata":{"id":"zc9OU0FGb0Xw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from typing import Dict, List, Optional\n","\n","def build_input_last_window(\n","    df: pd.DataFrame,\n","    menu_name: str,\n","    mv,  # Make_Variables() 인스턴스\n","    cols: List[str],\n","    enc_cols: List[str],\n","    num_cols: List[str],\n","    encoders: Dict[str, object],\n","    features_scaler,\n","    lookback: int,\n","    debug: bool = False,\n",") -> Optional[np.ndarray]:\n","    \"\"\"\n","    해당 메뉴 df에서 마지막 lookback 윈도우(1개)를 만들어 (lookback, F) numpy 반환.\n","    예측 시와 동일한 전처리를 최대한 재현. (없거나 부족하면 None 반환)\n","\n","    Params\n","    ------\n","    df : 전체 데이터프레임 (여러 메뉴 포함)\n","    menu_name : trained_models의 키(문자열 or ('키',) 형태 튜플일 수 있음)\n","    mv : Make_Variables 인스턴스 (make_variables_train 사용)\n","    cols : 최종 입력 피처 컬럼 리스트 (모델 학습 시 사용한 순서)\n","    enc_cols : 인코딩할 범주형 컬럼 리스트\n","    num_cols : 스케일링할 수치형 컬럼 리스트\n","    encoders : {col: fitted LabelEncoder-like} 딕셔너리\n","    features_scaler : fitted scaler (예: StandardScaler/MinMaxScaler)\n","    lookback : LSTM lookback 길이\n","    debug : True면 중간 정보 프린트\n","\n","    Returns\n","    -------\n","    np.ndarray shape (lookback, len(cols)) or None\n","    \"\"\"\n","\n","    # 1) 메뉴 키를 문자열로 정규화\n","    key = menu_name\n","    if isinstance(key, (tuple, list)):\n","        key = key[0]\n","    key = str(key)\n","\n","    # 2) df 쪽도 문자열 비교로 통일\n","    df_key = df['영업장명_메뉴명'].astype(str)\n","    store = df[df_key == key].copy()\n","    if store.empty:\n","        if debug:\n","            print(f\"[build_input_last_window] menu='{key}' → store.empty=True\")\n","        return None\n","\n","    # 정렬 (필수)\n","    store = store.sort_values('영업일자')\n","\n","    # 3) 파생변수 생성 (함수 내부에서 NaN 생기지 않게 주의)\n","    store = mv.make_variables_train(store)\n","    store = store.sort_values('영업일자').reset_index(drop=True)\n","\n","    if len(store) < lookback:\n","        if debug:\n","            print(f\"[build_input_last_window] menu='{key}' → len(store)={len(store)} < lookback={lookback}\")\n","        return None\n","\n","    # 4) 입력 특징 행렬 (lookback 길이만큼 슬라이스)\n","    #    필요한 컬럼이 전부 있는지 먼저 체크(없으면 없는 것만 제외하고 경고)\n","    missing_cols = [c for c in cols if c not in store.columns]\n","    if missing_cols and debug:\n","        print(f\"[build_input_last_window][WARN] menu='{key}' missing cols: {missing_cols}\")\n","\n","    # 존재하는 컬럼만 사용 (모델과 cols가 반드시 일치해야 한다면 여기서 None 반환해도 됨)\n","    use_cols = [c for c in cols if c in store.columns]\n","    if len(use_cols) == 0:\n","        if debug:\n","            print(f\"[build_input_last_window][ERROR] menu='{key}' no usable cols in `cols`.\")\n","        return None\n","\n","    full = store[use_cols].iloc[-lookback:].copy()\n","\n","    # 5) enc_cols 인코딩 (학습 시 encoders가 있다면 transform 사용)\n","    for c in enc_cols:\n","        if c not in full.columns:\n","            continue\n","        s = full[c]\n","        if c in encoders:\n","            le = encoders[c]\n","            # 문자열로 통일 후 transform\n","            try:\n","                full[c] = le.transform(s.astype(str))\n","            except Exception as e:\n","                # 학습 시 없던 새로운 레이블 등장 시 대응(필요하면 더 정교하게 처리)\n","                if debug:\n","                    print(f\"[build_input_last_window][ENC WARN] menu='{key}' col='{c}' transform error: {e}. Fallback to factorize.\")\n","                full[c] = pd.factorize(s.astype(str))[0]\n","        else:\n","            # 수치형이 아니면 안전하게 factorize\n","            if not np.issubdtype(full[c].dtype, np.number):\n","                full[c] = pd.factorize(s.astype(str))[0]\n","\n","    # 6) num_cols 스케일링 (교집합만 적용)\n","    if num_cols:\n","        scale_cols = [c for c in num_cols if c in full.columns]\n","        if scale_cols:\n","            full[scale_cols] = features_scaler.transform(full[scale_cols])\n","\n","    # 7) 결측 안전 처리\n","    full = full.fillna(0.0)\n","\n","    # 8) 최종 컬럼 순서를 원래 `cols` 순서로 맞춰주되, 없는 건 제외\n","    #    (모델 입력 차원 순서를 맞추기 위함)\n","    final_cols = [c for c in cols if c in full.columns]\n","    X = full[final_cols].to_numpy(dtype=np.float32)\n","\n","    # 만약 모델이 정확히 len(cols) 차원을 기대한다면, 여기서 길이 검증\n","    if len(final_cols) != len(cols):\n","        if debug:\n","            missing_for_model = [c for c in cols if c not in final_cols]\n","            print(f\"[build_input_last_window][WARN] menu='{key}' some model cols missing in final input: {missing_for_model}\")\n","\n","    # shape: (lookback, F_used)\n","    return X\n","\n","\n","\n","def aggregate_feature_importance_IG(\n","    test_df: pd.DataFrame,\n","    trained_models: Dict[str, dict],\n","    mv,  # Make_Variables() 인스턴스\n","    MultiOutputLSTM,  # 모델 클래스\n","    cols: List[str],\n","    enc_cols: List[str],\n","    num_cols: List[str],\n","    lookback: int,\n","    predict: int,\n","    device: str = \"cpu\",\n","    ig_steps: int = 64,          # IG 적분 스텝\n","    baseline_mode: str = \"zero\", # \"zero\" or \"mean\"\n","):\n","    \"\"\"\n","    모든 메뉴(모델)에 대해:\n","      1) 마지막 윈도우 입력 x (1, T, F)를 만들고\n","      2) 각 호라이즌 k에 대해 IG(Integrated Gradients)로 (T,F) 기여도 계산\n","      3) 절대값 합으로 특성별 중요도 집계\n","    반환:\n","      - overall_df: 전체 메뉴×호라이즌 집계한 최종 특성 중요도\n","      - per_horizon_df: 호라이즌별 특성 중요도 (각 k 행)\n","    \"\"\"\n","    device = torch.device(device)\n","\n","    # 전역 집계 버퍼\n","    feat_total = np.zeros(len(cols), dtype=np.float64)               # 전체 특성 중요도\n","    feat_total_by_h = np.zeros((predict, len(cols)), dtype=np.float64)  # 호라이즌별 특성 중요도\n","\n","    # baseline 준비용 mean 벡터 (선택)\n","    mean_input = None\n","    if baseline_mode == \"mean\":\n","        # 간단히: 모든 메뉴의 마지막 윈도우를 모아 평균 (메모리 아끼려면 일부만 샘플)\n","        stacks = []\n","        for menu, bundle in trained_models.items():\n","            x_np = build_input_last_window(\n","                test_df, menu, mv, cols, enc_cols, num_cols,\n","                bundle['encoders'], bundle['features_scaler'], lookback\n","            )\n","            if x_np is not None:\n","                stacks.append(x_np)\n","        if len(stacks) == 0:\n","            raise ValueError(\"평균 baseline을 만들 입력이 없습니다.\")\n","        mean_input = np.mean(np.stack(stacks, axis=0), axis=0)  # (T,F)\n","\n","    for menu, bundle in trained_models.items():\n","        state = bundle['model']\n","        meta  = bundle['meta']\n","        encoders = bundle['encoders']\n","        fscaler  = bundle['features_scaler']\n","\n","        # 모델 로드\n","        model = MultiOutputLSTM(\n","            input_dim=meta['input_dim'],\n","            hidden_dim=meta['hidden_dim'],\n","            num_layers=meta['num_layers'],\n","            output_dim=meta['output_dim']\n","        ).to(device).eval()\n","        model.load_state_dict(state)\n","\n","        # 입력 만들기\n","        x_np = build_input_last_window(\n","            test_df, menu, mv, cols, enc_cols, num_cols, encoders, fscaler, lookback\n","        )\n","        if x_np is None:  # 데이터 부족\n","            continue\n","\n","        x = torch.from_numpy(x_np).unsqueeze(0).to(device)  # (1,T,F)\n","        x = x.detach()\n","        x.requires_grad_(True)\n","\n","        # baseline\n","        if baseline_mode == \"zero\":\n","            baseline = torch.zeros_like(x)\n","        else:\n","            baseline = torch.from_numpy(mean_input).unsqueeze(0).to(device)\n","\n","        # 호라이즌별로 IG 계산\n","        for day_k in range(predict):\n","            def forward_for_k(inp):\n","                out = model(inp)          # (N, predict)\n","                return out[:, day_k]      # (N,)\n","\n","            ig = IntegratedGradients(forward_for_k)\n","            attr, _ = ig.attribute(\n","                inputs=x, baselines=baseline, n_steps=ig_steps, return_convergence_delta=True\n","            )  # (1,T,F)\n","\n","            A = attr.squeeze(0).detach().cpu().numpy()  # (T,F)\n","\n","            # 시간축으로 합산(또는 평균)하여 특성 중요도 벡터로\n","            feat_imp_k = np.abs(A).sum(axis=0)  # (F,)\n","            feat_total_by_h[day_k] += feat_imp_k\n","            feat_total += feat_imp_k\n","\n","    # 정리: pandas로 출력\n","    overall_df = pd.DataFrame({\n","        \"feature\": cols,\n","        \"importance\": feat_total\n","    }).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n","\n","    per_horizon_df = pd.DataFrame(\n","        feat_total_by_h, columns=cols\n","    )\n","    per_horizon_df.index = [f\"H+{k+1}\" for k in range(predict)]\n","\n","    # 정규화(선택): 총합=1\n","    if overall_df[\"importance\"].sum() > 0:\n","        overall_df[\"norm_importance\"] = overall_df[\"importance\"] / overall_df[\"importance\"].sum()\n","    per_horizon_norm = per_horizon_df.div(per_horizon_df.sum(axis=1).replace(0, np.nan), axis=0)\n","\n","    return overall_df, per_horizon_df, per_horizon_norm"],"metadata":{"id":"KP_QU6hkb6jJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 test_*.csv 순회\n","test_files = sorted(glob.glob('DATA/test/TEST_*.csv'))\n","\n","for path in test_files[:1]:\n","    test_df = pd.read_csv(path)"],"metadata":{"id":"nSAndkvIcQtY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 준비물 예시\n","mv = Make_Variables()\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","overall_df, per_horizon_df, per_horizon_norm = aggregate_feature_importance_IG(\n","    test_df=test_df,\n","    trained_models=trained_lstm,         # 당신의 dict\n","    mv=mv,\n","    MultiOutputLSTM=MultiOutputLSTM,     # 당신의 클래스\n","    cols=cols,\n","    enc_cols=enc_cols,\n","    num_cols=num_cols,\n","    lookback=28,\n","    predict=7,\n","    device=device,\n","    ig_steps=64,\n","    baseline_mode=\"zero\",   # 또는 \"mean\"\n",")\n","\n","print(overall_df)      # 전반적 변수 중요도 Top20\n","print(per_horizon_norm)  # 호라이즌별 중요도 (행정규화)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECOyGzagcBF_","executionInfo":{"status":"ok","timestamp":1755325574439,"user_tz":-540,"elapsed":126030,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"eaeec41c-aed2-43bf-89b4-27f9a0155f1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                feature  importance  norm_importance\n","0                season   84.869912         0.206079\n","1             month_cos   44.624976         0.108357\n","2           weekday_cos   41.015457         0.099593\n","3           weekday_sin   36.113747         0.087690\n","4               day_sin   32.110272         0.077969\n","5               day_cos   20.873418         0.050684\n","6   is_holiday_sandwich   19.185584         0.046586\n","7             month_sin   19.170896         0.046550\n","8            prev_sd_21   13.856936         0.033647\n","9            prev_sd_14   13.843205         0.033614\n","10            prev_sd_7   13.391129         0.032516\n","11          prev_avg_21   12.042355         0.029241\n","12           prev_avg_7   11.037719         0.026801\n","13          prev_avg_14   10.936975         0.026557\n","14             year_enc   10.776368         0.026167\n","15           is_holiday    9.935498         0.024125\n","16         month_weight    7.548724         0.018330\n","17          is_sandwich    6.332801         0.015377\n","18          week_weight    4.166663         0.010117\n","     year_enc  month_sin  month_cos   day_sin   day_cos  weekday_sin  \\\n","H+1  0.025421   0.044210   0.107307  0.079813  0.056660     0.088023   \n","H+2  0.027531   0.043186   0.111484  0.075353  0.056181     0.086934   \n","H+3  0.027152   0.046871   0.107155  0.076787  0.050625     0.085544   \n","H+4  0.027221   0.050133   0.108448  0.078907  0.047925     0.083304   \n","H+5  0.026910   0.048198   0.109178  0.080486  0.047059     0.087075   \n","H+6  0.025284   0.047048   0.108965  0.075177  0.047434     0.090359   \n","H+7  0.024335   0.047009   0.106135  0.079332  0.048354     0.090921   \n","\n","     weekday_cos    season  is_holiday  is_sandwich  is_holiday_sandwich  \\\n","H+1     0.098885  0.202263    0.027403     0.017000             0.049134   \n","H+2     0.097523  0.205434    0.026055     0.016232             0.049096   \n","H+3     0.098122  0.212629    0.025088     0.015853             0.047841   \n","H+4     0.093112  0.213519    0.022290     0.015417             0.046730   \n","H+5     0.094760  0.208800    0.020562     0.014101             0.043732   \n","H+6     0.104562  0.206107    0.021989     0.014378             0.042992   \n","H+7     0.107338  0.197455    0.024942     0.014709             0.046667   \n","\n","     month_weight  week_weight  prev_avg_7  prev_avg_14  prev_avg_21  \\\n","H+1      0.020127     0.010061    0.026448     0.024531     0.027075   \n","H+2      0.019896     0.009711    0.025725     0.024647     0.028304   \n","H+3      0.018844     0.009689    0.025441     0.026115     0.028681   \n","H+4      0.018492     0.009461    0.026925     0.027763     0.030402   \n","H+5      0.017364     0.010465    0.027072     0.029111     0.031802   \n","H+6      0.016904     0.010122    0.028204     0.027932     0.030313   \n","H+7      0.016887     0.011052    0.027485     0.026179     0.028527   \n","\n","     prev_sd_7  prev_sd_14  prev_sd_21  \n","H+1   0.031835    0.031796    0.032010  \n","H+2   0.031640    0.032526    0.032540  \n","H+3   0.031541    0.033067    0.032955  \n","H+4   0.032005    0.034089    0.033858  \n","H+5   0.033377    0.035301    0.034648  \n","H+6   0.032896    0.034332    0.035000  \n","H+7   0.033980    0.034268    0.034427  \n"]}]},{"cell_type":"code","source":["overall_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"mzzed51TkmW9","executionInfo":{"status":"ok","timestamp":1755325857412,"user_tz":-540,"elapsed":25,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"6d4184eb-57f7-43a3-c35b-f9eee7f63765"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                feature  importance  norm_importance\n","0                season   84.869912         0.206079\n","1             month_cos   44.624976         0.108357\n","2           weekday_cos   41.015457         0.099593\n","3           weekday_sin   36.113747         0.087690\n","4               day_sin   32.110272         0.077969\n","5               day_cos   20.873418         0.050684\n","6   is_holiday_sandwich   19.185584         0.046586\n","7             month_sin   19.170896         0.046550\n","8            prev_sd_21   13.856936         0.033647\n","9            prev_sd_14   13.843205         0.033614\n","10            prev_sd_7   13.391129         0.032516\n","11          prev_avg_21   12.042355         0.029241\n","12           prev_avg_7   11.037719         0.026801\n","13          prev_avg_14   10.936975         0.026557\n","14             year_enc   10.776368         0.026167\n","15           is_holiday    9.935498         0.024125\n","16         month_weight    7.548724         0.018330\n","17          is_sandwich    6.332801         0.015377\n","18          week_weight    4.166663         0.010117"],"text/html":["\n","  <div id=\"df-bdc2d600-4317-4934-82c5-a17812c513fe\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature</th>\n","      <th>importance</th>\n","      <th>norm_importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>season</td>\n","      <td>84.869912</td>\n","      <td>0.206079</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>month_cos</td>\n","      <td>44.624976</td>\n","      <td>0.108357</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>weekday_cos</td>\n","      <td>41.015457</td>\n","      <td>0.099593</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>weekday_sin</td>\n","      <td>36.113747</td>\n","      <td>0.087690</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>day_sin</td>\n","      <td>32.110272</td>\n","      <td>0.077969</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>day_cos</td>\n","      <td>20.873418</td>\n","      <td>0.050684</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>is_holiday_sandwich</td>\n","      <td>19.185584</td>\n","      <td>0.046586</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>month_sin</td>\n","      <td>19.170896</td>\n","      <td>0.046550</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>prev_sd_21</td>\n","      <td>13.856936</td>\n","      <td>0.033647</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>prev_sd_14</td>\n","      <td>13.843205</td>\n","      <td>0.033614</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>prev_sd_7</td>\n","      <td>13.391129</td>\n","      <td>0.032516</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>prev_avg_21</td>\n","      <td>12.042355</td>\n","      <td>0.029241</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>prev_avg_7</td>\n","      <td>11.037719</td>\n","      <td>0.026801</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>prev_avg_14</td>\n","      <td>10.936975</td>\n","      <td>0.026557</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>year_enc</td>\n","      <td>10.776368</td>\n","      <td>0.026167</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>is_holiday</td>\n","      <td>9.935498</td>\n","      <td>0.024125</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>month_weight</td>\n","      <td>7.548724</td>\n","      <td>0.018330</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>is_sandwich</td>\n","      <td>6.332801</td>\n","      <td>0.015377</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>week_weight</td>\n","      <td>4.166663</td>\n","      <td>0.010117</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdc2d600-4317-4934-82c5-a17812c513fe')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bdc2d600-4317-4934-82c5-a17812c513fe button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bdc2d600-4317-4934-82c5-a17812c513fe');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f68d44d8-9d63-458a-b7d8-338fec1dd04c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f68d44d8-9d63-458a-b7d8-338fec1dd04c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f68d44d8-9d63-458a-b7d8-338fec1dd04c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_b727376d-3cac-4a28-94cc-7d49de2f5556\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('overall_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b727376d-3cac-4a28-94cc-7d49de2f5556 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('overall_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"overall_df","summary":"{\n  \"name\": \"overall_df\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"season\",\n          \"day_cos\",\n          \"prev_avg_21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.34372321296684,\n        \"min\": 4.166663011291121,\n        \"max\": 84.86991227574981,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          84.86991227574981,\n          20.873417720924408,\n          12.042355019747376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"norm_importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04696986488615196,\n        \"min\": 0.010117369676551238,\n        \"max\": 0.20607864724921982,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.20607864724921982,\n          0.050684224503730245,\n          0.02924089545540261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["per_horizon_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"DTQdfutXk0uj","executionInfo":{"status":"ok","timestamp":1755325923047,"user_tz":-540,"elapsed":49,"user":{"displayName":"박준희","userId":"01167826914931997240"}},"outputId":"71bc629b-d1d4-4c06-dbb9-15d5e0d3247d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     year_enc  month_sin  month_cos   day_sin   day_cos  weekday_sin  \\\n","H+1  1.604334   2.790146   6.772316  5.037103  3.575934     5.555296   \n","H+2  1.659375   2.602959   6.719466  4.541760  3.386222     5.239784   \n","H+3  1.391010   2.401211   5.489500  3.933792  2.593494     4.382369   \n","H+4  1.359214   2.503329   5.415160  3.940078  2.393078     4.159656   \n","H+5  1.509117   2.702943   6.122737  4.513648  2.639076     4.883200   \n","H+6  1.611569   2.998806   6.945364  4.791700  3.023415     5.759425   \n","H+7  1.641750   3.171501   7.160433  5.352190  3.262199     6.134017   \n","\n","     weekday_cos     season  is_holiday  is_sandwich  is_holiday_sandwich  \\\n","H+1     6.240763  12.765112    1.729429     1.072913             3.100922   \n","H+2     5.877996  12.382138    1.570435     0.978376             2.959194   \n","H+3     5.026776  10.892910    1.285235     0.812130             2.450873   \n","H+4     4.649391  10.661720    1.112991     0.769818             2.333372   \n","H+5     5.314176  11.709555    1.153136     0.790762             2.452519   \n","H+6     6.664727  13.137104    1.401579     0.916469             2.740308   \n","H+7     7.241629  13.321374    1.682693     0.992333             3.148396   \n","\n","     month_weight  week_weight  prev_avg_7  prev_avg_14  prev_avg_21  \\\n","H+1      1.270241     0.634946    1.669149     1.548195     1.708743   \n","H+2      1.199221     0.585311    1.550529     1.485531     1.705968   \n","H+3      0.965381     0.496349    1.303348     1.337872     1.469338   \n","H+4      0.923385     0.472400    1.344457     1.386320     1.518058   \n","H+5      0.973754     0.586854    1.518178     1.632551     1.783480   \n","H+6      1.077440     0.645174    1.797734     1.780360     1.932157   \n","H+7      1.139302     0.745629    1.854323     1.766147     1.924612   \n","\n","     prev_sd_7  prev_sd_14  prev_sd_21  \n","H+1   2.009152    2.006677    2.020215  \n","H+2   1.907065    1.960410    1.961275  \n","H+3   1.615817    1.694023    1.688270  \n","H+4   1.598106    1.702183    1.690636  \n","H+5   1.871783    1.979664    1.943044  \n","H+6   2.096748    2.188317    2.230893  \n","H+7   2.292459    2.311930    2.322603  "],"text/html":["\n","  <div id=\"df-53e33d38-e7b5-4994-9ad3-cc6a2d0a5b01\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year_enc</th>\n","      <th>month_sin</th>\n","      <th>month_cos</th>\n","      <th>day_sin</th>\n","      <th>day_cos</th>\n","      <th>weekday_sin</th>\n","      <th>weekday_cos</th>\n","      <th>season</th>\n","      <th>is_holiday</th>\n","      <th>is_sandwich</th>\n","      <th>is_holiday_sandwich</th>\n","      <th>month_weight</th>\n","      <th>week_weight</th>\n","      <th>prev_avg_7</th>\n","      <th>prev_avg_14</th>\n","      <th>prev_avg_21</th>\n","      <th>prev_sd_7</th>\n","      <th>prev_sd_14</th>\n","      <th>prev_sd_21</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>H+1</th>\n","      <td>1.604334</td>\n","      <td>2.790146</td>\n","      <td>6.772316</td>\n","      <td>5.037103</td>\n","      <td>3.575934</td>\n","      <td>5.555296</td>\n","      <td>6.240763</td>\n","      <td>12.765112</td>\n","      <td>1.729429</td>\n","      <td>1.072913</td>\n","      <td>3.100922</td>\n","      <td>1.270241</td>\n","      <td>0.634946</td>\n","      <td>1.669149</td>\n","      <td>1.548195</td>\n","      <td>1.708743</td>\n","      <td>2.009152</td>\n","      <td>2.006677</td>\n","      <td>2.020215</td>\n","    </tr>\n","    <tr>\n","      <th>H+2</th>\n","      <td>1.659375</td>\n","      <td>2.602959</td>\n","      <td>6.719466</td>\n","      <td>4.541760</td>\n","      <td>3.386222</td>\n","      <td>5.239784</td>\n","      <td>5.877996</td>\n","      <td>12.382138</td>\n","      <td>1.570435</td>\n","      <td>0.978376</td>\n","      <td>2.959194</td>\n","      <td>1.199221</td>\n","      <td>0.585311</td>\n","      <td>1.550529</td>\n","      <td>1.485531</td>\n","      <td>1.705968</td>\n","      <td>1.907065</td>\n","      <td>1.960410</td>\n","      <td>1.961275</td>\n","    </tr>\n","    <tr>\n","      <th>H+3</th>\n","      <td>1.391010</td>\n","      <td>2.401211</td>\n","      <td>5.489500</td>\n","      <td>3.933792</td>\n","      <td>2.593494</td>\n","      <td>4.382369</td>\n","      <td>5.026776</td>\n","      <td>10.892910</td>\n","      <td>1.285235</td>\n","      <td>0.812130</td>\n","      <td>2.450873</td>\n","      <td>0.965381</td>\n","      <td>0.496349</td>\n","      <td>1.303348</td>\n","      <td>1.337872</td>\n","      <td>1.469338</td>\n","      <td>1.615817</td>\n","      <td>1.694023</td>\n","      <td>1.688270</td>\n","    </tr>\n","    <tr>\n","      <th>H+4</th>\n","      <td>1.359214</td>\n","      <td>2.503329</td>\n","      <td>5.415160</td>\n","      <td>3.940078</td>\n","      <td>2.393078</td>\n","      <td>4.159656</td>\n","      <td>4.649391</td>\n","      <td>10.661720</td>\n","      <td>1.112991</td>\n","      <td>0.769818</td>\n","      <td>2.333372</td>\n","      <td>0.923385</td>\n","      <td>0.472400</td>\n","      <td>1.344457</td>\n","      <td>1.386320</td>\n","      <td>1.518058</td>\n","      <td>1.598106</td>\n","      <td>1.702183</td>\n","      <td>1.690636</td>\n","    </tr>\n","    <tr>\n","      <th>H+5</th>\n","      <td>1.509117</td>\n","      <td>2.702943</td>\n","      <td>6.122737</td>\n","      <td>4.513648</td>\n","      <td>2.639076</td>\n","      <td>4.883200</td>\n","      <td>5.314176</td>\n","      <td>11.709555</td>\n","      <td>1.153136</td>\n","      <td>0.790762</td>\n","      <td>2.452519</td>\n","      <td>0.973754</td>\n","      <td>0.586854</td>\n","      <td>1.518178</td>\n","      <td>1.632551</td>\n","      <td>1.783480</td>\n","      <td>1.871783</td>\n","      <td>1.979664</td>\n","      <td>1.943044</td>\n","    </tr>\n","    <tr>\n","      <th>H+6</th>\n","      <td>1.611569</td>\n","      <td>2.998806</td>\n","      <td>6.945364</td>\n","      <td>4.791700</td>\n","      <td>3.023415</td>\n","      <td>5.759425</td>\n","      <td>6.664727</td>\n","      <td>13.137104</td>\n","      <td>1.401579</td>\n","      <td>0.916469</td>\n","      <td>2.740308</td>\n","      <td>1.077440</td>\n","      <td>0.645174</td>\n","      <td>1.797734</td>\n","      <td>1.780360</td>\n","      <td>1.932157</td>\n","      <td>2.096748</td>\n","      <td>2.188317</td>\n","      <td>2.230893</td>\n","    </tr>\n","    <tr>\n","      <th>H+7</th>\n","      <td>1.641750</td>\n","      <td>3.171501</td>\n","      <td>7.160433</td>\n","      <td>5.352190</td>\n","      <td>3.262199</td>\n","      <td>6.134017</td>\n","      <td>7.241629</td>\n","      <td>13.321374</td>\n","      <td>1.682693</td>\n","      <td>0.992333</td>\n","      <td>3.148396</td>\n","      <td>1.139302</td>\n","      <td>0.745629</td>\n","      <td>1.854323</td>\n","      <td>1.766147</td>\n","      <td>1.924612</td>\n","      <td>2.292459</td>\n","      <td>2.311930</td>\n","      <td>2.322603</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53e33d38-e7b5-4994-9ad3-cc6a2d0a5b01')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-53e33d38-e7b5-4994-9ad3-cc6a2d0a5b01 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-53e33d38-e7b5-4994-9ad3-cc6a2d0a5b01');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-63082d51-f0a5-418e-bebf-7bdf31dd2637\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63082d51-f0a5-418e-bebf-7bdf31dd2637')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-63082d51-f0a5-418e-bebf-7bdf31dd2637 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_e8e41214-fe9c-4806-b422-cb69638e5373\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('per_horizon_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_e8e41214-fe9c-4806-b422-cb69638e5373 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('per_horizon_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"per_horizon_df","summary":"{\n  \"name\": \"per_horizon_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"year_enc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12226860344422823,\n        \"min\": 1.3592138825733855,\n        \"max\": 1.659374830294837,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.604333795110506,\n          1.659374830294837,\n          1.6115685420918453\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_sin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27283111536388444,\n        \"min\": 2.4012113254502765,\n        \"max\": 3.1715011624128238,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.7901456944837264,\n          2.602959362569891,\n          2.99880595963441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_cos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.705664793592376,\n        \"min\": 5.4151603688296746,\n        \"max\": 7.1604332703354885,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6.772316498780128,\n          6.719465630099876,\n          6.94536366077773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_sin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5295640042452171,\n        \"min\": 3.933791580686375,\n        \"max\": 5.352190412959317,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5.037103427905095,\n          4.5417597998384736,\n          4.791700487759954\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_cos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44939635705882836,\n        \"min\": 2.39307796326284,\n        \"max\": 3.5759336966930277,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.5759336966930277,\n          3.3862224091672033,\n          3.0234147298479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday_sin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7248740703032781,\n        \"min\": 4.159656354943763,\n        \"max\": 6.134016597818118,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5.555296334798186,\n          5.23978408939729,\n          5.759425356414795\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday_cos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9273210974663838,\n        \"min\": 4.649391042544266,\n        \"max\": 7.241628893975758,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6.240763199111825,\n          5.877995560145791,\n          6.664726967172783\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.061708603992158,\n        \"min\": 10.66172011992603,\n        \"max\": 13.321373789593054,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          12.765111630837055,\n          12.382137551452615,\n          13.137103701639717\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_holiday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2487814168134456,\n        \"min\": 1.1129913350778224,\n        \"max\": 1.7294289236351688,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.7294289236351688,\n          1.570434971586792,\n          1.4015785909373335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sandwich\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11639457725005048,\n        \"min\": 0.7698176576391234,\n        \"max\": 1.0729126452040845,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0729126452040845,\n          0.9783761527298793,\n          0.9164694637559023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_holiday_sandwich\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3358271706135091,\n        \"min\": 2.333372192817478,\n        \"max\": 3.148396115968353,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.1009219386050972,\n          2.959193685561786,\n          2.7403077512535674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1309353461945559,\n        \"min\": 0.9233854477715795,\n        \"max\": 1.2702411045762574,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.2702411045762574,\n          1.1992209897323391,\n          1.0774396419890877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"week_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09284844867125493,\n        \"min\": 0.47239969088786893,\n        \"max\": 0.7456291913713358,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.634946403262802,\n          0.5853108129635984,\n          0.6451738064131405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_avg_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21104703419844148,\n        \"min\": 1.3033484414262375,\n        \"max\": 1.8543232558670297,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.6691490742140616,\n          1.5505293635246744,\n          1.7977341338633437\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_avg_14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1739098574654554,\n        \"min\": 1.337872275816494,\n        \"max\": 1.7803601772210413,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.5481945814432265,\n          1.4855311219042733,\n          1.7803601772210413\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_avg_21\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1802040281976862,\n        \"min\": 1.4693383437699339,\n        \"max\": 1.9321569261018112,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.708742668656356,\n          1.7059677504377646,\n          1.9321569261018112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_sd_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2504024110849312,\n        \"min\": 1.598105536287676,\n        \"max\": 2.2924590512089935,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.009151570201766,\n          1.9070654682178656,\n          2.0967479706852146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_sd_14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22861692513747034,\n        \"min\": 1.6940232901737318,\n        \"max\": 2.311930456649975,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.006676507565203,\n          1.9604103707885656,\n          2.188317197114884\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_sd_21\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24238211092569392,\n        \"min\": 1.6882696672266775,\n        \"max\": 2.322603426302237,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.0202151369996955,\n          1.961275234231536,\n          2.2308928410387807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":37}]}],"metadata":{"colab":{"collapsed_sections":["u9ImcgXgKdEC","i2wKL_C6P2Bp","Qbp0yN6WBSq5","PnTZIj8uXAdw"],"machine_shape":"hm","provenance":[],"mount_file_id":"1amDhjUMWZ3X_w8BIuJ2AM6hIP2d6j3Yn","authorship_tag":"ABX9TyN5NMAhuwPa546AfzvFCJAK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}